California Institute of the ArtsElectromagnetic Translucenceartistic approaches to interaction design for installations, interfaces, and mechatronic performancebyNathan Villicaña-ShawA thesis submitted in partial fulfillment for the degree of Master of Fine ArtsHerb Alpert School of MusicMusic Technology: Interaction, Intelligence & Design2017
Supervisory CommitteeDr. Ajay Kapur							MentorDr. Owen Vallis			   			     Committee MemberDr. Spencer Salazar							Committee Member

AbstractThis thesis focuses on a variety of approaches for complicating, simplifying, and exposing human-circuit interaction within the context of installation art, interface design, and mechatronic performance. Every interface, installation, and performance presented in this document addresses these topics with divergent values in order to gain a comprehensive understanding of our relationships with technology. Due to the large number of projects introduced, the document is structured with multiple projects contained within each chapter. After an introduction of related work in the background chapter, Chapter 3 presents several interactive-installations that explore interactive experience within the art gallery. In Chapter 4 a collection of hardware interfaces are introduced and discussed in terms of the relationships they build with their users and how the user and device interact. Chapter 5 focuses on stage dynamics between human and mechatronic performers through several human-mechatronic performances. Chapter 6 gives an overview of The Pantheon, the authors comprehensive system for creating mechatronic sound art.The primary goals of this work include:• To create a corpus of work that provokes dialogue on human-circuit interaction within and outside of the art world.• To explore the creation, and dissolution, of abstractions separating humans from circuitry.• To explore the idea of mechatronic personality and social interaction as a form of performance.
AcknowledgmentsI would like to thank my loving and supportive family which have always believed in my abilities and have given me the freedom to explore what I am passionate about.       Kimby my beautiful, loving, partner, I am so blessed to have you by my side to share this beautiful life with and your unquestioning support and unbounded wisdom has enabled me. Your laugh can end wars.       I want to thank my parents for giving me my tireless worth ethic, sense of moral duty, and love of life.       My mentors, Ajay Kapur and Owen Vallis who have always had my best interest in mind and who have given me the chance to prove myself and my abilities. Who have recognize my talents and pursue what I am passionate about. For being my bosses, relying on me, and respecting my abilities. Without their guidance I would have never been able to soar to such great heights.      I would like to thank all the professors, instructors, and faculty at CalArts who have guided, inspired, and motivated me throughout the past four years. Tom Jennings for helping me to break free from the technology in my art. Sarah Roberts for helping me to start thinking about space, sound, and interaction in new ways. Spencer Salazar, for his calm wisdom. Clay Chaplin for embracing me as one of his own students.      I would like to thank all the friends and colleagues that I have studied, collaborated, and learned with throughout the years. Special thanks to Mason for inspiring me to think in larger scale, and for his respectful grace as an artist and human..  Wolfgang, my dear friend, who is longer with us for his friendship, support, and talks. People who deserve to have their name on this document: John Meagher, Pat Dibert, Keith Bishop, Tessa Bishop, Peter Blasser, Evelina Dominitch, Dimitry Gelfand, Mike Leize, Shaurja Benaurje.Lastly I would like to thank  my cat Newton for beinig the best little buddy!
ContentsAbstract	vAcknowledgments	viiContents	ixList of Figures	xiiiList of Tables	xvChapter 1	Introduction	11.1	Thesis Overview & Outline	3Chapter 2	Background	42.1	Exposing Circuitry	42.1.1	Circuit Bending & Hardware Hacking	42.1.2	Nicholas Collins	52.1.3	Peter Blasser	72.1.4	Andrew McPherson	92.2	Interactive Art and Interaction Design	122.2.1	Interaction Goals	122.2.2	Designing for Hackability	132.3	Tapping into Electromagnetic Systems	132.3.1	Christina Kubisch	142.4	Mechatronic Music	172.4.1	Godfried-Willem Raes	182.4.2	Trimpin	202.4.3	The Machine Lab	22Chapter 3	Human-Circuit Interaction in the Gallery	253.1	Interaction Rail	273.1.1	Electrical Box	273.2	Open Interaction	313.2.1	Cathode Ray Tubes	323.3	Deception	343.3.1	Symbiotic SNES	353.3.2	6 * 9 = 42	363.4	Unwelcoming Spaces	373.4.1	No Humans Allowed	383.5	Non-Interactive	393.5.1	Digital Rain	403.5.2	Computer Music	423.6	Chapter Conclusion	43Chapter 4	Designing Exploratory Interfaces	454.1	Abstractive Deconstruction	464.1.1	Discovery Synth	474.2	Camouflage and Exposure	524.2.1	Retrono	524.3	Re-Appropriation of Conventions	544.3.1	Rotary SNES	544.3.2	Modular SNES	564.4	Deception	604.4.1	Symbiotic SNES	614.4.2	Chroma-Temporal Surveillance Bot	644.5	Removing Agency	674.5.1	EavesDropper	684.6	Orchestrating Circuitry	704.6.1	The Voltage Slammer V1	714.6.2	The Voltage Slammer V2	734.6.3	OneToFour	754.7	Chapter Conclusion	76Chapter 5	Approaches to Human-Robot Performance	775.1	Non-Interactive	785.1.1	Beatles	795.1.2	Hello Humans	805.1.3	Computer Music	835.2	Mechatronic Instruments Played by Humans	845.2.1	Robots Improvisational Jam	855.3	Mechatronic Instrumentalists Led by Humans	855.3.1	Robot Whispers	865.4	Social Interaction as Performance	875.4.1	AntiSocial	875.4.2	Hedonism Bot	885.4.3	No Humans Allowed	905.5	Chapter Conclusion	91Chapter 6	The Pantheon: A System for Mechatronic Art Creation	926.1	Server	926.2	Sensors	936.3	Digital Conductor	946.4	OSC	946.5	Shields	956.5.1	Brigid	966.5.2	Homados	986.5.3	Hermes	996.5.4	Theia	1006.6	Mechatronic Personalities – A Pantheon Project	1006.7	Chapter Conclusion	101Chapter 7	Conclusion	1037.1	Summary	1037.2	Primary Contributions	1047.3	Final Thoughts	104Bibliography	106
List of FiguresFigure 1: Thesis outline.	3Figure 2: Nicolas Collins’ Original Hacking Manual and Handmade Electronic Music.	5Figure 3: Example "Paper Circuit" by Peter Blasser.	8Figure 4: TouchKeys capacitive sensor for augmenting keyboard instruments.	10Figure 5: The D-Box circuit bendable musical instrument.	11Figure 6: Christina Kubisch with one of the listening devices used on her Electrical Walks.	14Figure 7: Map from Kubisch's 2009 Electrical Walk in Milano.	16Figure 8: Mechatronics is a blend of many engineering and computer science disciplines.	17Figure 9: Godfried-Willem Raes with a portion of the Man and Machine robot orchestra.	18Figure 10: Trimpin with Sheng High in 2006.	20Figure 11: Zimoun's 138 prepared dc-motors, cotton balls, cardboard boxes.	21Figure 12: Required interaction for Electrical Box.	28Figure 13: Electrical Box spacial layout when installed in the WaveCave gallery.	29Figure 14: Listening station with two EavesDropper EM listening devices.	30Figure 15: Cathode Ray Tubes installation with three Retrono interfaces.	32Figure 16: Example output from Retrono synthesizer.	33Figure 17: Symbiotic SNES control flow.	35Figure 18: No Humans Allowed as installed in the WaveCave gallery at CalArts.	38Figure 19: Digital Rain as presented at the 2015 Digital Arts Expo.	40Figure 20: Computer Music at the 2016 Digital Arts Expo.	42Figure 21: Discovery Synth musical interface.	46Figure 22: Five of the Discovery Synth's buttons.	48Figure 23: How a potentiometer, or slider , functions.	49Figure 24: Two ways to use a Discovery Synth potentiometer.	50Figure 25: Close up of the Discovery Synth potentiometers.	51Figure 26: Retrono Synthesizer.	52Figure 27: Rotary SNES circuit bent video game console.	54Figure 28:  Rotary SNES's video bends.	55Figure 29: Modular SNES circuit bent video game console.	56Figure 30: Modular SNES with case open.	57Figure 31: Sample bends from the Modular SNES.	58Figure 32: Symbiotic SNES hardware.	61Figure 33: One of two SNES controller inside SSNES unit.	62Figure 34: Sample outputs from Chroma Temporal Surveillance Bot.	64Figure 35: Chroma Temporal Surveillance Bot interface, final design on right.	66Figure 36: EavesDropper magnetic field listening device.	68Figure 37: EavesDropper magnetic flux sonification device with cover removed.	69Figure 38: EavesDropper electrical system diagram.	70Figure 39: The Voltage Slammer (v1) circuit bending probe and sequencer.	71Figure 40: The Voltage Slammer (v1) when viewed from rear.	72Figure 41: The Voltage Slammer (v2) circuit bending probe and sequencer.	73Figure 42: OneToFour installed in a private residence circa 2016.	75Figure 43: Beatles is composed for MalletOTon (top) and Lydia.	79Figure 44: Bot positions in Machine Lab in relation to each other.	81Figure 45: Computer Music as installed at the 2016 Digital Arts Expo.	83Figure 46: Ivy Liu feeding HedonismBot during a performance of Hedonism Bot.	88Figure 47: The Pantheon Server initialization routine.	92Figure 48: Circuit for a single Brigid, or Homados, actuator channel.	97Figure 49: Homados (v2) sixteen channel actuator shield for the Arduino Mega.	98Figure 50: Hermes four channel stepper motor shield for the Arduino Uno.	99Figure 51: Model-A (left) and Model-B (right) mechatronic personalities.	100
List of TablesTable 1: The installations presented in this chapter and their approaches to interaction.	26Table 2: Possible interactions with Retrono interfaces.	34Table 3: Interfaces for challenging human circuit interaction modalities	46Table 4: Technical comparison between Rotary SNES and Modular SNES.	59Table 5: Sampling of basic play modes supported by Symbiotic SNES.	63Table 6: Approaches to mechatronic performance presented in Chapter 5.	78Table 7: Make-up and capabilities of Computer Music ensemble.	84Table 8: How changes in on bots state affects the states of the other bots.	90Chapter 1 
Chapter 1 Introduction      “art becomes interactive when audience participation is an integral part of the artwork. In making interactive art, the artist goes beyond considerations of how the work will look or sound to an observer. The way that it interacts with the audience is also a crucial part of its essence.”       Ernest Edmonds, Professor of Computation and Creative Media at the University of Technology in SydneyIn my daily activities, I am captivated by the authority of the electromagnetic spectrum. I am fascinated by the diverse technology we have developed to harness, control, and leverage the irresistible power of this spectrum. Our social-personal relationships with electricity are complex, dynamic, and a constant topic of examination in my labors. I love analyzing how we, as humans, have constructed interfaces to interact with electrical systems. Over the past four years during my studies at CalArts I have chosen to express these interests through the design of interfaces that challenge our relationships with electricity, by producing performances that assign unconventional responsibilities to robotic performers, and designing hardware interfaces which invite us to rebuild our expectations for interaction.       In 2017, numerous conventions for human-circuit interaction will benefit from questioning, exploration, and discourse. Many of the ways that we interact with electronic devices are based on old standards of expression which were established in the 20th century, or earlier, and are outdated in today’s technological landscape. A good example of this is the QWERTY keyboard layout. This pattern for mapping keys on a keyboard to the letters of the alphabet, and other symbols, originated from the physical limitations of mechanical typewriters. The layout is designed to space the most commonly used keys as far away from each other as physically possible. This serves to slow down the typist, alleviating a tendency of typewriters to jam when two keys are pressed in rapid succession. QWERTY, however, remains the default keyboard layout on millions of new keyboards and laptops sold every year. Despite both the liberation of modern keyboards from the mechanical limitations of their typewriter ancestors and alternate keyboard layouts such as the Dvorak Simplified Keyboard (DSK) which can increase typing speeds while reducing finger movements and repetitive strain injuries, QWERTY remains the keyboard layout most people learn how to type on. [1], [2]      While the consumer sphere is often slow to change, the world of interactive art is agile: constantly redefining the role of the gallery visitor, the artwork, and interaction as a whole.[3] As Professor Edmonds commented in the opening quote, interactive art prioritizes movement and touch along with sight and sound: which usually serve as effect to the interactive element. While sight and sound have traditionally been vitally important in galleries over the centuries, interactive art has added touch to the senses used in the gallery. The old motto of “look but don’t touch” has been transformed in many galleries into “look and please touch” and an open accepting audience is more than happy to play test subject to novel, new interactions.[4] Thus, interactive art is the perfect realm in which to explore the possibilities afforded by employing a fresh look at our relationships with electrical systems.      In the 21st century, it is nearly impossible to avoid digital technology in daily activities, the work discussed in this thesis seeks to open the discussion of not only how we fundamentally interact with these electrical systems, but associatively with everyone and everything in the world around us. The projects presented in this thesis seek to explore the interactive experience through the disciplines of interface design, installation art, and mechatronic music.       1.1  Thesis Overview & OutlineFigure 1: Thesis outline.A background chapter which covers artists and movements that have incepted this body of work is presented to provide a framework for the remainder of the document to build upon. Next, a variety of installations created by the author, each of which champion a unique approach to user interaction in the gallery, are presented in Chapter 3. Chapter 4 introduces interfaces designed while employing varying strategies for both specifically facilitating interaction and broadly challenging the interfaces role in interactive art.   Chapter 5 outlines seven examples of mechatronic and human-mechatronic performance which each explore the varied roles that humans and robots can play in mechatronic music performances.  Chapter 6 then provides an overview of a modular hardware-software system for building mechatronic instruments, sculptures, and installations which is utilized in a number of the projects discussed in earlier chapters and was developed during the author's studies at CalArts.Chapter 2 BackgroundThe installations, performances, and interfaces exhibited in this thesis are indebted to a multitude of contemporary and past individuals, movements, and ideas. This chapter presents a selection of the most influential forces during the creation of the projects introduced in later chapters. This chapter serves to contextualize the work furnished in the later chapters while aiding the reader acclimate themselves to the author’s frame of mind.2.1 Exposing CircuitryContrary to popular convention, many of the interfaces discussed in this thesis seek to unveil electrical systems both physically and functionally1. The impulse to formulate electrical systems which interact directly with the bodies electrical properties has been acted upon by many designers and artists over the years from the Theremin in 1928, to McPherson’s TouchKeys in 2012, and the technology prevalent in touchscreens today. [5]–[8] The early circuit bending technique of “Laying Hands”[9], where the bender licks his fingers and touches random parts of an exposed powered circuit board to quickly determine active areas of the board, has been a mainstay in the tinkerer’s repertoire for decades. 2.1.1 Circuit Bending & Hardware HackingThe circuit bending and hardware hacking communities served as my introduction to both electronics, and interface design, and have continued to influence the approaches I take when engineering interaction. Both circuit bending and hardware hacking are eccentric, punk, anarchistic pastimes which invite us to subvert the manufacturer's intentions and void your warranty.[10] Often these hobbies employ a knowledge-on-demand approach to electronics where one learns enough to be safe, have fun, and produce a working end product. The spirit of fun, play, and exploration with which hackers and benders identify with are coincidently paramount tenets of the artistic process employed in the work submitted in this thesis. 2.1.2 Nicholas CollinsFigure 2: Nicolas Collins’ Original Hacking Manual and Handmade Electronic Music.Nicolas Collins, born 1954 in New York City, is a pioneer in adopting microcomputers in live music performance. Collins takes advantage of hacked and repurposed electronic devices and serves as the father of hardware hacking. Collins received a B.A. and M.A. from Wesleyan University. Collins has participated in over 300 concerts and installations throughout the world as both a solo artist and as a member of various ensembles. In 2006 Nicolas published the book Handmade Electronic Music: The Art of Hardware Hacking which has been instrumental in both my own development as a tech-artist as well as for scores of hackers, artists, and electricians from around the globe. Collins is a renowned curator for performance and installation art holding positions at institutions including the Studio for Electro Instrumental Music (STEIM) and the Leonardo Music Journal where Collins became Editor in Chief beginning with their eighth volume in 1998. A year later in 1999 Collins began teaching at the School of the Art Institute of Chicago (SAIC) where here he is currently a professor and chair for the sound department. [10], [11]	In 2002, while teaching a class on electronic art at the Art Institute of Chicago Collins began compiling a .pdf full of information about basic electronics, along with example projects (assignments), for his students to download and use as reference. Although the file was only intended for use by his students, it soon leaked onto the internet and spread like wildfire becoming known as The Original Hacking Manual. Surprised by the success of the class handout and somewhat embarrassed by the quality of his hand drawn circuits, Collins set out to turn the themes of The Original Hacking Manual into a proper book. Handmade Electronic Music was first published in 2006 and again, with revisions, in 2009. The 2009 printing of Handmade Electronic Music along with the PDF The Original Hacking Manual, are collectively the most influential texts in the development of my interest in electronic art. While circuit bending taught me to become comfortable with exploring electronic circuits, the projects in Collins’ texts empowered me to build my own devices from scratch: to invent. The chapters in Handmade Electronic Music explain how to replicate the project, how it operates, why it functions as it does, and even muses to possible extensions to the underlying concepts. It tells you why everything behaves how it behaves while not dumbing down the tech when it is important. The book even introduces artists, and their creations, which are relevant to the topics of each section. My experience with these texts was one of excitement: for the next thing I would learn, about being an artist, and exploring the field. The ideas, projects, and concepts introduced in these texts are simple and that is what makes them so powerful: they showed the power of a little technical knowledge mixed with a lot of creativity. [12], [13]2.1.3 Peter BlasserFigure : Peter Blasser tuning his rollable synthesizer before a performance.Peter Blasser graduated from the Oberlin College and Conservatory with a degree in electronic music and Chinese, with minors in computer science and ancient Greek, where he briefly taught electronic music and throat singing. In 2001 Blasser apprenticed with Don Buchla while honing his unique approach to synthesizer design. Blasser is an accomplished performer who has toured with various groups across the USA, usually performing with instruments he built. In 2013 Blasser returned to school, this time studying at Wesleyan University, a small liberal arts college in Middletown, Connecticut where he graduated with a Masters in Arts under the advisement of Ron Kuivila in 2015. Blasser currently operates the online company ciat-lonbarde.net which sells electronic instruments Peter designs and builds. Blasser enjoys the role of mentor, and instructor, and often holds workshops and lectures about his work. [14]–[16]      For several years, Blasser developed synthesizers under the notion of “inner surface” which involves creating instruments that can produce sound on an exposed interior surface. These instruments involve unprotected circuits which performers are able to touch to directly affect the sounds produced. After his work with inner surface, Peter went on to develop “synthesis clothing” and “Paper Circuits” the latter of which he still develops. [17], [18]      Blasser’s paper circuits, point-to-point soldering, and capacitive interfaces are stunningly creative, unique, and functional. Peter creates novel, fun ways to build relationships with electronic devices through his designs which subtly question the rigidity of electrical engineering. For example, approximately one third of the component values in his schematics are left to the discretion of the builder providing a range of values that could be used instead of a singular value. Blasser does this so each instrument is unique and that the creator of the instrument has a stronger personal bond to the instrument. The closer you look at a Blasser schematic the more you notice Peter’s quirky terminology: including “harry caps” and “X” resistors. His circuits are intentionally unstable and unpredictable while being both reactive and generative. His electronic diagrams are hand-drawn and often use his own symbols in place of industry conventions which he develops according to the electronic effect the component has on the sonic output of the device. This makes it easier for one to transverse the functionality of the circuitry, while imbuing a sense of wonder and exploration when building one of his projects.Figure 3: Example "Paper Circuit" by Peter Blasser.      In a world dominated by rigid rules and equations, it is refreshing to embrace Blasser’s unique approach to circuit design which I was exposed to during a CalArts workshop with Peter in 2015. Talking to Blasser about his approach to circuit design while building one of his Old Mr. Grassi synthesizers was instrumental in the development of several of the projects tendered in this document. During that week, Peter instilled in me the importance of building a relationship with electronics. Blasser’s own work does this by both maximizing the amount of personality each of his creations have and ensuring that no two devices are identical. Additionally, the workshop experience helped me figure out ways to apply circuit bending techniques and approaches, which rely on a starting object to modify, to the origination of new interfaces which are not built from the dissection, augmentation, or modification of a preexisting electrical system. Peter’s instruments are intended to be touched and felt relying on our bodies’ electrical properties to function: creating a symbiotic relationship between the instrument and musician.2.1.4 Andrew McPhersonAndrew McPherson is at the forefront of the augmented musical instrument revolution and is an academic powerhouse. Andrew McPherson started his academic career at the Massachusetts Institute of Technology with dual majors in music and electrical engineering where he continued his graduate studies completing a masters degree in engineering. In 2009, Andrew completed his Ph.D. in music composition at the University of Pennsylvania. After his Ph.D. studies, Andrew worked for two years as a postdoctoral researcher at Drexel University in the Music Entertainment Technology laboratory. In 2011, McPherson began work at the Augmented Instruments Laboratory, a research sub-group within the Centre for Digital Music (C4DM) at Queen Mary University of London (QMUL), where he mentors a group of Ph.D. students in developing new instruments, and interfaces, for creative musical expression. McPherson holds the position of Senior Lecturer in Digital Media in the QMUL School of Electronic Engineering and Computer Science. Everything that McPherson has produced in his graduate studies and beyond is worth attention, but there are two specific projects that are of particular importance to the topics discussed in this thesis due to their approach to interaction:  TouchKeys and D-Box. [19], [20]2.1.4.1 TouchKeysFigure 4: TouchKeys capacitive sensor for augmenting keyboard instruments.The majority of McPhersons work in the field of instrument design is focused around the creation of augmented instruments, in particular the Magnetic Resonator Piano, which he defines as “a traditional instrument whose capabilities have been electronically extended through new sensors, new types of sound production or new modes of interaction.”[21], [22] This philosophy is mirrored in McPhersons modified Moog PianoBar which is capable of reading continuous key positions of the host device, which can be any full-sized piano-type keyboard instrument. [22], [23] Another portable augmentation for the piano is the TouchKeys interface, which McPherson also invented. TouchKeys is a set of touch sensors that is attached to the tops of the keys of a full-size keyboard instrument such as a piano or organ. They augment the host instruments capabilities by providing data about where the player’s fingers come into contact with the keys as they play (Figure 4). TouchKeys leverage the bodies’ inherent electrical properties to detect not only the location of fingers on the keys but additionally the surface area of each finger in contact with the key. [7], [24], [25] While the fidelity of TouchKeys is indisputably impressive and its compositional implications are profound, it is how the device leverages the electrical properties of our biology that enchanted me to begin work on many of the devices and installations introduced in later chapters. Additionally, the portability of both the TouchKeys and PianoBar proved inspirational when designing interfaces such as Symbiotic SNES introduced in section 3.3.1 which expand upon the idea of portability in device augmentation.2.1.4.2 D-BoxFigure 5: The D-Box circuit bendable musical instrument.The D-Box, created by McPherson in collaboration with Victor Zappi a colleague at the University of British Columbia in Vancouver, is not an augmentation of any preexisting instrument but is instead an entirely new instrument which struggles for comparison. The D-Box is conceived from the ground up to be circuit bent by its user and function as an electrical sandbox for new music creation.  The personal watermelon sized box includes many features to provide an easy, portable, and engaging circuit bending experience. It provides easily-removable panels providing quick access to a breadboard that houses electric components which affect the synthesis engine running on a Beaglebone Black. The fixed sides house Force Sensitive Resistors (FSRs), and a speaker.  By designing for circuit bending and experimentation from the onset, D-Box is capable of a considerably larger range of sounds and behaviors than any circuit bent instrument could hope to embody alone. Aside from its sonic capabilities, what is provocative is the D-Box’s expected mode of interaction: hacking. [26]–[28]2.2 Interactive Art and Interaction DesignComputers and electronic devices have facilitated the rise of new art forms such as Internet Art, Digital Art, Glitch Art, and Interactive Art and has forever changed the workflow of many conventional artists including painters, photographers, sculptors, architects, and others.[4], [29]–[31] This creates a problem for any artist working in the digital realm as Walter Benjamin observes in the seminal essay The Work of Art in the Age of Mechanical Reproduction. Benjamin argues that art of the past, such as painting or sculpture, possessed an “aura” that is lacking in mass-produced art. Walter used the camera as an example. He challenged that if any number of prints can easily be reproduced, where lies the art? [32] One approach for addressing this issue has been for artists to focus on the production of art. With interactive installation art the artists are able to ensure that each participant has a unique experience with the installation. The uniqueness and personalized experience becomes the art in installation art; the art does not lie in an artifact, but instead in the experience. While this thesis delivers installations, interfaces, and performances there is only a singular art form that the artist works with: experience.2.2.1 Interaction GoalsMany of the techniques applied to interface design in this corpus follow traditional tenets of interface design which according to Gillian Crampton Smith, the director of the Interaction Design Institute Ivrea, consists of:● Reassuring Feedback – you know you are doing something when it’s being done.● Navigability – your ability to keep track of location in the system and how to get where you are going.● Consistency – a command in one part of the system will have uniform effect as in all other parts of the system.These tenets are to facilitate what Smith describes as “Intuitive Interaction” which are exchanges that minimize the conscious thought needed to operate the system.  These principles make good sense for devices including computers, automobiles, televisions, and phones as well as some of the installations introduced in later chapters, such as 6 * 9 = 42 and Electrical Box.      But, this is not always the case, and many of the hardware interfaces formed under the scope of this thesis are created with disparate goals. For these projects, the interfaces are the Art, should not be transparent, and often do not exhibit the traits of intuitive interaction. Devices such as the Symbiotic SNES and the Retrono, for instance, are designed in direct opposition to those priorities in an attempt to either force a reexamination of our expectations for interaction or implicitly draw attention to the interface: instead of simply being concerned with the results of its actions.2.2.2 Designing for HackabilityAmong the approaches used when designing and building the interfaces revealed in later chapters is “Designing for Hackability” as proposed in the 2004 international conferences Designing Interactive Systems (DIS) by Anne Galloway, Jonah Brucker-Cohen, Lalya Gaye, Elizabeth Goodman, and Dan Hill in the paper with the same name. Interfaces that are designed for Hackability are customizable: allowing the user to turn them into the device they want them to be. Hackable interfaces cultivate reciprocity between the designers, users, and the device itself while embracing unanticipated usage with both transparency and robustness in construction.[33] In the current age of hyper-normalization and increased technological literacy, a revitalized consumer desire for individuality and personalization is emerging and hackable design is increasingly common. McPherson and Zappi’s D-Box, as well as Peter Blassers Paper Circuits and inner surface creations, introduced earlier in this section are all examples of projects which are designed for hackability along with select projects introduced in later chapters such as the Discovery Synth2 and Modular SNES3. 2.3 Tapping into Electromagnetic SystemsHardware hacking and circuit bending are both inherently violent activities that tend to mutilate the original device: altering its capabilities, interactions, and even purpose. While that method is exemplified in several works presented in later chapters, and is a valid approach, not all profit from those methods. A source of provocation and the catalyst for many projects is Christina Kubisch’s work as an installation artist. Christiana’s installations empower visitors to listen to electronic circuitry with her custom magnetic flux sonification headphones. The headphones enact their magic from afar without any violence, obtrusiveness, or even physical contact and are a direct departure from the exchanges typical with circuit bent devices. Her interactions are introverted yet exploratory, covert and empowering.2.3.1 Christina KubischFigure 6: Christina Kubisch with one of the listening devices used on her Electrical Walks.Christina Kubisch (b 1948) studied electronic music at the Milan Conservatory of Music. She quickly became unsatisfied with the conventionality of the conservatories curriculum and decided to enroll in the Technical University in Milan to take supplementary classes in electronics. In her own process of opportunistic design, as described in an interview for cabinet magazine, Christina stumbled upon what has become known as the Electrical Walks:“One day I bought a telephone amplifier, a little cube that you could put next to your telephone so that you could hear it without having the receiver in your hand. The cube was switched on, and when I came into the laboratory, it started to make really strange sounds in my handbag. I took it out and asked my professor what was going on. He explained to me that there were coils in this little cube, and that they picked up some of the machines in the room. It was like a flash in my mind. It was exactly at the time when I wanted to get away from performance and start producing installations.”She goes on to explain how her excitement over the technology commanded her installation configurations.“In my early installations, there were people wandering around with these little cubes in their hands, walking along thick electrical cables that had sounds running through them. I didn’t think about using the sounds of the outside world. I had no idea about electricity in general or that it could make interesting sounds. I just used the system of electromagnetic induction as a way of amplifying musical sounds.”After five years of searching for collaborators, she started working with an Italian headphone manufacturing company and commissioned twenty custom headphones with her electromagnetic snooping technology installed inside of large soviet headphones. She made several installations showcasing the custom headphones but eventually the set deteriorated and the project was put on hold. Almost a decade later, she found a sponsor which helped develop the technology to create an improved system. In 1999, at the Potsdamer Platz4 in Berlin, the new system is used for the first time in the installation Forty Pillars and One Room located in a large parking garage. She wrapped lengths of cables covered in green phosphorescent paint around forty of the free standing pillars in the parking garage creating the trunks of trees as seen from underground. Each of the pillars emitted a peculiar sequence of tones: with all of them sharing the common theme of water. The participants particular sonic experience is dependent on their position within the space and the specific time of day. Forty Pillars and One Room interestingly uses electricity and concrete to create a world of implied nature. Christina created a sonic landscape in direct juxtaposition to the electrical and industrial materials she used for construction. [34]–[37]Figure 7: Map from Kubisch's 2009 Electrical Walk in Milano.      In 2004, Kubisch officially began exhibiting works which used the EM listening devices in public locations under the umbrella name of Electrical Walks. Christina used the term “electrical walk” to describe the action of exploring a space’s EM properties by means of EM listening: just as one might go on a nature walk and listen for bird calls. For her, the Electrical Walks are not only for other people to enjoy, but are activities she enjoys doing for herself. The Electrical Walks, although closely related to her previous work with the listening devices, feature divergent source material and interactions than seen in her past work. Instead of planting composed electromagnetic signals in wiring that people listen to with her devices, Electrical Walks delegates the creation of sonic content to the environment. When researching a new walk, Kubisch embarks into an (usually) urban center with an EM listening device. She walks around the city and maps the magnetic activity. She uses the master map to create tours showing areas of sonic interest with routes that tour the cities magnetic features. The public receives copies of the routes along with her custom magnetic field listeners and are sent off to explore the environment at their own pace.       Christina Kubisch is of importance to the author's work because of her approach for creating unique experiences for her gallery viewers. This has influenced the interactions and experiences crafted by the work supplied in later chapters. Her carefully distilled and delicate treatment of technology and the electromagnetic spectrum has informed the design approach for simplicity and elegance seen in interfaces such as the EavesDroppers, Chroma-Temporal Surveillance Bot, and Rotary SNES introduced in Chapter 4. Kubisch’s work formulates intimate experiences that can be shared by many people at the same time. Technology is at the core of her work and is necessary to tell the narrative and impart the experience she is attempting to enforce. This reliance is not emphasized, instead, her installations abstain from telling the interactee about the wonders at hand and simply gives them enough information to navigate the worlds she reveals. 2.4 Mechatronic MusicFigure 8: Mechatronics is a blend of many engineering and computer science disciplines.Mechatronics is an interdisciplinary field which blends electrical engineering, computer science, control engineering, telecommunications engineering, systems engineering, and mechanical engineering to create a wide variety of electro-mechanical systems from self-driving cars to robotic butlers. The field of mechatronic music is concerned with the musical implications of mechatronic systems within the context of human-robot musical performance. [38], [39] The fields of mechatronics is relevant as many of the installations, and a majority of the performances, introduced in this paper either utilize preexisting mechatronic instruments, are concerned with the creation of new mechatronic instruments, or involve music composed for mechatronic performers. This section aims to introduce the three most important influences from the field of mechatronic music to the work presented in later chapters. The remainder of this section introduces Godfried-Willem Raes, Trimpin, and The Machine Lab in chronological order.2.4.1 Godfried-Willem Raes Figure 9: Godfried-Willem Raes with a portion of the Man and Machine robot orchestra.Godfried-Willem Raes, born 1952 in Ghent, Belgium, is the mastermind behind the Man and Machine orchestra at the Logos Foundation, founded in 1968, where he proceeds over about 150 new music concerts a year.[40], [41]  In 1968/69 Raes co-founded the Logos Ensemble5 while about a year later, in 1970, Raes began performing with the Logos Duo in collaboration with Moniek Darge. In 1973, Raes began acting as programmer for the Philharmonic Society at the Palais des Beaux Arts in Brussels where he held the position until 1988. In 1990, Rae’s commitment to mechatronic instrument creation, and composition, lead to the founding of the Man and Machine Orchestra which currently boasts over forty-five wind, string, percussion, and noise-generation instruments and is one of the oldest robotic orchestras in the world.       Raes’ careful documentation and clean, refined method are an inspiration to how I try to conduct my own research. Raes, his students, and collaborators do a thorough job documenting the process of design and construction of many of the instruments that make up the Man and Machine orchestra. Raes takes meticulous notes on what is accomplished for the given project on each day it is worked on. The foundation freely publishes the information along with pictures of the work in progress on the Logos Foundation’s website. These valuable notes even contain information about what books and websites are used to research various bits of information no matter how minor the detail. These notes serve not only as an invaluable guide to discerning how the individual instrument is structured, but additionally provides insight into the overarching process that Raes and the Logos Foundation employs when creating new mechatronic instruments and performances.      In 1990, with the construction of Autosax, Raes championed the Logos Foundation into a new era, where the foundation shifted its focus away from of the design and use of analog and electronic hybrid sound generating devices and onto the creation of musical robots. Over years performing with purely electronic synthesizers, Raes became convinced that loudspeaker reproductions of sounds are nothing more than a virtualized reality of acoustic sound. He started building new mechatronic instruments and started writing compositions which take advantage of both the extra-human capabilities of the robotics and the liberties afforded onto human instrumentalists when they are able to interact with their instrument in unconventional manners.  This has developed into extensive research into the adoption of gesture recognition to interface with the robots of the orchestra. [42]–[44] The instruments that constitute the Man and Machine orchestra are beautiful, unique, and inspirational but it is Raes explorations into the roles of humans and robots in shared performance spaces which is of paramount importance to the pieces introduced in this document, specifically in the fifth chapter. 2.4.2 TrimpinFigure 10: Trimpin with Sheng High in 2006.Trimpin, born 1951 in Germany to a father who played wind instruments, is a kinesthetic sculptor, mechatronic inventor, and installation artist based out of Seattle, Washington. Trimpin played wind instruments before developing an allergy to brass after which he began experimenting with modifying electronic devices. In 1980, after studying at the University of Berlin and showcasing installations in Germany, Trimpin moved to America in pursuit of old, used electronic components, which he found difficult to find in Europe. Using repurposed materials, Trimpin currently works creating large-scale sound art in galleries and public spaces throughout the world. [45]      Trimpin often employs the tactic of building multiples of a single object that are parallel yet contrasting. This is used to great effect in installations such as Klompen (1990), which features 96 wooden clogs; and Sheng High (2006), shown with Trimpin in Figure 10, which calls upon thirty bamboo pipes to produce more than a two octave range of tones. In both Klompen and Sheng High each one of the similar objects serves to produce a unique note that is vital to realizing the compositions the installation plays. This is a different approach from those taken by artists such as Zimoun (Figure 11), whose installations employ flocks of identical objects who’s emergent complexity is due to sheer numbers and not differences between the objects. For instance, in Trimpin’s installation Sheng High each of the thirty bamboo pipes are tuned to a distinctive pitch. Pattern on the wall created from old, broken CD-ROMs serve as a graphic score which plays back a composition using the pipes. If one of the units is removed, the composition is severely compromised. Trimpin approaches his installations both as a visual artist and as a composer, a philosophy implemented in several of the installations introduced in Chapter 3. [46]Figure 11: Zimoun's 138 prepared dc-motors, cotton balls, cardboard boxes.      Just like Godfried-Willem Raes, an idea Trimpin is adamant about is the inherent power of acoustic sound over its loudspeaker counterpoint. Trimpin, along with many of his disciples [47], are adamant that speakers are inadequate at reproducing the experience of the original sound. This sentiment is a tenet in many mechatronic ensembles which tend to only feature mechanically actuated sonic content. Although the work in later chapters often does follow this approach, there are projects, namely Computer Music, which attempt to utilize only the electro-mechanical artifacts of the mechatronic instruments to create the soundscape.      Throughout his impactful career, Trimpin has maintained humble and willing to teach the wonders of mechanical art to anyone with interest. This I learned firsthand over the years at CalArts as Trimpin has served as a deeply valued mentor on several of the projects described in the following chapters. 2.4.3 The Machine LabFigure 12: The Machine Orchestra on stage at the Walt Disney Music Hall.The CalArts Machine Lab is the hub of the Music Technology department as well as the Digital Arts Minor and functions as the technological core of the institute. The Machine Lab is home to the nine mechatronic instruments that make up the Machine Orchestra which consists of a mixed ensemble of human and robotic performers which combines the musical elements of a laptop ensemble with the acoustic affordances of traditional instruments.       Nine mechatronic musical instruments inhabit the Machine Lab at CalArts. BreakBot is a hanging percussion instrument that features a kick drum, a crash cymbal, and a snare6 . Spread throughout the entire room, hidden in the ceiling grid, are twenty Clappers: each consisting of a single solenoid, with a blue LED inside of a ping-pong ball. MalletOTon is a mechatronic marimba that features 48 rotary solenoid actuated rubber headed mallets striking its keys [48]. StringThing is made up of three steel strings picked by DC motors with plectrum mechanisms as well as steel post dampener mechanisms activated by solenoids. RattleTron is a percussion instrument that includes an assortment of hand percussion instruments along with three pipes struck with solenoids. MahaDeviBot is an Indian percussion robot that consists of a total of twelve solenoid actuators that strike frame drums, gongs, bells, wood blocks, and finger cymbals. GanaPatiBot is a percussion robot that features five plastic drums of various sizes each with multiple solenoid powered beaters. Lydia is a standup piano with twenty solenoids that strike the strings percussively, sixteen DC motors which ring the strings via custom rubber strikers, and a hacksaw which saws through a large steel bolt at the base of the instrument.  JackBox is both a percussion and string instrument which features twelve guitar and bass strings, three cymbals, eleven German beer glasses, an eight key xylophone, and three plastic drums which are all activated using dozens of solenoids7. Tammy consists of six brass bells struck with steel posts and six custom cut wooden keys directly actuated by solenoid plungers. [49]–[53]      By way of my undergraduate and graduate studies with the Music Technology program at CalArts, the Machine Orchestra served as my introduction into the worlds of mechatronic music performance.  Over the past four years, I have gotten to know the multifarious instruments in the Machine Lab through hours spent repairing, maintaining, upgrading, and composing for them. My experiences caring for these robots shape the adjunctions made when designing my own mechatronic instruments and installations. 

Chapter 3 Human-Circuit Interaction in the GalleryIn this chapter, several of the authors installations are described in terms of their approach to human-circuit interplay in the gallery (Table 1). The first section, Interaction Rail, introduces the installation Electrical Box which guides participants through an electromagnetic eavesdropping expedition with minimal guidance. Next, Open Interaction presents the installation Cathode Ray Tubes which creates an inclusive interaction environment which strives to be open, flexible, and complex. The Deception section bestows two interfaces: Symbiotic SNES, a project that reinterprets familiar games, and their interfaces, through the manipulation of control messages; and 6 * 9 = 42, a project that implements a program which misuses data to publically label users without their knowledge. Next, the Unwelcoming Spaces section tenders the installation No Humans Allowed which creates a hostile environment that discourages interaction from visitors. This chapter concludes with the Non-Interactive section where Computer Music and Digital Rain are the featured installations where interactivity is nonexistent.Installation NameInterfaceType of Gallery InteractionApproach to Human-Circuit InteractionElectrical BoxEavesDropperInteraction rail, linearObservational, extension of bodyCathode Ray Tubes		RetronoOpen, branching, non-linearDirect contactSymbiotic SNESSymbiotic SNESGame, deceptionRe-appropriated6 * 9 = 42Chrome Temporal Surveillance BotOpen, branching, non-linear, deceptionTypical, sinisterNo Humans AllowedNoneUnwelcoming environment, presence discouragedObservational, frictionDigital RainNoneNoneObservationalComputer MusicNoneNoneObservationalTable 1: The installations presented in this chapter and their approaches to interaction.3.1 Interaction RailThe terminology “Interaction Rail” is used by the author to describe situations where an interactee encounters multiple interactions which must be executed in a specific order without the option for deviation. The term is inspired by on-rail video games. In video game design, a game is considered to be “on-rail” if the manner the player travels is pre-determined on a line, as if literally on rails. This originally was done to allow for the use of high production backgrounds and higher quality pre-rendered graphics. When a video game is designed on-rail the designers do not have to commit resources to creating vast open levels and can focus on presenting less content that is of higher artistic quality. This approach to game design still persists today mostly as a stylistic choice instead of a technical necessity.8[54] An example of an interaction rail, outside the context of gallery art, or video games, is the financial transactions that use a credit card chip-reader. In order to pay for the goods, the customer must complete the interaction rail in order:1. Insert credit card into chip-reader2. Confirm that the amount is ok3. Sign for the purchase4. Remove the credit card from the chip-readerIf the customer skips one of these steps or attempts to perform any step out of order, for instance by removing the credit card from the chip-reading before signing for the purchase, the transaction is rendered void.       Unsurprisingly, with installations that use these configurations, it can be difficult to ensure the attendee completes all interactions in order. Thus, installations that exhibit this structure are burdened with guiding the visitors along the rail, usually while affording minimal confusion and discomfort onto the interactee. This can be easier to accomplish by closely guiding the participant with written, or implicit symbolic, guidance. The installation introduced in this section, however, instead attempts to guide subjects while avoiding the use of explicit written or symbolic directions. The installation sheds the responsibility of explaining itself to the visitor, allowing the installation to impart a spirit of discovery and exploration to its guests. 3.1.1 Electrical BoxFigure: Electrical Box as seen in the WaveCave gallery from September 9th through September 19th, 2016.Electrical Box offers a silent room ordained with over one-thousand feet of instrument cables hanging from the CalArts WaveCave gallery’s ceiling rigging grid. Small, Light Emitting Diodes (LEDs) flicker at the ends of the cables suspended around the room. Several pairs of headphones hang in the far corners of the gallery. After walking to one of the corners of the gallery and equipping themselves with a pair of headphones, and the accompanying small metal tin, participants can hear faint static.  As they explore the room, radio broadcasts can be heard emanating from the cables. The tins, or EavesDroppers, empower visitors with the ability to sonically explore the electromagnetic energy hidden within the cables hanging in the chamber.3.1.1.1 Approach to InteractionFigure 12: Required interaction for Electrical Box.Electrical Box guides visitors through a singular interaction rail (Figure 12) while providing minimal direction to the visitor. In an attempt to avoid granting explicit written or symbolic instructions for how to interact with the installation, subtler methods were used to encourage viewers to stay on rail. This included minimal signage, the acute placement of open space, lighting, and strategic interface design.      The signage for Electrical Box functions as clues for visitors to uncover steps in the interaction rail. A simple sign outside of the gallery only discloses the name of the installation and that the installation is “electro-magnetic” and “interactive”. The information disclosed on the sign is essential for helping visitors decouple the space’s expectations. Electro-magnetic hints at the technology implemented while hopefully promoting an aura of danger and scientific adventure. The word interactive informs the visitor of the participatory nature of the installation; helping to ease them into a mindset of an active participant - assisting in steps II, III and IV. Figure 13: Electrical Box spacial layout when installed in the WaveCave gallery.      Although the installation utilizes over one-thousand feet of cable, 35% of the gallery is designated as free space: void of cables, EavesDroppers, or any other clutter. The free space takes two forms: the walkways, or boarders, and the listening posts. The outside rows and columns of the grid, the frame, is left void of cables with the exceptions of the corners which house the EavesDroppers (Figure 13). The frame encourages viewers to enter into the space, approach the headphones, and to explore the room and functions as a walkway around the installation - assisting with steps I, II and V. This helps guide viewers through the interaction rail while softening the transition into the gallery by allowing intermediate commitment to the space.  In addition to the frame, EB harbors nine listening ports which are also void of cables. The listening posts allow visitors to easily sample a variety of signals un-harassed by hanging cables - assisting with step V. Figure 14: Listening station with two EavesDropper EM listening devices.3.1.1.2 Lighting"A painter should begin every canvas with a wash of black, because all things in nature are dark except where exposed by the light."  -- Leonardo da Vinci“I will love the light for it shows me the way, yet I will endure the darkness for it shows me the stars.” -- Og MandinoAs Mandino and da Vinci foreshadow, EB embraces the darkness while using light sparingly as a tool to show folks the way by guiding interaction. EB has three sources of light that participants are exposed to inside the installation space: the cable LEDs, the door light, and the flood-lights. This section discusses how each of these luminance sources are leveraged to guide the viewer to the interaction rail.      At the terminus of each of the cables are white LEDs which echo the audio signal being transmitted through the cables. These LEDs are the primary visual draw to most visitors due to their flickering, and relative brightness, in the dim room. As indicated in Figure 13, seven LEDs are concentrated in the rear of the installation followed by a single row with no light before the remaining nine LEDs are distributed through the remaining space. The rear formation fabricates a visual focal point which encourages visitors not only to enter into the space but to explore it - assisting with steps I and II.       As the installation is relatively dark when compared to the hallway outside, when the gallery doors are opened, the space is flooded with outside luminescence brighter than any source of light found within the room. The large, heavy glass doors of the WaveCave gallery take upwards of eight seconds to close creating a distinctive transition time into the gallery. This eases the guests descent into relative darkness, hopefully smoothing the transition by helping the eyes to adjust and simply giving the visitor time to acclimate to the new environment without being fully committed to the space.       The final source of light in EB originates from two dim spotlights which are directed on the headphones and EavesDroppers resting on glass shelves in the far corners of the gallery. The spotlights are not bright enough to drastically change the overall ambience of the space, but do provide enough illumination to focus attention on the headphones - assisting with steps II and III.3.2 Open InteractionThe installation, Cathode Ray Tubes, presented in this section provides multiple ways users can affect the system while refraining from establishing a hierarchy of value over the varied interaction options. It employs a non-linear interaction structure, in direct opposition to the interaction rail discussed in section 3.1 above, which strives to present all possible interactions to visitors at all times. This approach seeks to construct a rewarding experience for both participants that are willing to fully explore the capabilities of the space, in addition to wallflowers which are uncomfortable touching things in front of strangers in an art gallery. 3.2.1 Cathode Ray Tubes Figure 15: Cathode Ray Tubes installation with three Retrono interfaces.Cathode Ray Tubes builds a feedback loop out of four cathode ray tube (CRT) televisions (TVs) and four Retrono synthesizers: modern knock-offs of the Nintendo Entertainment System (NES) video game consoles which have been slightly modified.  The Retrono interfaces are sensitive to changes in the electromagnetic field surrounding them resulting in a vulnerability to the presence of human bodies. The Retronos, with no game cartridge inserted, produce the varied and evolving visuals seen in Figure 16. Each of the CRT TVs which the Retronos are placed in front of, create a strong electro-magnetic field which acts as an input stimulus to keep its corresponding Retrono in an active state of flux. Changes in the visual output of the TVs result in corresponding modulations in the EM field surrounding the units affecting the audio and visual outputs. This feedback loop between the Retrono and its TV generates an electrical system with numerous interactions while refraining from showing favor over one interaction over another. The goal of the technology is to create a reactive system which passively encourages folks to participate in whatever manner they are comfortable with.      Cathode Ray Tubes was initially exhibited in the WaveCave gallery at CalArts in Valencia, California from April 5th, 2016 through April 11th, 2016. Subsequently, the installation has been shown at the 2016 Digital Arts Expo and was installed in the Kadenze Inc. corporate headquarters in Valencia, California from May 2016 through June 2017.3.2.1.1 Interaction DesignFigure 16: Example output from Retrono synthesizer.The experience of interacting with Cathode Ray Tubes is envisioned to be ripe with discovery, creating no rules to force, or limit, any type of interaction between the technology and gallery visitors. The video and audio synthesized by the Retrono devices can be effected by gallery goers in many distinct ways. For the installation, the desired interaction is both none and all of the options proposed in Table 2 below. What is important, and the primary goal of the installation, is that the viewer discovers their own unique relationship with the space. It is preferable that visitors are able to forge a personal backstory and explanation of the space over them acting in a particular manner or doing any specific thing. InteractionCommitmentEffect SeverityExample ResultNoneNoneBaselineOutput slowly oscillates as the feedback loop is the only source of inputStand within 3’ of unitMildMildThe unit will visually react to your presenceWave hand over RetronoMediumMediumThe unit will immediately visually and sonically react to your presence immediatelyTouch TVFullMediumThe static charge on the TV will discharge, providing a spike to the system before temporarily reducing the effects of the feedback loopTouch a RetronoFullMedium-MajorThe unit will immediately visually and sonically react to your presence. You will have more control over the effectTouch multiple Retronos at onceTotalMajor-ExtremeBoth units will immediately visually and sonically react to your presenceMove Retrono interfaceTotalMajorChanges the sensitivity of the feedback loopUse foreign objectFullMild-ExtremeDepends on the construction of the objectTable 2: Possible interactions with Retrono interfaces.3.3 DeceptionUsually when creating interactive installation art, one of the fundamental tenets is to facilitate scenarios that are reactive to the interactee’s actions. If a guest pulls a lever, pushes a button or somehow interacts with the installation, it is traditionally desirable the visitor understands how their actions affect the installation or why they have no effect. In the book Windows and Mirrors, Bolter and Gromala referred to this quality in interaction design as “transparency” while Gillian Smith, as introduced in section 2.2.1, called it “reassuring feedback”. [3] No matter the term preferred, both texts introduce this trait as a desirable attribute when designing an interaction scenario. This section, however, seeks to explore deception through opaque interaction design by releasing the design process from concerns over providing transparency to the user.      Deceptive art, art that intends to deceive its primary audience9, is  relatively uncommon in the art world and usually takes the form of optical illusions, or visual trickery[55]. This scarcity motivated the creation of two installations, demonstrated in this section, which deceive their participants using divergent tactics. Symbiotic SNES supplies a familiar interface, a SNES controller, that behaves in unexpected ways while 6 * 9 = 42 presents a seemingly innocent visual sandbox to visitors while obscuring its true motives from the implicated party.3.3.1 Symbiotic SNESFigure 17: Symbiotic SNES control flow.Symbiotic SNES (SSNES) is an interactive installation in which two visitors are able to cooperatively play the video game Super Mario World, on a Super Nintendo Entertainment System (SNES), in a novel manner. Two unmodified SNES controllers are connected to the SSNES device which is then plugged into an unmodified SNES console as seen in Figure 17. When participants play the familiar video game the subversive nature of the SSNES reveals itself. The SSNES device forces the two players to jointly control a single character by intercepting controller messages from the controllers and only allowing button presses that occur on both controllers, at the same time, to pass to the console10. This approach to multiplayer gaming is in contrast to the typical cooperative gaming experience where players either take turns playing the same character, or everyone controls their own separate avatar.       The SSNES system hopes to grant its players the experience of playing one of their favorite childhood games in a new way that makes them fall in love with the game all over again. The deceptive effect is most pronounced when the user is familiar with both the game and how to play the game. The installation could have easily been realized on any 16-bit era, or earlier, video game console. The SNES’s cultural familiarity and popularity is unmatched by the Sega Genesis, Neo Geo or TurboGrafx-16 or any other console from its era. [56]–[58] But besides being the most popular video game console of the 16-bit era, the SNES has one of the most iconic controllers of all time which is still easy to understand for those who have never used one before. [57][58] Unlike, for instance, the SEGA Genesis controller which was designed with a single row of three buttons on the right side, the SNES controller’s four front buttons in two rows of two is still the conventional button configuration on the right side of modern controllers such as the Dualshock-4, Steam, and X-Box One. The final argument for choosing the SNES console to host the Symbiotic system resides in the adamant SNES fan base which is still producing brand new titles for the console almost thirty years after its release. [59] SEGA is no longer a company that builds video game consoles and their absence from the current industry has dwindled the fan base which now pales in comparison to the throngs of fans for retro Nintendo video games.       Because the SSNES’s deception is dependent on the user’s firm expectations for how their controller will behave, it is important SSNES uses an iconic SNES game with an adamant fan base. There have been dozens of highly successful games released for the SNES that would have worked but none as effectively as Super Mario World. Super Mario World, released in 1990 and selling over 20 million copies worldwide, was a pack-in launch title for the SNES that was sold along with brand new consoles to millions of people worldwide. For these consumers, Super Mario World is the first game they ever played on the SNES and often holds a vivid place in their memory of that gaming era. Super Mario World was engendered by a superstar team, directed by Takashi Tezuka and produced by Shigeru Miyamoto, features simple intuitive controls, is fun to play, and continues to be on lists of the greatest games of all time. [60] This combination of familiarity, fame, and simplicity works perfectly for SSNES, which is most effective when someone is a fan of the game.3.3.2 6 * 9 = 42According to the book series The Hitchhikers Guide to the Galaxy, written by Douglas Adams, 42 is “the answer to the ultimate question of life, the universe, and everything” as calculated, over 7.5 million years, by the mammoth supercomputer Deep Thought. When faced with the answer to the ultimate question, the beings whom constructed Deep Thought realized they did not know what the ultimate question actually is. Thus, the beings built a second even more powerful, planet-sized supercomputer to calculate the question. After millions of years, the program came to a conclusion and it is revealed that without any doubt, that the ultimate question is: “What do you get when you multiply six by nine?”. Everyone is baffled.[61] 6 * 9 = 42 is named after this chunk of hitchhiker’s lore due to questions the installation invites about the role of digital information, its deceptive meaning, and condemning finality.      6 * 9 = 42 seeks to bring attention to the deceptive nature of data while providing critique on our trust in data and the menace of omnipresent surveillance. The installation presents an iMac computer, with no keyboard or mouse, along with what looks like an unpainted guitar pedal with a button and a single knob as seen in Figure 34. As the viewer approaches, they can see a temporally distorted video feed of their actions over the last few seconds. By pressing the button, or by turning the knob, they can modify the underlying slit-scan algorithm11 which displays its output on the iMac’s screen.[63] After the user is satisfied with their experience playing with the system, they leave and go on with their day. Unbeknownst to them, the underlying algorithm, the Chroma-Temporal Surveillance Bot (CTSB), has a sinister agenda. Ten percent of the button presses randomly cause the program to perform a “political profiling” of its user. The program saves the currently displayed frame, determines the red, green, and blue color intensity for each pixel, throws out the green information, and determines if there is more red or blue overall in the image. Based on the results of this chroma analysis, the program designates a political orientation to the interactee and proceeds to tweet the analyzed image along with a proclamation of the users suspected political orientation. None of this activity is explicitly told to the user who only experiences a temporarily dropped framerate. In fact, the user needs a computer, or internet connected smart device, to visit the CTSB twitter page to get any idea of the programs secret agenda.3.4 Unwelcoming SpacesA common tenet of art is to be appealing. Generally, painters want their painting to look good to visitors to their gallery, and likewise installation artists are usually concerned with creating interactions that are appealing, or pleasing, to the interactee. This section presents No Humans Allowed (NHA) as a reaction to this commonality. NHA’s mechatronic personalities12interact with visitors by creating an uncomfortable, unnervingly hostile environment and doing everything in their power to encourage guests to leave. NHA exhibits a circuit-centric interaction architecture where its personalities react detrimentally to the presence of humans.3.4.1 No Humans AllowedFigure 18: No Humans Allowed as installed in the WaveCave gallery at CalArts.NHA forms a community of automated robotic entities which reside in the gated WaveCave gallery. The robots are xenophobic: reacting to outsiders via paralysis or violence. When the presence of a human is detected, the community’s productivity breaks down as the individuals are no longer able to function harmoniously. The result is a hostile space where outsiders are unable to enter without being attacked or shunned by the robotic society.       Each of the three mechatronic sound sculptures, or mechatronic personalities13, are constructed from extruded aluminum, acrylic, ultrasonic rangefinders, solenoids, and LEDs. The ultrasonic rangefinders allow each personality to independently detect the presence of any guests in the gallery. When no outside presence is detected, all members of the community are active and productive while the presence of a human, or other, disrupts the society. If the outsider ventures too close to any personality, they will either become paralyzed by hate and fear, and turn off, or attempt to “violently” deter the intruder with loud, abrupt, a-rhythmic noises. Either way, the personality is so preoccupied by the existence of the other it no longer actively contributes to society and can even reduce the productivity rating of other bots residing in the community14. By endowing these situations, No Humans Allowed hopes to shine light on the danger of xenophobic other thinking that is common in the zeitgeist. [64], [65] With the rise of mechatronics, robotics, machine learning, and artificial intelligence (AI) questions of artificial morality are no longer topics for future generations. [66] Do we want our robotic children to exhibit violent, isolationist, bigoted tendencies or do we want them to be accepting, loving and caring to all other forms of life and intelligence?3.5 Non-InteractiveAlthough this thesis is primarily concerned with interaction between humans and electronics it does not advocate that all installation art should be interactive. This section exhibits two mechatronic installations which contain no interactive element. Digital Rain is a dynamic installation which sonifies weather conditions from around the world, while Computer Music is a static installation in which an ensemble of mechatronic instruments perform a deterministic, eight-hour composition inspired by phase interference patterns. Both of these installations benefit from providing no human-circuit interaction to their visitors due to divergent reasons which are disclosed in the following subsections. 3.5.1 Digital RainFigure 19: Digital Rain as presented at the 2015 Digital Arts Expo.Digital Rain is a data driven installation which explores the crossroads of generative music, emergence patterns, data sonification, and technology driven systems of expression. 192 electromagnetic relay switches, broken out into twenty-four units of eight, are arranged in a grid and mounted on the gallery wall. The relays are orchestrated by six Arduino Megas which are networked together and controlled by a hidden host computer. Weather conditions from a randomly selected meteorological station is collected by a Python script. The program then announces the location of the station along with the weather conditions via a text-to-speech algorithm and a stereo system. Meta conditions - such as sunny, rainy, or cloudy - select the composition’s style while the specifics of the sonification are determined by the wind speed, humidity, temperature and barometric pressure. Digital Rain utilizes the mechanical ticking of the relays as the sonic source material for the installation. The relays, because of their precision and speed, are able to actuate fast enough to produce sustained pitch. This, in addition to their aptitude for arrhythmic snaps, allows for a wide variety of soundscapes which are surprisingly representative of the atmospheric conditions they strive to emulate. When the short generative composition representing the conditions of the randomly chosen station comes to a close, the system resets and a new station is chosen.3.5.1.1 Approach to Non-InteractivityDigital Rain attempts to directly sonify weather conditions through the use of electromagnetic relay switches. The playback speed of the sonification is mapped to the temperature of the currently selected weather report: with a slower playback when the weather is cooler. The humidity dictates the note density, with a higher humidity resulting in less time between actuations. The installation cycles through stations at a steady pace, only lingering on a single station for more than a minute if networking errors occur. 	Digital Rain attempts to reflect the varied, grand scale of the earth’s atmospheric patterns, with hope of imparting on its viewer not only the specifics of the weather at one or two of the stations, but also how varied the weather is across the globe at any one moment. Digital Rain could have been realized as an interactive installation. Visitors could have been given agency over what weather station is being represented or could have selected the different parameters which affect sonification. However, this would have changed the dynamic of the installation and would have violated its conceptual goals. In the alternate scenario where guests are able to select individual weather stations, for example, they are more likely to view the system as an educational tool than a work of art. If guests are able to affect the playback parameters of the sonification algorithm, the accuracy of the sonification suffers: no longer sounding like the event it is attempting to emulate. Digital Rain, is an installation that, for conceptual reasons, does not benefit from human-circuit interactivity.3.5.2 Computer MusicFigure 20: Computer Music at the 2016 Digital Arts Expo.Computer Music, unlike Digital Rain introduced in section 3.5.1, is an installation unaffected by outside persuasion. The mechatronic ensemble of floppy disk drives (FDD), hard disk drives (HDD), stepper motors, and Compact Disk Read Only Memory (CD-ROM) drives are controlled by a MacBook Pro through four Arduino microcontrollers. The pitched FDDs and CDROMs are amplified using single-coil guitar pickups. The HDD spindles continuously spin creating a source of white noise which is interspersed with the pitched FDDs and CD-ROMs. The stepper motors raise and lower the covers to the HDDs, revealing the spinning disk while also filtering the noise created by the HDDs. 15      The Computer Music ensemble performs music which is composed in Ableton Live16. During the installation Ableton Live, running on a MacBook Pro hidden from sight, sends MIDI messages through an internal IAC bus where a Python17 script decodes the notes. The Python program determines what drives and motors need to be activated and coordinates four Arduinos which are responsible for directly controlling the drives. Although the MIDI messages originated from a composition written in Ableton Live, the Python script does not care where the messages originate from as long as they pass through its designated IAC bus18. This flexible configuration allows the Computer Music Ensemble to be controlled from any program, or programming language, capable of outputting MIDI messages in real time.      The stepper motors which raise and lower the lids for the HDDs are controlled using a single Hermes Arduino shield which is introduced in its own section in The Pantheon: A System for Mechatronic Art Creation3.5.2.1 Approach to Non-InteractionWithout an interactive element, or any indeterminacy due to external factors, non-interactive installations afford their creators precise control over the state of the piece: a necessity for Computer Music’s sonic content to be effectively realized. Computer Music’s presentation style, and deterministic approach to sonic art, is akin to how single-channel video installations are traditionally exhibited. The video content is static and is screened, projected, or shown as a single series of images; if someone watches the film from beginning to end, they will witness the entire film and can no longer experience new content.[67] In the same manner, the composition Computer Music is static and the mechatronic interpretation of the piece remains consistent from one performance to another; if someone stays in the gallery for eight-hours, they will hear the entire piece. The Computer Music ensemble performs a composition written specifically to take advantage of their natural talent for keeping track of complex polyrhythms and precise timing variations. The composition leaves no room for interpretation by the mechatronic performer and must be played exactly as written or the effect is ruined19. If any interactive element is injected into the system, it will interfere with the precision of the musical execution and will prove detrimental to the overall experience.3.6 Chapter ConclusionThis chapter presented five contrasting approaches to interactivity within the art gallery. Electrical Box, in the Interaction Rail section, created a complex set of interactions which must be executed sequentially. Open Interaction showed Cathode Ray Tubes as an installation consisting of a highly reactive system open to interaction in a variety of ways: all with equal validity. The Deception section talked about installations that attempted to deceive users by either re-appropriating familiar interfaces, with the example of Symbiotic SNES, or by disguising their true intentions, as with 6 * 9 = 42. Unwelcoming Spaces looked at No Humans Allowed as an installation which uses interactive elements to create an aware space that is hostile to gallery viewers. With Computer Music and Digital Rain, the section Non-Interactive compared deterministic and dynamic approaches to creating mechatronic installations.  Collectively, these installations and their corresponding philosophies to interaction are the authors attempt to question how we interact with electronic devices, specifically in the art world, and explore possible frameworks for creating new forms of art.Chapter 4 Designing Exploratory Interfaces This chapter focuses on interfaces created for the installations discussed in Chapter 3, while additionally introducing new interfaces which explore human-circuit interaction (Table 3). The first contribution, the Discovery Synth, facilitates interaction by removing physical abstractions that separate humanity from circuitry. The second section introduces the Retrono which repackages preexisting electrical systems in a way that exposes them to direct human contact while transforming their function. The next section compares and contrasts two approaches to circuit bending retro video game consoles with the Rotary SNES and Modular SNES. The Symbiotic SNES and the Chroma Temporal Surveillance Bot are presented in the following section as examples of deceptive interfaces that either obscure their true intentions or sabotage their user’s actions. The EavesDropper is disclosed in the sixth section as an interface which does not provide any control options to its user while the final section introduces The Voltage Slammer and OneToFour as two distinctive interfaces which act as puppeteer to multiple host devices. Project NameType of ProjectForm of InteractionDesign PrioritiesDiscovery SynthAudio/visual synthesizerButtons, pots, slidersRemoval of mechanical abstractionsVoltage SlammerSequencer for circuit bent devices, circuit bending toolRotary encoders, buttons, distance sensorsOrchestrating multiple circuit-bent systems from one deviceRotary SNESCircuit bent video game consoleRotary switchesTransparencyModular SNESCircuit bent video game consolePots, patchbayFlexibility, modularity, complexitySynergetic SNESControl message interceptor, and injector, for SNESNoneDeceptionRetronoAudio/visual synthesizerPresence, physical contactReduction, minimalismEavesDropperMagnetic flux sonifierNoneTransparencyTable 3: Interfaces for challenging human circuit interaction modalities4.1 Abstractive DeconstructionFigure 21: Discovery Synth musical interface.This section introduces the Discovery Synth (DS) as an example of a musical interface which applies techniques of deconstructivism and abstraction to its design. The interface’s buttons and potentiometers seek to replace the mechanical abstractions that separate our bodies from the electronics with the body of the user.       The DS is a reaction to the observation that electricity, in its raw form, is of little worth to our society. Lightning arching in rainclouds, or striking the ground, does little to ease the struggle of human existence just as the static electricity that builds on your body as you shuffle along a shag carpet is rarely anything but an annoyance. However, electricity can work miracles when harnessed using the correct tools and the power of electricity, in modern society, comes from the design and implementation of electronic components. As a result, we usually interact with electricity via a physical abstraction or a tool which then electronically modifies the underlying circuitry for us. Let’s take the example of the popcorn button on a microwave, the button physically separates the finger from the electronics that operate the microwave. When pressed, the button internally will connect two points in the circuitry which were unconnected when the button is in its resting state. This connection causes electrons to flow, alerting the microwave’s logic to the certitude that the popcorn button is pressed. The DS project wants to bring the user closer to the electronics they are controlling just as Peter Blasser has sought to do with his own work20. The project seeks to remove physical constructs - the popcorn button - which separate the body from the electricity which controls the interface.4.1.1 Discovery SynthThe Discovery Synth is a Raspberry Pi powered interface used in both installation and experimental music performance. Physically, the device features eight buttons, sixteen potentiometers, stereo output, and microphone input. The Raspberry Pi inside the interface is powered using an onboard battery which can be recharged using a USB cable. The Pi, with the help of a custom cape, is reads the values from the buttons and potentiometers. Pure Data is run on the Pi to make sense of the sensor readings while also serving as the audio and video synthesis engine for the device. [68]      The DS Raspberry Pi cape was developed in collaboration with Clay Chaplin for the CalArts AV Ensemble which Chaplin leads. Each of the ensemble members built their own version of the DS and students were free to choose whatever specific components, enclosures, and configurations they preferred for their instrument. The authors iteration features eight custom buttons along with sixteen voltage dividers: eight of which are standard mechanical potentiometers while the remaining eight are custom. The instrument is crafted from reclaimed materials: the buttons and pots are housed in the base of an old aluminum lamp, the main body is crafted out of wood found on the side of the road, and the tuning pegs are salvaged from an old guitar. 	The Raspberry Pi 2 that acts as the brain for the DS, features twenty-six General Purpose In/Out (GPIO) pins which operate as either inputs or outputs at a logic level of 3.3V.[69] While the GPIO pins are adequate for many circuits, they are limited both by their strictly digital operation and minimal current sourcing capabilities when compared to an Arduino Uno microcontroller. The Discovery Synth Cape21 gives the Raspberry Pi input capabilities which reflect an Arduino or equivalent microcontroller: bestowing the ability to read analog values from sensors in addition to expanding the available number of usable inputs. This is done with two MCP3008, 8-channel, 10-bit, A/D converters. 4.1.1.1 ButtonsFigure 22: Five of the Discovery Synth's buttons.The DS’s buttons are designed as minimally as possible with no physical mechanism separating the action of pressing from the flow of electrical current within the component. Every part of the design is functional and vitally important for the device to work properly. The process started conceptually by distilling how Normally Open (NO) electro-mechanical push buttons function; they internally contain two conductive paths which are electronically separated when no external force is applied. When a NO pushbutton is pressed, two parts of the circuit are joined through mechanical means allowing current to flow from one lead to the other.        The DS’s buttons follow the NO model providing no electrical connection between the two leads while the buttons are in their resting state but allowing current to flow when the buttons are pressed. To refrain from using any unneeded abstractions the buttons consist simply of two conductive bolts, spaced a few millimeters apart, as seen in Figure 21. The bottoms of the bolts are soldered to lengths of wire which are connected to the DS cape. One of the bolts is connected to the 3.3v power rail while the other is monitored by a GPIO pin on the Raspberry Pi. By pressing on the bolts with a finger, the interactee fathers an electrical connection - through their skin - between the two bolts. 4.1.1.2 PotentiometersThe DS interface features a total of sixteen potentiometers in two banks of eight. Each of the two banks contain distinctly different types of potentiometer. The first bank, which this document will refer to as the knob-style potentiometers, are typical store-bought mass produced potentiometers and are mounted in the metal portion of the interface next to the buttons. The second bank, or the slider-style potentiometers, are custom designed just for the DS and do not look like the bank of knob-style potentiometers. The goal when designing the slider-style potentiometers was to remove the physical abstraction wedged between the human and the circuitry in order to create a direct interaction: just like with the buttons discussed in section 4.1.1.1. Figure 23: How a potentiometer, or slider , functions.	A potentiometer is mechanical component that functions electronically as a variable resistor. Potentiometers, or pots as they are often called, have three leads they use to connect to the circuity around them. The outside leads are connected to the ends of a resistive material, while the inside lead is connected to the wiper as seen in Figure 23. To adjust its point of contact with the strip the wiper is typically moved using mechanical force to come into contract with the strip at different points producing a varying resistance between the wiper and the outside leads, as seen in Figure 23. A common application for potentiometers, and how the DS is using its potentiometers, is to connect the component to a circuit so it functions as a voltage divider. By connecting one of the two outside leads of the potentiometer to the circuit’s power, the other outside lead to ground the center wiper lead will produce a variable voltage depending on its position.Figure 24: Two ways to use a Discovery Synth potentiometer.	The DS slider design functions identically to the conventional potentiometer described above; it has a strip of resistive wire, specifically Kanthal, that comes into contact with conductive copper tape at different locations producing a variable voltage at the wiper node. What makes the slider novel is not how it behaves electronically, but is instead its construction. The DS slider, just like the buttons in section 4.1.1.1, contains no parts that are not completely necessary to it functioning: there is no casing, levers, springs, or anything else. The copper tape exposed on the outside of the DS’s wooded case serves at the sliders wiper and is connected to an A/D converter found on the DS cape while the Kanthal wire suspended above is the resistive strip and is connected to power on one end and ground on the other. 	One of the primary duties of the DS cape is to provide analog readings from the potentiometers to the Raspberry Pi, which normally is limited to digital readings by the capabilities of its GPIO pins. This is done with two sixteen pin, MCP3008 ICs. The MCP3008, manufactured by Microchip Technology Inc., provides eight channels of 10-bit resolution A/D converters,  can be controlled over SPI, and operates on a voltage range of between 2.7V and 5.5V.[70] With the help of these IC’s, the DS reads a high value from the slider when the user presses its wire down close to the aluminum portion of the interface and a low value when held down on the opposite side.Figure 25: Close up of the Discovery Synth potentiometers.      A pecurality of this design becomes apparent when the slider is not being pressed. With no external force to bend the wire down the Kanthal moves to a resting position ½” above the interface, breaking its connection with the copper-tape wiper below. This results in the Pi receiving a reading of “0” for that channel. In this way, the sliders do not hold their last value as a typical potentiometer does and effectively function as “normally-open potentiometers”. Meaning, the sliders only return values when physical force is applied to them, just as a normally-open pushbutton will only return a value when pressed. This quirk is desirable in some circumstances, especially working well for controlling effects, filters, or some sample playback parameters. In compositions with parameters that demand the ability to hold and maintain an intermittent value, they have to be mapped to the standard store bought potentiometers. To partially offset this limitation, the interface is often presented with several copper pipe segments as seen on the right side of Figure 24. The pipes are used to maintain an electronic connection between the wiper and Kanthal wire allowing the performer to hold intermittent values on with the components. However, the pipes are not a perfect solution. They work well for holding values, but a awkward when increasing or decreasing a value and overall are clunky to use.       The DS project succeeded in creating new ways to interact with familiar electronic components. Both the buttons and sliders designed for the interface, while maintaining the electronic functionality of the component they are named after, approached their construction in a different way. The DS works well when used by the author, but proves difficult for those unfamiliar with the interface. Especially with the sliders, which look like guitar string and invite users to strum or pluck them, folks struggled to figure out how to interact with the device. That being said, clarity and transparency are not declared tenants of the project and overall the project is considered a success.4.2 Camouflage and ExposureThis section looks at the Retrono interface as a case study in repurposing preexisting electronic systems while exposing their circuitry to direct human contact as a means of control. The Retrono interface is an appropriated video game console which is repackaged to facilitate a completely new and unconventional interaction schema between the device and interactee. The interface exposes, highlights, and reveals the internal circuitry of the device, ironically disguising it from recognition and liberating it from the uses of its past life.4.2.1 RetronoFigure 26: Retrono Synthesizer.Retrono interface introduced in this section is directly influenced by Peter Blassers work with developing instruments under the philosophy of inner surface as mentioned in section 2.1.3. The interface, used in the installation Cathode Ray Tubes in section 3.2.1 above, is not a blue-sky project built from the ground up. Instead, creating a Retrono is an act of removal and replacement as oppose to construction. The interface is a Retron22 retro video game console which is a hardware emulator for the famed Nintendo Entertainment System, or the NES, and is capable of playing NES game cartridges and using NES controllers. To transform a Retron into a Retrono takes three steps:1. The controller ports, reset button, and power button are removed from the Retron2.  The red power LED is replaced with a white LED3. The original plastic case is removed while the hardware is rehoused in a laser-cut clear acrylic boxThe Retrono cases have four openings: one for the power plug, one for the video output, one for the audio output, and one large rectangular opening directly above where the unit’s main circuitry is housed intentionally exposing board to outside interference - electromagnetic of physical.  Once a Retron is converted into a Retrono it is unable to play NES games; the case does not allow a game cartridge to be inserted into the cartridge slot and the interface is assembled without a game inside. Unlike a NES console which has mechanisms to detect the presence of a game cartridge and will not attempt to synthesize video output without a game, the Retron has no such mechanisms and will always synthesize a video output. When the devise is housed in its original case it is protected from outside interference and the image it displays will usually be black, when the console is turned into a Retrono this changes. The console attempts to decode the floating electrical charges at each of its input pins as video and audio data. The once video game console is transformed into an 8-bit audio-visual synthesizer whose output is can be manipulated by the electrical properties of its user’s body.	Retronos are most effective when CRT TV’s are used to display their output. The strong electromagnetic field emanating from the tubes turbocharges the reactivity of the Retrono creating a feedback loop between the TV and Retrono. As they are not functional in a conventional sense there is no right, or wrong, way to interact with a Retrono. They are created out of the desire for a hyper-reactive system that people can play with and explore without the burden of any expectations or instructions.4.3 Re-Appropriation of ConventionsThe two interfaces introduced in this section, the Rotary SNES and the Modular SNES, originated from the desire to develop techniques for circuit bending retro video game consoles. The Rotary SNES uses familiar interface components, two knobs, to allow users to select from over a hundred contrasting combinations of circuit bends. Its more complicated counterpart, the Modular SNES, mimics a patchbay to allow for millions of configurations. This section explains the process of creating these two interfaces, describes their capabilities, and compares their relative success to one other.4.3.1 Rotary SNESFigure 27: Rotary SNES circuit bent video game console.The Rotary SNES, is the precursor to the Modular SNES introduced in section 4.3.2 below, is a circuit bent Super Nintendo Entertainment System with twenty-two intermittent video bends made available to users through two twelve positions rotary encoder switches. The Rotaty SNES is able to play any unmodified SNES video game cartridge and provides glitched out, bent versions of the game for folks to play in real time on the console. Instead of simply framing the glitch and viewing in as one would a painting, the Rotary SNES project is interactive at its heart and encourages visitors to play the game, and to become comfortable with the glitch.4.3.1.1 Circuit Bending a Super NintendoFigure 28:  Rotary SNES's video bends.The bends are found by opening up the consoles case and probing vias on the motherboard near the unit’s graphics processing ICs as seen in Figure 28. Vias are holes in a circuit board that provide an electrical connection from one side of the PCB to the other side and were chosen at the primary subject for the Rotary SNES’s circuit bends due to both their abundance and ability to play host to a foreign cable. To test the vias the SNES it powered on with a game inserted and connected to a TV. The vias are bridged to the system’s ground through a low value resistor, one at a time while watching the video output to see if any interesting glitches occur. The glitches vary from changing the color blend, mismatching tile data, inserting random noise, and even removing textures. The Rotary SNES can play any standard SNES game and allows its users to switch between bend variants using two 12-pole rotary switches (Figure 27). The common terminal for each switch is connected to system ground. One of the twelve positions is left unconnected, allowing for the user to choose “no bend” for that switch, while the other eleven positions are each attached to a different bends that are found in the console using the method described above (Figure 28). 4.3.2 Modular SNESFigure 29: Modular SNES circuit bent video game console.The Modular SNES, an evolution of the Rotary SNES introduced in section 4.3.1, is a modified Super Nintendo Entertainment System that is hacked and circuit bent using an Arduino Nano microcontroller. The Modular SNES utilizes the same approach of via-based hardware bending for finding and exploiting the SNES consoles. The Modular SNES, however, does not only provide a path to ground for these bends, but instead opens them up to the world by porting the connections to the outside via 1/8th inch ports. The activity of circuit bending is steeped in exploration and discovery and the Modular SNES chose a patchbay interface to allow for flexibility in its use representative of the act of circuit bending while still benefitting from the advantages afforded by working within an established convention with established expectations for interaction. In addition to the patchbay, the Modular SNES additionally boasts an Arduino Nano hidden inside the case with four input jacks, four analogue pots, as well as its own eight outputs. Figure 30: Modular SNES with case open.To find the bends used in the Modular SNES, an Arduino Nano’s PWM pins are used to pulse, at varying speeds, potential locations on the SNES mainboard. Just like when bending the Rotary SNES, the Modular SNES focused in on the plentiful vias found on the host SNES’s mainboard and tested each one. If the via provides consistently interesting results when probed with the Arduino, it is tested against system ground before being marked as “good”. After testing all possibilities for the SNES, each of the final bends is connected to a 1/8th inch jack which is mounted onto the SNES plastic case - as seen in Figure 30. In fact, all of the input and output jacks on the Modular SNES use the same 1/8th inch housings which provided the perfect balance between size and functionality. The 1/8th inch standard is common among electronic devices allowing the Modular SNES to easily mate with auxiliary cables, headphones, and even other Modular SNESs; as long as the interfaced system has an operating voltage of 5V or lower there are no limitations.       One thing that sets the Modular SNES apart from the Rotary SNES is its use of an onboard Arduino Nano microcontroller. The logic levels of a SNES console operate at 5V and the system is organized with at least 500mA of extra current draw on top of normal operations. This provides enough overhead to allow the console to internally power an Arduino without any additionally cables or cords. The Modular SNES takes advantage of this and houses an Arduino NANO inside the SNES plastic casing. The Arduino’s PWM output pins are connected to 1/8th” jacks and are mounted to the case in the same manner as the bends. In addition to simply providing output connections, analog input pins from the Arduino are ported out to 1/8th” jacks which are mounted to the back of the SNES unit. The voltages read at these inputs affect the pulse rate and overall intensity of several of the Arduino’s PWM outputs. These allow for some interesting feedback loops to be created between the Arduino and the various bends available on the patchbay. The operations of the Arduino can furthermore be controlled using four potentiometers positioned on the top of the SNES case which additionally affect the rates and intensities of the Arduino outputs.Figure 31: Sample bends from the Modular SNES.	In addition to the video bends offered by the device, the Modular SNES provides its user an output from the audio card in the patchbay. This connection can be connected to one of the video bends to allows the visuals to be effected by a games music and sound effects as seen in the top left image in Figure 31 or can be routed into the Arduino to control its behavior. Furthermore, a separate jack in the patchbay provides a connection to the logic signals of one of the controllers. This interesting jack can be used to either control the in-game avatar with another bend, or the Arduino, or can leverage the controller messages to dynamically bend the game according to the players button presses. 4.3.2.1 Compared to Rotary SNESVideo BendsAudio BendsInput JacksArduinosMethod of InterfacingRotary SNES22NoneNoneNone2x Rotary SwitchesModular SNES12-17141x Arduino NanoPatchbay, 4x PotentiometersTable 4: Technical comparison between Rotary SNES and Modular SNES.Both the Modular SNES and Rotary SNES have been shown at various Fairs, Expos, Festivals, and installations often together with the Symbiotic SNES as the SNES Trinity and due to their similarities invite comparison. When evaluated based strictly on their technical capabilities there is no doubt that the Modular SNES boasts more features than its rotary counterpart with an onboard Arduino, access to audio, and the patchbay interface which allows different bends to be connected to each other. However, as seen in Table 4, the Rotary SNES does feature between five and ten more bends than its counterpart. This is due to both the fragility of Modular SNES bends and the amount of physical space required to implement each of its bends. However, more available bends does not equate to more available bend combinations, the Modular SNES’s patchbay interface allows for every possible bend to be connected to any other bend, or Arduino port, vastly increasing on the number of possibilities offered by the Rotary SNES whose two twelve-positions rotary switches only provide a total of 144 different possible states.       The Modular SNES is by no means the better device in all facets and the simplicity of the Rotary SNES is preferred in some circumstances. For instance, the Modular SNES is prone to “crashing” and when some bends are connected to each other the system will reboot or freeze. While these events are avoidable after learning what the triggers are, these crashes prove crippling during public events where unsuspecting visitors are unaware of such limitations. Another example of how the complexity of the Modular SNES works to its disadvantage becomes apparent in how many visitors interact, or avoid interacting, with the interface. The Modular SNES’s dozens of jacks, along with the operational cabling, distracts users from the circuit bent video game which is intended to be the focus of the exhibit. The Rotary SNES on the other hand has two simple knobs guests can turn to their hearts content without fear of breaking the exhibit; they encouraged guests to quickly find bends they like and then focus on the game without the interface impeding them.      When used as an interfaces for public installations where the installation topic is not the interface itself the Rotary SNES triumphs at transparency, simplicity, and minimalism and serves its resulting glitched software without drawing unneeded attention to itself. It refrains from obstructing the circuit bent games, which are the topic of the installation, while still allowing for control over the system. This the Modular SNES fail to achieve due to the complexity of its controls which requires explanation drawing attention away from the games guest should be focusing on. To conclude, the Rotary SNES is a better interface for installations while the Modular SNES is the better choice for the individual user interested in spending extend time with the device.4.4 DeceptionThis section offers the Symbiotic SNES (SSNES) as well as the Chroma-Temporal Surveillance Bot (CTSB) as interfaces that are schematized to deceive their users.  First, the SSNES hardware interface, from the installation of the same name in section 3.3.1, is described along with its method of exhibiting familiar interfaces that behave in unexpected ways. Next, the 6 * 9 = 42 installation’s23 interface and software system, the CTSB, is submitted as an insidious interface prone to fraudulent public declarations. 4.4.1 Symbiotic SNESFigure 32: Symbiotic SNES hardware.The physical component of the SSNES is presented to its users, like many devices in this chapter, as a nameless black box intended to draw as little attention to its presence as possible. If the box is opened, however, it reveals inside circuit boards from two SNES controllers, two SNES controller extension cables, and two SNES controller ports all connected to an Arduino Mega fitted with a custom SSNES shield.       The key to how the SSNES system works lies in the SNES controllers, and how they communicate with the SNES console. Inside of the SNES controller’s cable there are five wires. The controller is powered with the first two wires which are 5V and GND while the other three wires are for communication: clock, latch, and data. Once the wires are routed into the Arduino through the SNES shield the “SNES” Arduino library24 trivializes the decoding of incoming controller information. The SSNES uses a different method for sending its messages to the console than when decoding incoming messages. For each of the buttons on two controller circuit boards a wire is soldered to the “sensing” side of the button pads and then secured with hot glue as seen in Figure 33. The other end of the wire is connected to the SSNES shield allowing the Arduino to digitally simulate a button press by turning on one of its GPIO pins. As the controller operates on 5V logic as does the Arduino this is as simple as flipping a digital pin on the Arduino.      \Figure 33: One of two SNES controller inside SSNES unit.      The SSNES system does not require any external power source, nor does it rely on batteries which need to be replaced or recharged. Instead, through the power normally provided to the SNES controllers, SSNES is able to power itself off whatever SNES console it is being used with. The Symbiotic SNES works with any production SNES and is not tied to any hardware modifications to the console itself. Similar to the techniques seen in section 4.3.2 above with the Modular SNES, the SSNES’s Arduino is directly powered from the SNES host console. While in the Modular SNES the Arduino was hidden inside of a modified SNES, the SSNES uses the power and ground connections provided by the controller ports to power the device through its output connections to the host SNES console.4.4.1.1 SoftwareThe buttons on a SNES controller are binary: they are either on or off with no alternative. The SNES controller protocol will represent a pressed button with a 1 and an unpressed button with a 0. Several times a second the SNES asks the controller for the state of its buttons and the controller responds with a strings of 1s and 0s. If, for instance a player is pressing forward and the run button the resulting message might look like 10010000000. The digital nature of these messages lends itself nicely to bitwise logic which was invented as a set of mathematical operations specifically for working with the base two number system. Many of the operating modes for the SSNES software is based on these basic mathematical operations.NameOperationResultUltimate Co-OpBitwise ANDOnly buttons pressed by both players are passed to the consoleOpposing ForcesBitwise XOROnly buttons pressed by one player will get passed to the console (multiplayer mode)Alternating-PressesButton PressesPlayers alternate total control over the character after a predetermined number of button pressesAlternating-TimeTurn LengthsPlayers alternate total control over the character over a set period of timeTwo FaceController SplitPlayers alternate control over different parts of the controllerTable 5: Sampling of basic play modes supported by Symbiotic SNES.      The SSNES has two categories of operating modes that it supports: single player, and multiplayer What makes the single player modes differ from the multiplayer modes is not the number of people that play the game but instead is the type of game the mode supports. Both the single player and multiplayer modes require two players to operate (see Table 5 for more information). The single player modes support games where one player controls an in-game avatar25 while the multiplayer modes support games where two players each control their own in-game avatar at the same time26. The single player modes each divulge a way two participants can play a single player game together. For example, the “Agree” mode only sends messages - button presses - to the SNES if both of the input controllers are pressing the same button at the same time. This forces the two players to press the same buttons at identical times if they want to get anything done in the game world. This is contrary to the multiplayer experience offered when these games were originally released. The two players are not controlling two independent characters but instead have to work in tandem to control a singular character.  Each of the modes create a unique way to experience content that was created decades ago. The SSNES system allows us to play nostalgic classics for the first time with our friends and loved ones in a truly co-operative way.       While many of the single player game modes can be used with multiplayer games as well, the multiplayer game modes are programmed specifically for games such as Street Fighter II where the two players fight against each other. Just like when the bitwise AND operation is applied to the controller data in the single player mode explained above, when a bitwise XOR is applied to the controller data when playing Street Fighter II the result is quite interesting. With this game mode, all button presses will be passed to the console as long as they are only occurring on a single controller. If, for instance, both players choose to press the kick button, neither message will be sent to the console. This allows players to effectively counter their opponents moves by pressing a button before, or at the same time as them.4.4.2 Chroma-Temporal Surveillance Bot The Chroma-Temporal Surveillance Bot (CTSB) consists of a simple hardware interface consisting of only two controls housed in a small metal box connected to a iMac computer running a few hundred lines of Processing27 code running on an iMac computer. CTSB serves as the functional portion of the installation 6 * 9 = 42 introduced in section 3.3.2. While section 3.3.2 covers the interactive aspects of CTSB when used as an installation environment, this section explains how the software functions as well as the reasoning behind the interfaces hardware design. 4.4.2.1 SoftwareFigure 34: Sample outputs from Chroma Temporal Surveillance Bot.While there is simple firmware running on an Arduino Uno inside of the CTSB hardware interface, it only serves to report button presses and switch positions to the computational core of the system which is written in Processing and is running on an iMac host computer. Besides using the state of the hardware interface to determine its internal state as expanded upon below, CTSB gains control over the iMac’s webcam which it turns on. The images captured from the webcam provide the source material for the remainder of the program.      Although the true purpose of the CTSB is to run its political profiling subroutine, this can only be done when someone is interacting with the CTSB hardware. Thus, the first thing CTSB does after initializing the webcam is to create some interesting “art” with the hope of drawing a crowd of users it can proceed to tweet about. This is done by means of a specialized type of slit-scan video processing algorithm which operates on the red, green, and blue color channels with separate images masks providing color independent slit-scan processing as seen in Figure 34.       Upon initialization, the system creates three contrasting greyscale “master color masks” - one for each of the primary colors. Next, the program begins storing the 256 most recently captured images from the host computer’s webcam in a FIFO28 buffer. After updating the FIFO CTSB calculates the color information for each pixel it will display on the iMac screen one at a time. The program references the value stored in each of the three master image mask’s corresponding pixel which is used to look up a corresponding image stored in the FIFO buffer. For instance, if the first pixel returns 0, 50, and 200 from the three master color masks it will take its red value from the first frame in the FIFO buffer, its green value from the 51st frame, and its blue value from the 201st frame. This process is repeated for every single pixel of each image displayed on the iMac.      The switch and button give the user control over the master color masks. When the switch is turned to a new position, the program chooses a different algorithm for drawing the master color masks and redraws the masks, resulting in a different aesthetic quality as seen in Figure 34. When the pushbutton is pressed, the program reconstructs the masks using the rule set dictated by the rotary switch creating a different variation of the currently selected aesthetic.       While the video produced by the CTSB is entertaining its enjoyment comes at a cost to the users privacy and possible reputation. The hidden purpose of the CTSB is not to create beautifully psychedelic videos, but instead to gather data about the political affiliation of the gallery visitors. Ten percent of the time, chosen randomly, the pushbutton is pressed the CTSB executes its surveillance subroutine. First, the program analyzes the color content of the frame it is about to display on screen. It adds up all of the red and blue values for all of the pixels and determines if the image overall contains more red or blue. Next, according to the results of this “chroma analysis”, the CTSB determines the interactee is either Republican (if there is more red) or Democrat (if there is more blue). Although the system for determining the users political affiliation is obviously naive and erroneous, the CTSB proclaims the results of its findings along with its evidence (the image) on Twitter in the form of a tweet announcing the users allegiance to the affiliated political party.4.4.2.2 HardwareFigure 35: Chroma Temporal Surveillance Bot interface, final design on right.The CTSB has gone through two major hardware revisions. The first version of the interface comprised of six N.O. push-buttons on the top of a BB aluminum project enclosure box as seen in the left of Figure 35. Inside the enclosure, an Arduino Nano recognizes button presses and reports the events to a Processing sketch running on a host computer. The Processing program handles communication with the hardware, reading images from the computers webcam, computing the slit-scan processing, and displaying the video output. Each of the buttons on the controller gave the user an axis of control over the slit-scan processing algorithm. This includes: changing the buffer length; reconstructing a mask; cycling through the mask categories; toggling between red, green, and blue channel separation; inverting the color processing; tweeting a photo; and cycling through different frame rates. This multitude of control results in millions of unique optional program states. After some testing, it became apparent that the interfaces large number of controls distracted attention away from the software system which the user is intended to focus on. As interactees spent more time figuring out what each of the button do than playing with the system they controlled, the need for a simplified interface motivated the design and construction of the second version of the CTSB. 	The second, and final, version of the interface features only two controls instead of the six found on the prototype. The first control is a button which redraws the color masks when pressed. The second control is a twelve-position, continuous rotary switch which allows users to choose between the different algorithms used to build the color masks. The simplified design provided users a more consistent experience29 in a curated, yet dynamic, manner. This was done partly by removing many of the axis of control once available to the user. For instance, by removing user control over the oversampling rate of the FIFO buffer, which is interesting with some effects but can destroy others if set too low or high, and hard coding its value for each of the program states reduces the chance the user enters into a “dead state” where nothing interesting is happening. This additionally reduces confusion about each controls’ effect on the displayed image, while still inviting exploration and allowing for countless variations through the generation of new masks. As the interface needs to attract participants to collect its data, it is important that the device appears friendly, innocent, and easy to use. The hardware interface is straightforward, familiar, and easy to understand to hide the software’s more sinister purpose. 4.5 Removing AgencyThis section, Removing Agency, introduces the EavesDropper interface, used in the installation Electrical Box introduced in section 3.1.1 above, as a device which minimalizes its user’s agency over its functionality by removing access to its operational parameters. The rationale behind this design determination, how the interface technically functions, and the psychological implications to its interactions are discussed. Figure 36: EavesDropper magnetic field listening device.4.5.1 EavesDropperThe Eavesdropper is exhibited to its users as a black-box that obscures its internal workings and logic from the outside. The EavesDropper furnishes no instructions, explanations, or even a way to control or turn off the device. The absence of any user control removes the need for a calibration process while minimalizing operational learning curves. Scott Summers, a.k.a. Cyclops of X-Men fame, and his destructive vision serve as a guiding force when designing the EavesDropper. Cyclops’ pernicious energy-ray vision is perpetually active as long as his eyes are open: blazing away at 100% power. He has no option to adjust the gain on his vision and is forced to rely on ruby quartz glasses to keep the destructive might of his vision contained. While users are not intended to feel burdened by the EavesDroppers, as Cyclops often is by his power, it is desired that the user’s endowed ability of magnetic eavesdropping behaves like Cyclops superpower does and it is acceptable that the EavesDroppers are not perfectly calibrated for everyone.4.5.1.1 Technical DescriptionFigure 37: EavesDropper magnetic flux sonification device with cover removed.Permanent magnets from a guitar pickup housed in the tin case creates a static magnetic field around the EaveDropper device. The EavesDropper leverages the properties of inductance to detect changes in this field30 through a very long, thin copper wire in close proximity to the magnet. [71] The resulting signal is amplified before being sent to a pair of headphones where it is transduced into acoustic energy as sound  as seen in Figure 38. Figure 38: EavesDropper electrical system diagram.      Each EavesDropper system consists of two pieces: a small metal tin, which houses a battery and all of the electronics; as well as a pair of Telex headphones. The tins house a single-coil guitar pickup, a stereo amplifier, a ¼” headphone jack, and a lithium ion battery. The amplifiers used are PAM8403 ICs which provide enough amplification, at 3-watts to boost the output of the pickups to an audible level. The PAM8403’s features a filter-less architecture allowing it to drive the headphones directly eliminating the need for additional components and prolonging the devices battery life. The amplifiers are efficient Class-D amplifiers which operate off of a supply voltage between 2.5 and 5.5 volts allowing them to be powered directly from a lithium-ion battery and consume less power than a comparable Class AB or Class A amplifier. [72] Although by no means as sophisticated as the headphones used by Christina Kubisch in her installations introduced in section 2.3.1, these simple devices operated for over 48 hours on a single battery while maintaining effective at sonifying changes in its magnetic field.4.6 Orchestrating CircuitryThis section introduces two interfaces which each control multiple electronic devices: The Voltage Slammer and OneToFour. The Voltage Slammer is an experimental circuit bending probe, and sequencer, which is used both to circuit bend electronic devices as well as to control those devices in a manner analogous to a musical sequencer. OneToFour allows a pair of SNES controllers to concurrently control four SNES consoles in order to explore divergence between the video game consoles as they play copies of the same game. Both of these interfaces allow a single user to control multiple external electronic devices which would otherwise require several people to operate.4.6.1 The Voltage Slammer V1The Voltage Slammer is not only a mechanism for controlling circuit bent electronics but is additionally a platform for assisting in the activity of circuit bending. This project is part of an ongoing exploration in controlling circuit bent toys, video game consoles, and instruments with Arduino powered interfaces. Figure 39: The Voltage Slammer (v1) circuit bending probe and sequencer.      The Voltage Slammer is conceived to provide centralized control over a variety of circuit bent battery powered toys. The project originated from frustrations when circuit bending ensembles of toys with the goal of musical performance. As the number of bent devices increases, it became cumbersome to control dozens of circuit bent toys which each have their own set of local knobs, switches, and dials to conduct their behavior.  Additionally, many of the bend devices featured different bends with conflicting controls and it was difficult to keep track of how to operate each individual device. The Voltage Slammer provides a solution to that dilemma by providing a uniformed interface in which to interface with all the varied devices. Unfortunately, not every circuit bent device can be plugged into The Voltage Slammer and work its way into the system, devices have to be initially bent with the device. Figure 40: The Voltage Slammer (v1) when viewed from rear.      The first eight out its thirteen output channels produce Pulse Wave Modulation (PWM): a type of digital signal which allows the user to adjust the duty cycle of the underlying digital signal. Each of these channels have a corresponding potentiometer and switch. The potentiometer is used to modulate the pulse width of the outgoing signal, affectively producing higher current and voltage to the client device. The switch cuts off the connection to the client device entirely. Small LEDs are positioned above the switches which light up along with the output signal to provide immediate feedback to the user. These outputs are affected by the master delay pot stationed in the upper left corner of the interface as seen in Figure 39. The master delay inserts a period of dead time into the signal temporarily turning the signal off. This can be effective for simulating button presses on some devices and can even be necessary for getting many instruments to reach a state of incantation31. The remaining five outputs are kindred to the first eight but have no feedback LEDs, no on/off switches and are physically arranged on the interface in a separate group. These secondary outputs are used to control motors drivers or any other bend requiring constant voltage or current. The rear of the Voltage Slammer provides the output for both the primary and secondary output channels through thirteen RCA connectors32 as seen in Figure 40. The rings of the RCA cables are connected to the system ground, which is shared by The Voltage Slammer and all battery powered devices, while the pins carry the control signal which originates from the Arduino. A RCA connection with both the ring and pin connected to ground is included in the outputs to allow for easier probing and bending but serves no function when the interface is used as a sequencer.       Lastly, the Voltage Slammer has an ultrasonic rangefinder which allows the interface to be aware of the presence of gallery viewers in the case of installation. This proves especially beneficial when the interface is used in an installation setting, making it easier for the installation to exhibit traits of intelligence with a crude sense of spacial awareness. 4.6.2 The Voltage Slammer V2Figure 41: The Voltage Slammer (v2) circuit bending probe and sequencer.The second version of the controller boasts sixteen rotary encoders which each feature built-in push-buttons and RGB LEDs. The encoders provide an intuitive interaction experience to interactees when the interface is used for installations due to their ability to provide both visual feedback through the LED and by allowing for continuous rotation. When used to control circuit bent toys in a gallery setting the system resets the encoder states in-between each visitor, ensuring each interactee is yielded the same starting system state. This is a vast improvement over the potentiometers used in the first version which only rotate 270 degrees and have no mechanism to reset their values in-between users, causing each interactee to be left with whatever state the user before them put the unit into. Because the encoder shafts support continuous motion, users are not stuck having to reset the controls back to a starting state themselves as everything can be handled in software. To alert the new user that the unit has reset itself each of the encoder LEDs will turn green to indicate the values have been reset. As the user turns an encoder it will the LED will mirror the behavior of the output, pulsing when the unit is sending out a signal with green, yellow, and red corresponding to a low, medium, and high signal level. This instant feedback proves useful to offset the unpredictable nature of circuit bent instruments. In the circumstance where a puppet device is not responding to The Voltage Slammer, the feedback from the LEDs provides reassuring feedback which affirms the controller is working properly and that the user’s actions do indeed have affect . The pushbutton on the encoder allows its user to manually reset the encoder state: turning the LED green and resetting the value.       The second version of The Voltage Slammer replaced the SPST33 toggle switches with eight higher quality metal pushbuttons with LED rings. The new buttons are used in the same manner as the switches in the first version of the interface by connecting, or disconnecting, the output jack from the Arduino for its corresponding channel. The buttons are latching, functioning just as a SPST switch does. The LED rings provide instantaneous feedback about the status of each of the buttons, making it easier to tell the states of the outputs with a quick glance. The inclusion of the LED rings in the button housings additionally eliminate the need for adding discrete LEDs, to provide the valuable visual feedback, reducing the number of components used over the first version of the interface.       An additional upgrade added in the second version of The Voltage Slammer allows the interface to be powered with rechargeable batteries instead of a USB cable - which the interface still supports. As the devices that the controller is sequencing are almost always battery powered as well, this feature allows the entire system to easily be mobilized for performance, or installation, allowing for use in locations without access to a power grid.       The ultrasonic rangefinder in the front of the first version of The Voltage Slammer proved useful for detecting the presence of folks directly in front of the device, but was of little use when interfacing with the controller. The second version of the interface decided to increase to number of rangefinders to four by adding one to each side and one to the top of the unit.as seen in Figure 41. The added sensors give the interface a heightened sense of spacial awareness over the single front facing sensor in the first interface while also providing more options when mapping the interface for performance. 4.6.3 OneToFourFigure 42: OneToFour installed in a private residence circa 2016.OneToFour is a modified, extended version of the SSNES interface discussed in section 4.4.1 above which allows a single SNES controller to send its controller messages to up to four SNES consoles simultaneously. Just like the SSNES interface, OneToFour has two female jacks which accept any SNES compatible controller, is powered by an Arduino Mega and is powered off the host console.       While SSNES is interested in changing the way we play video games, the purpose of OneToFour is to explore divergence between seemingly identical video game consoles. However, although they appear identical from the outside, the four consoles used in OneToFour are each quite different on the inside. The SNES video game console went through a total of five hardware revisions from its release in 1990 to its discontinuation in 200334. [73] While each revision is supposed to perform identically, there are minute variances resulting from the diverging hardware: especially the audio card, video chips, and encoders. Each of the revisions process the games at slightly different rates and, when given the same controller data at the same time, will result in divergent game states. OneToFour provides a platform to explore differences in these systems.      While using consoles with different hardware revisions produce the quickest software divergence, even systems with the same hardware quickly creates vastly different play states. Part of this effect is due to differences in the internal clocks of each of the units. Whenever a game implements a random number, such as when an role playing game determines if the enemy will drop loot, the systems will usually produce different results. This causes the divergence to accelerate in games that rely heavily on indeterminacy. OneToFour highlights the illusion of control in video games by showing that even identical controller messages at identical times can result in vastly different results. 4.7 Chapter ConclusionThis chapter presented seven experimental interfaces under the context of six approaches to addressing human-circuit interaction. The User’s interaction with each interface was discussed in the chapter sections along with the motivations behind the interface and the design philosophy embodied in the device. Collectively, the design approaches introduced in this chapter serve as explorations into our relationship with electrical systems which strive to invite us to reflect on our relationships, interactions, and co-existence with electrical systems.Chapter 5 Approaches to Human-Robot PerformanceThis chapter introduces performances that exercise diversified techniques for affecting stage dynamics and compositional responsibility during human-mechatronic performance (Table 6). The first section, Non-Interactive Performances, covers compositions that do not require human performers and exhibit no elements of interactivity. Mechatronic Instruments Played by Humans, in contrast discusses a performance where the mechatronics instruments are always being directly controlled by human performers in real time. The third section, Humans Leading Robots in Musical Performance, presents a composition where the mechatronic performers are led by the actions of humans but are able to exhibit limited agency over the specifics of their actions. The final section, Social Performance, looks at social interaction with three pieces that challenge mechatronic personalities in outlandish social situations. Each of the performances introduced in this chapter seek to explore, in contrastive ways, the roles mechatronic entities can play in sonic performance art in 2017 and beyond.PerformanceNameHuman Performer’s RoleMechatronic Performer’s RoleAudience Role Robot WhispersOrchestrate robots through voices and a MIDI controllerAccompany human performersNoneBeatlesNoneProvide all contentNoneRobot Improvisational JamPlay both traditional and mechatronic instruments directlyTo be played by human performersNoneHedonism BotRitualistically interact with mechatronic entityRespond to human interaction, bring composition to conclusionNoneHello HumansNoneProvide all contentNoneComputer MusicNoneProvide all contentNoneAntiSocialNoneSocial interactionSocial interactionNo Humans AllowedNoneSocial interactionSocial interactionTable 6: Approaches to mechatronic performance presented in Chapter 5.5.1 Non-InteractiveThis section introduces three compositions which feature mechatronic instruments performing through-compositions without real-time guidance from humans. These compositions follow the “press play and sit down” presentation style popularized by the electro-acoustic, computer, and electronic music genera’ in the mid 20th century.[74] These compositions do not utilize human performers and no interaction occurs between the human composer and the mechatronic performers. Furthermore, there is no communication, or interaction, between the individual mechatronic instruments during the performance itself. Non-interactive mechatronic musical ensembles can be compared to the Nickelodeon, Orchestrion, or Player Piano all of which are mechanically programmed to perform the same handful of songs, in the same manner, on demand. Akin to the stage presence exhibited by these mechanical marvels, when mechatronic ensembles play without the presence of a puppeteer, or accompanying human performers, a distinct concert environment emerges separate from that found when listening to a metropolitan philharmonic orchestra. Often times the composer is not on stage during the performance and/or does not introduce the work, decentralizing audience attention. With less visual stimulation, again drawing parallels to many electro-acoustic music performances, the music, and technology, take center stage. Each of the works in this section abstain from interaction either because conceptually they have to, or because non-interactivity affords exploration into compositional avenues which would otherwise be hidden by gesture. 5.1.1 BeatlesFigure 43: Beatles is composed for MalletOTon (top) and Lydia.Beatles is an eight-minute etude written for the Machine Orchestra bots MalletOTon and Lydia (Figure 43) and is performed, in a concert setting, with no human presence. Beatles is coded in the ChucK programming language and was first performed in 2014, for the Composing for Robots final concert, in the Machine Lab at CalArts. Without introduction, the piece quietly begins with many low velocity messages being sent to Lydia’s solenoid beaters at quick random intervals. Each individual actuation is barely noticeable and only produces minute mechanical flutters, failing to approach the minimal force required to strike the piano strings with the solenoid plungers. The triggering rate, and overall velocity, of these message slowly increase over a period of a minute. After this gradual build, the messages begin to slow down and fade out as MalletOTon, positioned on the opposite side of the performance space, begins to exhibit the same behavior. Over the next minute MalletOTon goes through the same cycle Lydia just experienced. The two instruments trade off several times, progressively getting louder and faster with each transition. As the actuations approach the point of striking the strings, or keys, the composition enters into the next section.       Both Lydia and MalletOTon become active together and both begin receiving trigger messages from the server. Together the two instruments receive the messages at an increased rate and, at random intervals, one of the instruments will receive a message for the same solenoid in rapid succession causing the actuator to strike the instrument; resulting in a tone. For several moments the performance maintains this condition until, gradually, the messages slow. Over two minutes the messages slow to a stop and the composition is finished. 	The composition relies heavily on random number generators, indeterminacy, and the narrow velocity range when an actuator produces electro-mechanical noise, but does not strike its sound making mechanism. As result, every performance of Beatles is unique and each time the composition is actualized the realization will vary. Due to the unique orchestration and conceptual reliance on random number generations Beatles is unable to be performed by human instrumentalists and exists strictly in the realm of mechatronic computer music.5.1.2 Hello Humans      Hello Humans is a four-minute-long mechatronic music composition written for all of the robots of the CalArts Machine Orchestra. The piece is written in Ableton Live and was performed in a concert setting in the fall of 2016 in the Machine Lab at CalArts with no human presence on stage. The composition is through-composed with three distinct sections and will result in the same note messages and performance with each realization. Hello Humans begins with the chime of a bell on MahaDeviBot. As the reverberations of the bell fades into the room, BreakBot’s snare brush slowly starts to rub on the drum head. Slowly, bells, chimes, and cymbals quietly begin to accompany the brush along with the twenty Clappers: which are arranged throughout the ceilings rigging grid. For the remainder of the intro, the rest of the bots are introduced through short small motifs that are shared and exchange between them. As the introduction transitions into the middle section, the tempo increases from 63 Beats-Per-Minute (BPM) to 126BPM over approximately forty seconds. The middle portion of the song is marked by heightened activity between all of the bots along with tempo modulation; the tempo drops back down to 63BPM and then up to 198BPM during this time. The middle section attempts to conform to consonance and is arguably the most pleasant portion of the performance as a small handful of hummable motifs are passed between the instruments. The introduction of a solenoid repeatedly slamming a woodblock transitions the composition into the outro which begins with more repetitive, fast solenoids slamming noise making devices and woodblocks. At first they start off quiet, barely striking their sound producing mechanisms, but gradually they become louder and dominate the soundscape. The tempo once again begins to slowing increase as the other instruments in the ensemble begin to emulate the behavior of the wood block solenoids. The room becomes increasingly intense as the tempo increases and all the bots join in, creating an almost unbearable cacophony. The tempo tops out at 300BPM when each of the bots suddenly cease their performance. A final chime from the same bell that started the composition brings everything to a close.Figure 44: Bot positions in Machine Lab in relation to each other.      Hello Humans relies on careful attention to the spacialization of the bots to create both a visually and sonically engaging concert experience. When the Machine Lab is used as a concert venue for the Machine Orchestra, it is not configured as a typical concert hall with a large stage for the performers on one side of the building, with the audience facing the stage on the other side of the building. Instead the stage configurations for the Machine Lab are decentralized: half of the mechatronic instruments are permanently hung from the rooms ceiling grid in the rear half of the room, suspended 7-8 feet in the air, while the other half are resting on the floor dispersed throughout the other half of the room as seen in Figure 44: Bot positions in Machine Lab in relation to each other.. Chairs are placed along the walls while large rugs are placed on the floor to provide locations for people to sit, although standing and moving around the space is highly encouraged. One of the tactics employed for Hello Humans to dramatize the spacial aspects of the venue is careful selection of which bot plays when. For instance, for the first two minutes of the composition the Clappers are used strictly for their visual qualities and as a spacialization tool. The Clappers are triggered at very low velocity levels, sub-8 on the MIDI scale, ensuring that their onboard LED flickers but the bot makes no sound. By activating the Clappers in groups it is possible to visually focus audience member’s attention to where the bots are mounted. This effect is used in Hello Humans both to create visual movement to accompany the music and to introduce specific bots at key moments of the composition. Another tactic employed to heighten the specialization effect is by sharing melodic and rhythmic motifs between the different bots. This gave audience members something to latch onto and follow around the room. They could hear one simple melody, for instance, originate in Lydia, move over ten feet to the left to JackBox whom plays it several times before passing it to the other side of the room where MahaDeviBot and BreakBot discard the melody but playback the rhythmic content.       The compositional goal of Hello Humans’ is to create an arrangement which plays to the strengths of the Machine Lab as a performance venue while exploiting the extra-human capabilities of the mechatronic performers housed within. The composition is conceptually imagined to be written by the mechatronic instruments as a friendly, yet competitive, salutation to the audience consisting, primarily, of academically trained musicians. As result, Hello Humans relies heavily on intricate rhythmic and metric modulation where accurate execution is paramount in an attempt to impress the human audience by playing in a manner unbefitting of human performers. 5.1.3 Computer Music Figure 45: Computer Music as installed at the 2016 Digital Arts Expo.Computer Music is a mechatronic ensemble of floppy disk drives, CD-ROM drives, stepper motors, and hard disk drives as well as an eight hour long musical performance written for the ensemble which is shown as a non-interactive installation (Figure 45)35. When the Computer Music installation was shown at the 2016 Digital Arts Expo it was active between 12:00PM and 8:00PM performing a single eight-hour composition. Ableton Live running on a host computer orchestrates the activities of all the drives and motors.  The floppy disk drives are amplified through studio monitors using guitar pickups and a powered mixer.       The floppy disk drives are amplified using electromagnetic pickups that are placed under the drives’ tray motors. The floppies provide both the tonal center, as well as the primary texture, for the soundscape. The stepper motors raised and lowered the tops of the hard disk drives, which are constantly spinning. This provided a source of noise for the piece: if the lid is closed, the drive is silent; if the lid is opened, you can hear the disk spinning inside; which sound similar to wind or white noise. The CD-ROM drives utilized both their reading head motors, as well as their treys to participate in the music.      How ManyAmplificationPrimary UseSecondary UseMusical ContentCD-ROMs4NonePitched stepper motorsDisk treysAbout 2 octavesHDDs4NoneFiltered noisePercussive trey dropNoiseFDDs8YesPitched stepper motorsNoneBetween 2-3 octavesTable 7: Make-up and capabilities of Computer Music ensemble.      Each of the twelve pitch producing instruments play the same motif, but with each instrument pausing for a slightly different duration before repeating the theme. These variations are minuscule, fractions of a millisecond, but throughout the eight-hour rendition the CD-ROMs and FDDs fall out of sync before gradually realigning at the performance finale.36 The intent is not for gallery goers to stay for the entire composition or that they necessarily fully understand the scope of the performance. As the composition is approximately eight hours long, it is presented as an installation allowing guests to come and go as they please listening to as little or much of the piece as they desire. This passive presentations style strives to be undemanding on the audience. The composition, as written, can only be performed with mechatronic instruments due to both the length of the piece and the subtle complexity of the rhythmic phasing that the composition is structured around. 5.2 Mechatronic Instruments Played by HumansThis section presents the Robots Improvisation Jam as an example of a human-mechatronic performance where humans improvise using mechatronic, acoustic, and digital instruments. The mechatronic instruments are controlled with varying granularity at the note, score, and clip levels using a multitude of programming languages and physical interfaces. In these performances, the mechatronics are always being directly controlled by human performers and do not exhibit independence over their actions at any point. These situations can be compared to a typical rock show where each human performer plays an instrument, such as guitar or bass, and that instrument is unable to play without its human counterpart. During these performances, the humans are always in control and the mechatronics function as a guitar or bass: simply an instrument to be played by the human musician.5.2.1 Robots Improvisational JamThe Robots Improvisational Jam is an twelve-minute, live, human-mechatronic, group improvisational musical performance featuring eight student musicians improvising over a loose compositional form using a variety of mechatronic instruments, digital synthesis engines, audio feedback, and traditional string instruments. The Robots Improvisational Jam was the headline act for the 2015 Composing for Robots final showcase concert. During the performance, mechatronic instruments in the Machine Lab are controlled using grid controllers, laptops, microphones, and a variety of software systems including ChucK, Ableton Live, Reaktor, and Python. 	The Robots Improvisational Jam, contrary to what the name suggests, is a composition that foremost is about human musicians improvising using, mostly, instruments that are unique and new. Throughout the performance, the rhythmic, harmonic, and melodic content is dictated by the actions of the human performers while the robotics exhibit no agency over their actions. With so many performers, and no score or conductor, the piece required each participant to exercise considerable restraint, leaving silence for the other member to fill gaps. Relying heavily on the ear, the student performers each needed to exhibit total control over the sounds they are producing throughout the course of the lengthy improvisation. The Robots Improvisational Jam treated the mechatronic instruments with the same weight as the electric guitars used in the performance, with no preference given to any one instrument, or type of instrument, over another.5.3 Mechatronic Instrumentalists Led by HumansThis section discusses a human-mechatronic musical performance which incorporates reactive mechatronic systems that listen for input from human performers to determine its respective course of action. Robot Whispers, the case study for this section, is realized by an ensemble of seven mechatronic instrumentalists who react to the whisperings of two human performers according to the thresholds set by a third performer. In these class of performance, the mechatronic instruments are able to exhibit limited agency over what notes they play and when they play them but their overall behavior is dictated by humans in real-time.5.3.1 Robot WhispersRobot Whispers was performed in the CalArts Machine Lab in the fall of 2015 over approximately ten minutes. Composed in collaboration with Eric Heep37 and Danny Clarke38, Robot Whispers features three human performers who influence the behavior of over a half-dozen of the Machine Lab’s mechatronic instruments with the frequency content of their voices while reading poetry: which is algorithmically generated in real-time as the written score. We wanted to create a system which allows us to collaborate with the mechatronic instruments, adapt to on-the-fly changes during the performance, and utilize unconventional means of interaction. We are intrigued by the compositional affordances of textual language and the difference between listening to music and the spoken word and instead of directly dictating the notes that each of the robots play during the performance we decided to create a system for the robots to listen, and react, to the frequency content of our voices.       Throughout the performance a text score is algorithmically generated by a computer program in real time and is printed to a terminal window. The score contains information about the words that should be spoken, the tone in which they should be uttered, and the desired speaking speed. Eric and Danny followed the text score by quietly speaking the words into microphones. The audio from the microphones are processed with reverb, delay and other effects before being amplified and sent through quad sound into the performance space. Only the wet signal is amplified and after the extensive processing the original audio content is unintelligible.       Audio from the microphones is used to control the mechatronic instruments in the Machine Lab though a ChucK program which analyzes the frequency content of the microphones, in real-time, and splits up the energy content into several MEL bands each representing a range of frequencies.[75] The actuators for the robots in the Machine Lab are divided into three groups according to the relative pitch of each actuator. The high, medium, and low actuator groups are mapped to groups MEL bands according to relative pitch. Throughout the performance one of the human performers uses a MIDI controller to adjust the threshold for each of three groupings of MEL bins. At any given time, if the overall amplitude of the bands contained is higher than the threshold set by the MIDI controller, the robots will activate and begin to emulate the sounds uttered into the microphones: attempting to echo our language. 5.4 Social Interaction as PerformanceIn contract to the work presented in the other sections, which primarily seeks to create music that is interesting to listen to, the pieces introduced in this section are more concerned with the performance itself. They explore creating social situations that are not concerned with sonic results but instead are crafted for their performative and social dynamics. This section investigates extra-musical opportunities for mechatronic performance by using the mechatronic personalities which will be further described in section 6.6 below. In the following sub-sections, the performance installations No Humans Allowed, AntiSocial, and HedonismBot are each examined in accordance to their approaches to audience interaction, musical content, and social dynamics.5.4.1 AntiSocialAntiSocial is an extra-musical social performance which involves the mechatronic personality Craig intermingling with any number of audience members in an informal social gathering: such as a reception or party. AntiSocial can take place over any period of time, but when it was showcased in the fall 2016 MTIID Masters Show the performance lasted for two hours. Although AntiSocial is extra musical in nature, Craig is only able to express himself using solenoids and LED strips resulting in his interactions exhibiting rhythmic and (at times) tonal qualities.      Craig suffers from severe social anxiety and is poor at socializing with both robots and humans. When no-one is directly interacting with Craig he gives himself prep-talks in an attempt to boost confidence for the inevitable social encounter. As Craig sees someone approaching him, all his confidence fades and he is unable to speak, retreating into himself as he is gripped by social paralysis; Craig no longer activates any of his lights or solenoids, falling silent. If someone gets close enough that Craig is unable to ignore them he does his best to interact. Unfortunately, things go from bad to worse for Craig as he fumbles for the correct words, loudness, and pose to express his thoughts. 	These social situations are sonically realized in the following ways. When Craig is unable to detect someone within eight feet of his position, he will rhythmically trigger his solenoids in sequence at a slow, to moderate, speeds with low velocities. To represent him building confidence the longer no-one is detected the time between strikes will slowly decrease as the strike velocities increase. When Craig detects someone is approaching him, he shuts down and goes silent: only rarely activating one of his solenoids or LED’s. Lastly, if Craig detects someone within two feet of his position he attempts to converse as best he can. As he is inept at articulating his feelings and thoughts, the result is an arrhythmic splattering of loud, abrupt, and inappropriate solenoid strikes accompanied by excessively bright strobing light. 	This piece is not a musical performance, nor is it purely an interactive art installation, instead it is a performance of social interaction. AntiSocial is the authors first exploration into imbuing human personality traits, in this case shyness and social anxiety, onto a mechatronic entity and is the beginning of the work concerned with mechatronic personalities. 5.4.2 Hedonism Bot Figure 46: Ivy Liu feeding HedonismBot during a performance of Hedonism Bot.HedonismBot was composed in collaboration with Kyle McCarthy, Jake Turpin and Ivy Liu. HedonismBot is a social ritual that was performed in a concert setting with both mechatronic and human talents for the 2016 Composing for Robots final concert at CalArts.       The performance revolves around interactions with a mechatronic entity which has been given the characteristics of “HedonismBot” for the performance. HedonsimBot begins the performance in a deactivated state and only through being fed can the bot activate fully, and lead the ritual to an end. Each of the three performers use the iPad app Auraglyph39 to create soundscapes from simple waveforms and effects. Once a performer is happy with their program they approach HedonismBot, kneel down in front of it, and present the iPad to the bot. The feeding has the effect of temporally activating HedonsimBots solenoids and it briefly attempts to communicate before shutting down again. The performer stands back up and returns to their position giving room for one of the others to attempt to revive HedonsimBot. For the first few feedings, HedonismBot is unable to maintain enough energy to activate for longer than a few seconds but as the performance progresses HedonismBot gets stronger and is able to play louder and longer with each meal. Eventually, HedonismBot has been fed enough to come to life and the social dynamics of the performance shift. Instead of the human performers leading the pace and narrative of the ritual by creating sounds which are then fed into the robot, HedonismBot takes the musical lead. The robot cycles through its actuators and produces a consistent rhythm while the human performers fade their instruments out. During the last minute of the performance, Hedonism bot guides the audience through an outro without the accompaniment of any other performers.       HedonismBot is a performance which seeks to explore unconventional interactions between performers. The ritualistic act of feeding HedonismBot was as much social interaction as it is a part of the musical ebb and flow of the composition. For the first three fourths of the performance HedonismBot is passive, only reacting to the performers as they proceed to feed the bot. After the bot has been activated, the dynamic is flipped as HedonismBot takes center stage. HedonismBot explores the music it wanted to partake in earlier but did not have the energy. After 45 seconds of overzealous participation, HedonismBot “overheats” as it slows down before stopping completely: bringing the composition to a close.5.4.3 No Humans AllowedNo Humans Allowed (NHA) is an interactive mechatronic sonic installation where human participants are repelled by xenophobic mechatronic entities. NHA is extra-musical in nature but its three robots create a soundscape, by way of their solenoids, that can easily be analyzed for its musical content. NHA was installed in the WaveCave gallery in the Spring of 2017 for five days of intermittent performance.Bot becomes AggressiveBot becomes SurveillanceBot becomes ProductiveOther bot is AggressiveNo effectNo effectNo effectOther Bot is SurveillanceNo effectNo effectNo effectOther Bot is ProductiveForces into state of SurveillanceDecreases productivityIncreases productivity levelTable 8: How changes in on bots state affects the states of the other bots.      Parallel to the interactions seen in AntiSocial, each of the personalities in NHA have a total of three states: or moods. When no outsiders are detected in the gallery, the personalities are in their productive, happy state. They rhythmically activate their solenoids simulating a fully functioning productive state of mind. If a personality detects an outside presence in the gallery, such as a gallery viewer, their productivity steeply declines as the personality is preoccupied with the outsider and unable to accomplish their daily ‘work’. This mode is the surveillance state or cautious mood. If one of the personalities notices an outsider it alerts the other bots in the community which likewise enter into a state of surveillance; but with a higher productivity rating40 than the bot who sounded the alarm. The third state, or mood, is activated when an outsider ventures too close to the robot. The personality turns hostile as it flashes its lights, which are primarily dormant in the other states, and slams its solenoids in a disturbingly loud, fast, and arrhythmic way. The hostile personality alerts the other personalities in the gallery to the threat causing them to enter into a state of surveillance with a low productivity rating (Table 8).	Just like AntiSocial, NHA is not a musical performance nor is it an installation. Instead, it is a performance of social interaction, fear, and isolationism which invites us to question not only human-robot social interaction but conjointly human-human interaction on both personal and societal levels.5.5 Chapter ConclusionIn this chapter, four approaches to human-mechatronic performance were discussed through the lenses of mechatronic agency, reactiveness, and human-robot interaction. Each of these compositions were actualized as either installations, performances, or rituals and were introduced in each of the sections. While the styles, approaches, hardware, and software employed for each of these works were varied, they were all conceived, written, and actualized as explorations in the possibilities afforded by mechatronic presence in the social performance space. With mechanical and digital entities becoming increasingly common on the concert stage and in other performance venues, this body of work hopes to inspire performers to explore new possibilities for human-circuit interaction within the entertainment arena.Chapter 6 The Pantheon: A System for Mechatronic Art CreationThe Pantheon is a mechatronic art system which evolved out of an adaptation of the servers and hardware used by the music technology department at CalArts to control the mechatronic instruments residing in the Machine Lab. The Pantheon is structured to be modular, flexible, and easy to learn. This chapter provides an overview of the software and hardware that make up the Pantheon mechatronic system and constitute the technological core of many of the mechatronic installations, and inventions, presented in chapters 3 and 4.6.1 ServerFigure 47: The Pantheon Server initialization routine.The Pantheon server is written in the ChucK programming language[76]–[79] and plays host to mechatronic instruments and sensor banks in several of the installations presented in earlier chapters. To ensure that the server is able to keep track of any number of microcontroller clients, a handshake routine is run whenever the server is initialized to sort out the Pantheon microcontrollers from unrelated USB devices which might be plugged into the host computer (Figure 47). The routine requests an identification number (ID) from each USB device connected to the host computer. Connected Pantheon boards respond with their unique ID allowing the server to disseminate information about the microcontroller and assign a corresponding OSC address to the Arduino.      After the handshake is complete, the server begins to listen on the network for any OSC messages which correspond to the Arduinos who’ve completed the handshake. When the server recognizes a valid OSC address, and arguments, it forwards the message to the appropriate microcontroller using a custom serial communication protocol. In addition to the OSC listener, a supplementary ChucK program can optionally be executed to convert MIDI messages, from an internal IAC bus, into OSC messages that the server understands. This simple, yet flexible, system allows for the easy addition of any number of clients, can be controlled using any programming language able to output MIDI or OSC, provides a standardization for interfacing with the instruments, and gives the system administrator a built-in diagnostic to test if each of the devices are properly communicating with the server. 6.2 SensorsWhile most of the microcontrollers used in the Pantheon system only receive messages from the server, Arduinos which have onboard sensors report to the server with their sensor readings in addition to receiving messages from the server. During the handshake routine if any of the microcontrollers are discovered to be using sensors the server will spork a shred41 which infinitely polls the shield for readings. The Arduino firmware is kept simple simply reporting its raw sensor values delegating all signal conditioning and signal processing to the host computer. This greatly reduces the times needed for programming and calibrating systems after the hardware has been built by allowing for quicker calibration of the signal conditioning, providing a much more powerful machine to perform calculations, and reducing the number of times the new firmware needs to be uploaded onto the Arduino. The Pantheon polls the Arduinos telling each unit when to check the values of their sensors and report the result. This is done instead of the Arduinos continuously reporting their value to ensure the user maintains control over possible crosstalk between the sensors. This is especially important with ultrasonic rangefinders which have to be triggered one at a time, with an interval of inactivity between triggering, to avoid false positives and inaccurate readings. 6.3 Digital ConductorWhen the server is orchestrating many Arduinos that make up larger, more complex structures, such as with the mechatronic personalities in No Humans Allowed which each exhausting five Arduinos, the server initializes a “digital conductor” software process which organizes the multiple devices into larger constructs (personalities) while providing a comparatively intuitive interface for the artist to work with. The digital conductor orchestrates the overall activity of each of the personalities while acting as conduit for communication between the numerous Arduinos used in the ensemble. Just as an orchestral conductor does not play a violin or piano during a concert, the digital conductor does not exhibit direct control over what the personalities are doing. It instead acts as the glue that binds their communication and interaction to the world.6.4 OSCThe Pantheon uses the Open SoundControl (OSC) protocol to orchestrate communication between clients and servers. OSC has many advantages over comparative protocols, such as MIDI, which are often used for controlling musical instruments or installations. For one, OSC is built around the UDP42 internet protocol allowing it to work seamlessly over the network. This makes it possible for Pantheon installations and performances to decentralize via wireless communication. MIDI limits the values for notes and velocities to the range of 0 to 127 while OSC, on the other hand, is able to send full 32-bit integers (ranging from -2,147,483,648 to 2,147,483,637), floating point numbers, strings, and even audio data, or video frames, disguised as what the protocol refers to as “blobs”. [80], [81] One advantage of OSC over MIDI is its freedom to define custom communication schemas. While the OSC schema that The Pantheon uses for any particular project depends on the demands of the project, installations that utilize the mechatronic personality architecture follow a pattern of “/xyz/n/v” where:• x is the personality number• y is the board type (1: Brigid, 2: Homados, 3: Hermes, 4: Theia)• z is the board number of its type within its parent personality• n is the note number (0-63)• v is the velocity (0-1023)6.5 ShieldsArduino shields are modular circuit boards that piggyback onto a specific Arduino model instilling the microcontroller with added functionality. Many shields were created for the Pantheon system to handle a variety of commonalities when creating mechatronic installations and performances. From driving stepper motors, actuating solenoids and reading ultrasonic rangefinders, the functionality of each board is specialized and its construction varied. All of the Pantheon shields do, however, share a grouping of common traits:• All connectors used are Molex Mini-Fit Jr.o These robust connectors are able to withstand current of up to 9.0A, feature fully isolated terminals with locking housings, require low engagement forces, and adopt polarized housings.• All boards are conceived as shields for use with either an Arduino Uno or Arduino Mega microcontroller.• For all boards the connectors are consistently wired with the tops of the housings always corresponding with a connection to ground.• All boards have a RGB LED which is programmed to behave consistently between shields. The LED is red while booting after which it turns yellow until it responds to the server’s handshake routine. After completing the handshake the LED turns off and either remains off or can optionally flash blue each time a message is received from the server.6.5.1 BrigidFigure : Brigid six-channel actuator shield for the Arduino Uno.Brigid is the smallest of the two general purpose actuator shields and is designed for use with the Arduino Uno microcontroller. [82] Brigid has a RGB status LED, a I2C port [83], six channels of control for solenoids, DC motors, LED strips or other two-lead DC actuators, and an input jack for interfacing with an external power source. Each of the actuator channels utilize a Pulse Width Modification (PWM) pin on the Arduino, instead of a simple digital pin, for added flexibility and control. [84] The Brigid, along with its big brother Homados, includes JST jacks, along with pull-up resistors, for interfacing with the SDA and SCL pins on the Arduino; allowing for the easy attachment of I2C sensors.Figure 48: Circuit for a single Brigid, or Homados, actuator channel.      The Brigid shield, as well as the larger Homados solenoid driver, employ the same circuit for each of the individual channels (Figure 48). The circuit is engineered for activating solenoids but can be used for other components namely DC motors, LED strips, and relay switches. The reliability of both the Homados and Brigid in installations and performances is largely due to the AOT460 N-Channel Enhancement Mode Field Effect Transistors used for each of their control channels. The AOT460s are able to safely handle loads of up to 60V at 85A giving them enough headroom to handle most DC solenoids, relays, motors, and lights. [85] The gate of the transistor is connected to one of the Arduino Uno’s PWM pins through a 1kΩ resistor in series; limiting the current draw for each pin putting less strain on the Arduino while ensuring the transistors are not driven too hard. The transistor drain is connected to the positive end of the output jack where a 1N4004 clamp diode, with a path to PWR, protects the transistor from any possible inductive fly-back current caused by solenoids. [86] 6.5.2 HomadosFigure 49: Homados (v2) sixteen channel actuator shield for the Arduino Mega.Homados is the larger of the two actuator shields in the Pantheon system and is fashioned for use with the Arduino Mega microcontroller. The board supports sixteen channels of actuator control, three I2C jacks, and a RGB status LED. The first fifteen channels of the Homados driver utilizes PWM while the sixteenth channel uses a standard digital pin. The Homados is intended to function as a larger version of the Brigid shield and is to be used when six channels of control are inadequate. The Homados shield implements the circuit described in section 6.5.1 above and is functionally comparable to the Brigid in all ways.6.5.3 HermesFigure 50: Hermes four channel stepper motor shield for the Arduino Uno.Hermes is a Arduino Uno shield designed to control stepper motors. The Hermes shield provides the Arduino with an interface to two Toshiba ULN2803APG high-voltage, high-current darlington drivers which are used to control up to four stepper motors. [87] The ULN2803APG is a flexible chip which contains eight NPN darlington pairs with internal clamp diodes to protect against switching inductive loads. Each channel can operate at up to 50V at 125mA with a 5V, 0.5mA signal at the input. The ULN2803APG’s afford control over up to four permanent-magnet, or hybrid, unipolar stepper motors which are wired using either the 2-phase or 4-phase unipolar wiring convention. The darling pairs on the Hermes have quick turn-on and turn-off delays, at 0.1 and 0.2 microseconds respectively, allowing the attached stepper motors to be controlled at audio rate to produce sustained tones. In addition to the darlington arrays and output jacks Hermes additionally includes a single I2C channel, a RGB status LED, and two power jacks: one for the motors, and the other for the Arduino. 6.5.4 TheiaTheia is designed specifically for interfacing SR-04 ultrasonic rangefinders which are common sensor used in the work introduced in earlier chapters due to its cost efficiency and abundant availability. The shield features eight channels of control for the rangefinders as well as a RGB status LED. Although Theia is specifically structured for use with SR-04 rangefinders, the shield can alternatively be used for other sensors and actuators. Each of the eight 4-position Mini-Fit Jr. jacks provide power, ground, and two digital pins. The digital pins can be configured in the firmware to operate as either inputs or outputs allowing the shield to control 5V LEDs, motors, actuators, or sensors.6.6 Mechatronic Personalities – A Pantheon ProjectFigure 51: Model-A (left) and Model-B (right) mechatronic personalities.A mechatronic personality is a mechatronic musical instrument that is programmed to inherit human characteristics: specifically, those related to personality. The mechatronic personality project is interested in creating robotic entities that have musical capabilities but are not specifically designed to emulate any specific instrument or to create “musical” sound. The Mechatronic Personalities are given the personality traits of different fictional characters such as Craig in AntiSocial (5.4.1) or HedonismBot in HedonsimBot (5.4.2) and then are encouraged to interact with either performers, each other, audience members, or gallery visitors.      The author has created three mechatronic personalities for the purpose of exploring human-mechatronic interaction. Two models of personalities have been created: Model-A and Model-B as seen in Figure 51. Both are approximately five feet tall, are constructed primarily from extruded aluminum, are powered by the Pantheon mechatronic art system, have ultrasonic rangefinders poised at all four of their sides, and features dozens of solenoids and LED strips which can be controlled by the server. Model-A has six rotary solenoids, six large push-pull solenoids, and six smaller push-pull solenoids. None of the solenoids serve any explicit musical or mechanic purpose and are used for expression. The rotary solenoids are hanging in air while the small and large push-pull solenoids simply bang against the aluminum skeleton. Model-B does not have rotary solenoids but instead features sixteen additional push-pull solenoids. Only a single Model-A personality was constructed while two Model-B personalities were built. The Model-B personalities differ from each other minimally in their assembly and construction but are functionally exactly the same.	Apart from their minor differences, the personalities have many things in common. To streamline the amount to cables going to each robot, each of the personalities has its own seven-channel powered USB hub and power strip. The USB hubs allows the five Arduinos required to control all of the sensors, solenoids, and LED’s to be condensed down to be interfaced using a single USB cable. To accommodate the LED strips along with all the varieties of solenoids, each of the bots contains a 15amp, 24V and a 30amp, 12V switching power supply. The USB hub, and two power supplies, are plugged into a power strip allowing each bot to be powered with a single extension cable. To help with mobility, the personalities each have casters allowing them to be easily pushed around. 6.7 Chapter ConclusionThis chapter introduced the hardware and software systems behind The Pantheon mechatronic system for art creation.  Although still in its infancy, the current capabilities of the server and several of the Arduino shields was demonstrated through the examples of the Model-A and Model-B mechatronic personalities. The goal of this system is to ease in the creation of new mechatronic musical instruments and mechatronic driven installation art by providing a set of diverse modules along with easy to use, standardized software to control them. The hope is that my implementing The Pantheon the majority of the engineering and software design that goes into the creation of mechatronic art can be alleviated.Chapter 7 Conclusion7.1 SummaryThis document examined a portion of the work fathered by Nathan Villicaña-Shaw during his studies as a MFA student at CalArts. The projects presented served the authors questioning, exploration, and examination of human-circuit interaction within the context of performance and installation art. A background of relevant artists, movements, and ideas in the background chapter was followed by Chapter 3 which presented a multitude of installations that created varied interaction scenarios for visitors to navigate. Chapter 4 went into detail about the design philosophies behind the interfaces used in the installations presented in previous chapters while additionally introducing brand new interfaces which challenge our relationship with electronic devices. Chapter 5 detailed four approaches, with eight performance examples, for managing human and mechatronic agency during performance art within both concert and installation environments.       Through the completion of these projects, the author has refined his approach to interaction design not by means of iteration on a singular idea, or approach, but instead by employing new techniques with every project. The multiple lenses used to view the topic of human-circuit interaction has afforded a clarity in values, approach, and aesthetics to the authors artistic practice. This thesis documents years spent exploring, pondering, and musing on how our interactions with technology affect the human condition.7.2 Primary ContributionsThe majority of research in interaction design is conducted by industrial designers, product designers, web engineers, and computer scientists attempting to create intuitive ways to interact with complex hardware and/or software systems. [88] This corpus attempted to break away from the goals of conventional interaction design, which is concerned with interface transparency and idiosyncrasy, to explore interaction design through the disciplines of experimental music performance and mechatronic installation art. Throughout these works, one approach to interaction is not valued over another while all served to gather perspective on the field.7.3  Final ThoughtsThese projects were inspired by the author’s fascination with electricity, magnetism, and how the human race has harnessed electro-magnetism to run the world around us. In the 21st century, it is nearly impossible to avoid digital technology in the day-to-day grind and the work discussed in this thesis seeks to spark a discussion on how we fundamentally interact with electrical systems. The goal of the art tendered in this thesis is to invite us to question how we interact not only with electrical systems, but with everyone, and everything, in the world around us. 	The end of this document does not mark the end of this work or the authors fascinations with the topics contained herein. The author will continue to develop work that explores our interactions with technology, will continue to extend the capabilities of The Pantheon mechatronic system, and will begin building his own ensemble of mechatronic instruments.Bibliography[1]	J. Noyes, “The QWERTY keyboard: a review,” Int. J. Man-Mach. Stud., vol. 18, no. 3, pp. 265–281, Mar. 1983.[2]	P. A. David, “Clio and the Economics of QWERTY,” Am. Econ. Rev., vol. 75, no. 2, pp. 332–337, 1985.[3]	Jay David Bolter and Diane Gromala, Windows and Mirrors: Interaction Design, Digital Art, and the Myth of Transparency. 2003.[4]	B. Wands, Ed., Art of the Digital Age, 1. paperback ed. London: Thames & Hudson, 2006.[5]	S. T. Leo, “Method of and Apparatus for the Generation of Sounds,” US1661058 A, 28-Feb-1928.[6]	L. S. Theremin and O. Petrishev, “The Design of a Musical Instrument Based on Cathode Relays,” Leonardo Music J., vol. 6, p. 49, 1996.[7]	A. McPherson, “TouchKeys: Capacitive Multi-Touch Sensing on a Physical Keyboard.,” in NIME, 2012.[8]	S. Hotelling, J. A. Strickon, and B. Q. Huppi, “Multipoint touchscreen,” US7663607 B2, 16-Feb-2010.[9]	R. Ghazala, Circuit-bending: build your own alien instruments. Indianapolis, IN: Wiley Publishing, 2005.[10]	“Nicolas Collins Personal Website,” Nicolas Collins. [Online]. Available: http://www.nicolascollins.com. [Accessed: 30-May-2017].[11]	“Nicolas Collins,” Leonardo/ISAST. [Online]. Available: https://www.leonardo.info/led/806. [Accessed: 30-May-2017].[12]	Nicolas Collins, Hardware Hacking, 2.1 ed. 2004.[13]	N. Collins, Handmade Electronic Music: the Art of Hardware Hacking, Second edition. New York: Routledge, 2009.[14]	“Ciat-Lonbarde.” [Online]. Available: http://ciat-lonbarde.net/. [Accessed: 30-May-2017].[15]	Peterb:justb, “Peter B: Just B: Peter Blasser Biography,” Peter B, 11-Mar-2012. .[16]	P. Blasser, “STORES AT THE MALL,” Masters of Arts in Music, Wesleyan University, 2015.[17]	P. Blasser, “Pretty Paper Rolls: Experiments in Woven Circuits,” Leonardo Music J., vol. 17, pp. 25–27, Dec. 2007.[18]	“Peter Blasser (biography).” [Online]. Available: http://www.fondation-langlois.org/html/e/page.php?NumPage=372. [Accessed: 28-Apr-2017].[19]	“andrewmcpherson.org.” [Online]. Available: http://andrewmcpherson.org/. [Accessed: 30-May-2017].[20]	“Augmented Instruments Laboratory, C4DM.” [Online]. Available: http://www.eecs.qmul.ac.uk/~andrewm/. [Accessed: 30-May-2017].[21]	P. Bloland, “The Electromagnetically-prepared Piano and its Compositional Implications.,” in ICMC, 2007.[22]	A. McPherson and Y. Kim, “Augmenting the Acoustic Piano with Electromagnetic String Actuation and Continuous Key Position Sensing.,” in NIME, 2010, pp. 217–222.[23]	A. McPherson, “Portable Measurement and Mapping of Continuous Piano Gesture.,” in NIME, 2013, pp. 152–157.[24]	A. McPherson, “Buttons, Handles, and Keys: Advances in Continuous-Control Keyboard Instruments,” Comput. Music J., vol. 39, no. 2, pp. 28–46, 2015.[25]	A. McPherson and Y. Kim, “Design and Applications of a Multi-Touch Musical Keyboard,” Proc SMC, 2011.[26]	Victor Zappi and Andrew McPherson, “The D-Box: How to Rething a Digital Musical Instrument,” in Proceesings of the 21st International Symposium on Electronic Art, 2015.[27]	A. McPherson and V. Zappi, “Exposing the scaffolding of digital instruments with hardware-software feedback loops,” in Proceedings of the international conference on New Interfaces for Musical Expression, 2015, pp. 162–167.[28]	V. Zappi and A. McPherson, “Dimensionality and Appropriation in Digital Musical Instrument Design.,” in NIME, 2014, pp. 455–460.[29]	C. Paul, Digital Art, Third edition. London: Thames & Hudson, 2015.[30]	M. Rush and M. Rush, New Media in Art, 2nd ed. London: Thames & Hudson, 2005.[31]	R. Greene, Internet Art. New York, N.Y: Thames & Hudson, 2004.[32]	W. Benjamin, “The Work of Art in the Age of Mechanical Reproduction,” Film Theory Crit., vol. 4, pp. 665–82, 2006.[33]	A. Galloway, J. Brucker-Cohen, L. Gaye, E. Goodman, and D. Hill, “Design for hackability,” 2004, p. 363.[34]	Dagmar Kriegesmann, “BETWEEN PERCEPTION AND IMAGINATION,” Masters, Dutch Art Institute, Enschede, Netherlands, 2007.[35]	M. A. Net, “Media Art Net | Kubisch, Christina: Sound Flow Light Source – Forty Pillars and One Room,” 05-Oct-2016. [Online]. Available: http://www.medienkunstnetz.de/works/klang-fluss-licht/. [Accessed: 05-Oct-2016].[36]	“Christina Kubisch.” [Online]. Available: http://www.christinakubisch.de/en/works/installations/2. [Accessed: 25-Sep-2016].[37]	“CABINET // Invisible Cities: An Interview with Christina Kubisch.” [Online]. Available: http://cabinetmagazine.org/issues/21/cox.php. [Accessed: 25-Sep-2016].[38]	N. J. Brown and O. T. Brown, “Mechatronics ‘a graduate perspective,’” Mechatronics, vol. 12, no. 2, pp. 159–167, 2002.[39]	A. Kapur, “A History of Robotic Musical Instruments.,” presented at the International Computer Music Conference, 2005, vol. 31.[40]	L. Maes, G.-W. Raes, and T. Rogers, “The Man and Machine Robot Orchestra at Logos,” Comput. Music J., vol. 35, no. 4, pp. 28–48, 2011.[41]	“Biography Page Godfried-Willem Raes Composer and music maker.” [Online]. Available: http://www.logosfoundation.org/cv-god.html. [Accessed: 25-May-2017].[42]	G.-W. Raes, “NaMuDa: Gesture Recognition for Musical Practice,” Available -Line Www Logosfoundation OrgiiNamuda, vol. 123, 2010.[43]	G.-W. Raes, “Expression control in automated musical instruments,” in a paper presented at the, 2015.[44]	G.-W. Raes, Gesture controlled virtual musical instruments. Ghent, 1999.[45]	Peter Esmonde, Trimpin: The Sound of Invention. 2009.[46]	Trimpin and A. Focke, Trimpin Contraptions for Art and Sound. Seattle [Wash.]: University of Washington Press, 2011.[47]	Jim Murphy, Ajay Kapur, and Dale Carnegie, “Musical Robotics in a Loudspeaker World: Developments in Alternative Approaches to Localization and Spatialization,” Leonardo Music J., vol. 22, pp. 41–48, 2012.[48]	A. Kapur, J. Murphy, M. Darling, E. Heep, B. Lott, and N. Morris, “MalletOTon and the Modulets: Modular and Extensible Musical Robots,” New Interfaces Music. Expr., pp. 69–72, 2016.[49]	A. Kapur et al., “The Machine Orchestra,” in ICMC, 2010.[50]	A. Kapur et al., “The Machine Orchestra: An Ensemble of Human Laptop Performers and Robotic Musical Instruments,” Comput. Music J., vol. 35, no. 4, pp. 49–63, Dec. 2011.[51]	A. Kapur, “DIGITIZING NORTH INDIAN MUSIC,” University of Victoria, 2007.[52]	A. Kapur and M. Darling, “A Pedagogical Paradigm for Musical Robotics.,” presented at the The International Conference on New Interfaces for Musical Expression, 2010, pp. 162–165.[53]	O. Vallis, D. Diakopoulos, J. Hochenbaum, and A. Kapur, “Building on the Foundations of Network Music: Exploring Interaction Contexts and Shared Robotic Instruments,” Organised Sound, vol. 17, no. 01, pp. 62–72, Apr. 2012.[54]	V. Maisonneuve, Everything You Need to Know About Video Games. 2015.[55]	“Deceptive Art Installation by Jeroen Bisscheroux.” [Online]. Available: http://www.huhmagazine.co.uk/6616/deceptive-art-installation-by-jeroen-bisscheroux. [Accessed: 23-May-2017].[56]	C. Gaylord, “Super Mario Bros. has sold how many copies?,” Christian Science Monitor, 14-Sep-2010.[57]	“Super Nintendo Entertainment System,” Wikipedia. 12-Apr-2017.[58]	J. Ryan, Super Mario: how Nintendo conquered America. New York: Portfolio Penguin, 2011.[59]	“Consoles that won’t die: The SNES in 2013,” VentureBeat, 03-May-2013. .[60]	“Game Informer’s Top 200 Games of All Time,” Giant Bomb. [Online]. Available: https://www.giantbomb.com/profile/dantebk/lists/game-informers-top-200-games-of-all-time/32009/. [Accessed: 04-Jun-2017].[61]	D. Adams, The ultimate hitchhiker’s guide: [five complete novels and one story], Complete & unabridged. New York: Gramercy Books, 2005.[62]	“FORM+CODE In Design, Art, and Architecture by Casey Reas, Chandler McWilliams, and LUST.” [Online]. Available: http://formandcode.com/code-examples/transform-slit-scan. [Accessed: 23-May-2017].[63]	Andrew Davidhazy, “Slit-scan photography.” Rochester Institute of Technology, 17-Apr-2006.[64]	H. Gusterson, “From Brexit to Trump: Anthropology and the rise of nationalist populism: From Brexit to Trump,” Am. Ethnol., vol. 44, no. 2, pp. 209–214, May 2017.[65]	S. Jäckle and P. D. König, “Xenophobic violence after Brexit: how Britain could learn from Germany’s experience,” Democratic Audit Blog, 04-Nov-2016. [Online]. Available: http://www.democraticaudit.com/. [Accessed: 04-Jun-2017].[66]	M. Fisher, C. List, M. Slavkovik, A. Winfield, and M. Herbstritt, “Engineering Moral Agents -- from Human Morality to Artificial Morality (Dagstuhl Seminar 16222),” Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik GmbH, Wadern/Saarbruecken, Germany, 2016.[67]	“Video Art: Characteristics, Origins, History.” [Online]. Available: http://www.visual-arts-cork.com/video-art.htm. [Accessed: 23-May-2017].[68]	M. Puckette and others, “Pure Data: another integrated computer music environment,” Proc. Second Intercollege Comput. Music Concerts, pp. 37–41, 1996.[69]	“Raspberry Pi GPIO Pin information.” [Online]. Available: http://www.thebox.myzen.co.uk/Raspberry/Understanding_Outputs.html. [Accessed: 16-Nov-2016].[70]	Microchip, “MCP3008 Datasheet.” Microchip, 02-Jan-2008.[71]	“How do Guitar Pickups Work? | Atlantic Quality Design, Inc. Musical Products.” .[72]	“PAM8403.pdf.” .[73]	“Super Nintendo Entertainment System - Computing History.” [Online]. Available: http://www.computinghistory.org.uk/det/24546/Super-Nintendo-Entertainment-System/. [Accessed: 03-Jun-2017].[74]	B. Schrader, Introduction to electro-acoustic music. Englewood Cliffs, N.J: Prentice Hall, 1982.[75]	A. Lerch, Audio Content Analysis: an Introduction. Hoboken, N.J: Wiley, 2012.[76]	G. Wang, P. R. Cook, and S. Salazar, “Chuck: A Strongly Timed Computer Music Language,” Comput. Music J., 2016.[77]	G. Wang, A. Misra, A. Kapur, and P. R. Cook, “Yeah, ChucK it!⇒ dynamic, controllable interface mapping,” in Proceedings of the 2005 conference on New interfaces for musical expression, 2005, pp. 196–199.[78]	G. Wang, R. Fiebrink, and P. R. Cook, “Combining Analysis and synthesis in the Chuck Programming Language.,” presented at the International Computer Music Conference, 2007.[79]	P. R. Cook, S. Salazar, A. Kapur, G. Wang, and C. Reas, Eds., Programming for Musicians and Digital Artists: Creating Music with ChucK. Shelter Island: Manning, 2015.[80]	M. Wright, “Open Sound Control: an enabling technology for musical networking,” Organised Sound, vol. 10, no. 03, p. 193, Nov. 2005.[81]	A. Freed and A. Schmeder, “Features and Future of Open Sound Control version 1.1 for NIME.,” in NIME, 2009, vol. 4, p. 2009.[82]	Y. A. Badamasi, “The Working Principle of an Arduino,” 2014, pp. 1–4.[83]	F. Leens, “An introduction to I2C and SPI protocols,” IEEE Instrum. Meas. Mag., vol. 12, no. 1, pp. 8–13, Feb. 2009.[84]	M. Margolis, Arduino cookbook. Sebastopol, Calif.: O’Reilly, 2012.[85]	Alpha & Omega Semiconductor Inc., “AOT460 Datasheet.” .[86]	P. Scherz and S. Monk, Practical Electronics for Inventors, Third edition. New York: McGraw-Hill, 2013.[87]	Toshiba, “ULN2803A Datasheet.pdf.” Toshiba, 03-Dec-2010.[88]	B. Moggridge, Designing interactions. Cambridge, Mass: MIT Press, 2007.1 The Retrono, Discovery Synth, Voltage Slammer, and Modular SNES interfaces presented in Chapter 4 are examples.2 Introduced in section 4.1.1.3 Introduced in section 4.3.2.4 The Potsdamer Platz is an important public square, and traffic intersection, in the center of Berlin, Germany, lying about 1 km south of the Brandenburg Gate and the German parliament building.5 The Logos Ensembles was founded in 1968/1969 and has included dozens of members over the decades. The ensemble’s spring, 2017 members are Godfreid-Williem Raes, Moniek Darge, Karin De Fielyt, Marc Maes, Stefaan Smagghe, Kris De Baerdemacker, and Kristof Lauwers. 6 All are actuated with solenoid beaters. The crash symbol has two dampening mechanisms. The snare has a brush, which can be rubbed on the membrane, as well as a beater.7 The glasses, xylophone, cymbals and drums are directly struck by tubular push-pull solenoids. The guitar and bass strings each have their own picking mechanism, a string dampener, and five possible fret positions.8 Examples of games that belong to the rail shooter genera include: The House of the Dead 1, 2, 3, and 4; Star Fox 64; Virtua Cop 1, 2, and 3; Time Crisis 1, 2, 3, and 4; just to name a few. 9 The fabled Walt Disney Imagineer’s hidden Mickeys are subversive to the Disney corporation but do not attempt to deceive their audience and, for instance, would not be considered deceptive art.10 See section 4.4.1.1 for more information.11 Digital slit scan processing is a video process for transforming the frames of a video into a single image. [62] More information about the authors implementation can be found in sections 4.4.2 and Error! Reference source not found..12 The mechatronic personalities are covered in detail in section 6.6.13 More information about the mechatronic personalities can be found in section 6.6.14 More information about No Humans Allowed can be found in section 5.4.3.15 Information about Computer Music’s composition can be found in section 5.1.3.16 section 5.1.3 goes into detail about the musical components of the installation as well as the sonic capabilities of each of the ensemble members17 https://www.python.org/18 On Mac, the IAC bus allows for the creation of any number of virtual MIDI busses for inter-program communication.19 See section 5.1.3 below for more information about the composition.20 More information about Peter can be found in section 2.1.3.21 A Cape for a Raspberry Pi is analogous to a Shield for the Arduino platform. It is a small PCB designed to be attached to the GPIO headers of the Raspberry Pi and provides some sort of additional functionality usually though the integration of IC’s and/or discrete electrical components.22 A product of Hyperkin, a Chinese company which specializes in video game consoles that emulate well known old retro consoles such as the NES and SNES.23 6 * 9 = 42 the installation is discussed in detail in section 3.3.2.24 https://github.com/turicas/SNES25 Such as Super Mario World (1990), The Legend of Zelda: A Link to the Past (1992), or Donkey Kong Country (1994).26 Such as Mario Cart (1992), Teenage Mutant Ninja Turtles: Turtles in Time (1992), Super Double Dragon (1992), and Killer Instinct (1994).27 https://processing.org/, May 2017.28 A “First In First Out” buffer is a type of circular buffer that continually rewrites over the oldest values with the newest values.29 When compared to the first version.30 Faraday’s Law of Induction which states that changes in a magnetic field will produce an electric current to flow through a wire in close proximity. 31 Incantation is a circuit bending term originated by Reed Ghazala to describe a state of bent devices in which the device indefinitely produces sound that is not simply looping but is instead constantly producing new content.32 An RCA connector is a type of electrical connector commonly used to carry audio and video signals. The connectors are sometimes casually referred to as A/V jacks. The name "RCA" derives from the Radio Corporation of America, which introduced the design by the early 1940s for internal connection of the pickup to the chassis in home radio-phonograph consoles. 33 SPST: Single Pole Single Throw is the name for a type of switch which has two different states over a single channel.34 This is common in the video game industry which often releases a new generation console at a price point which undermines most if not all of the company’s profit knowing that they will be able to manufacture the console using cheaper parts in a few years.35 Information about the technical aspects of Computer Music and its installation at the 2016 Digital Arts Expo can be found in sections 3.5.2 and 3.5.2.1 in Chapter 3.36 See section 5.1.3 below for more information about the composition.37 CalArts 2016 – MFA MTIID Alum38 CalArts 2016 – MFA Composition Alum39 https://ccrma.stanford.edu/~spencer/auraglyph/40 A higher productivity rating will result in more actuator activations than a lower rating.41 Sporking a shred, in ChucK, generates a non-blocking, concurrent sub-process which runs on the same virtual machine as the host program.42 UDP or User Datagram Protocol is one of the core members of the internet protocol suite which allows computer applications to send messages over the internet to other hosts.--------------------------------------------------------------------------------------------------------------i