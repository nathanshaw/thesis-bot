California Institute of the ArtsElectromagnetic Translucenceartistic approaches to interaction design for installations, interfaces, and mechatronic performancebyNathan Villicaña-ShawA thesis submitted in partial fulfillment for the degree of Master of Fine ArtsHerb Alpert School of MusicMusic Technology: Interaction, Intelligence & Design2017
Supervisory CommitteeAjay Kapur, Ph.D.							MentorOwen Vallis, Ph.D.			   			     Committee MemberSpencer Salazar, Ph.D.							Committee Member

AbstractThis thesis focuses on a variety of approaches for complicating, simplifying, and exposing human- circuit interaction within the context of interactive installation art, interface design, and mechatronic performance. After a brief background of related work, this document presents several interactive-installations that exhibit varied approaches to human-circuit interaction. Next, an assortment of electronic-interfaces are discussed in terms of their approach to human-circuit [NV1]interfacing. An overview of The Pantheon, the authors comprehensive system for creating mechatronic instruments and sound art, along with a sampling of mechatronic performances are discussed in the final section. [NV2]The primary goals of this work include:• presenting a corpus of work that provokes dialogue on human-circuit interaction• exploring the creation and dissolution of abstractions separating humans from circuitry• to explore the idea of mechatronic/electronic personalities.
AcknowledgmentsI would like to thank my loving and supportive, family that have always believed in my abilities and have given me the freedom to explore what interests me. Kimby my beautiful, loving, partner that I am so blessed to have by my side to share this beautiful life with. I want to thank my parents for giving me my tireless worth ethic, sense of moral duty, and love of life.       My mentors, Ajay Kapur and Owen Vallis who have always had my best interest in mind and who have given me the chance to prove myself and my abilities. Who have recognize my talents and pursue what I am passionate about. For being my bosses, relying on me, and respecting my abilities. Without your guidance I would have never been able to soar to such great heights.      I would like to thank all the professors, instructors, and faculty at CalArts who have guided, inspired, and motivated me throughout the past four years. Tom Jennings for helping me to break free from the technology in my art. Sarah Roberts for helping me to start thinking about space, sound, and interaction in new ways. Spencer Salazar, for his calm wisdom. Clay Chaplin for embracing me as one of his own students.      I would like to thank all the friends and colleagues that I have studied, collaborated, and learned with throughout the years. Special thanks to Mason for inspiring me to think in larger scale, and for his respectful grace as an artist and human. Peter Blasser, Evelina Dominitch, Dimitry Gelfand, Mike Leize, Shaurja Benaurje.      Wolfgang, my dear friend, who is longer with us for his friendship, support, and talks.       Those who I lost contact with but influenced me artistically: John Meagher, Jarred Wikowfsky, Pat Dibert, Keith Bishop, Tessa Bishop.
ContentsAbstract	vAcknowledgments	viiContents	ixList of Figures	xiiiList of Tables	15Chapter 1	Introduction	181.1	Thesis Overview & Outline	20Chapter 2	Background	211.1	Exposing Circuitry	211.1.1	Circuit Bending & Hardware Hacking	211.1.2	Nicholas Collins	221.1.3	Peter Blasser	241.1.4	Andrew McPherson	261.2	Interactive Art and Interaction Design	291.2.1	Interaction Goals	291.2.2	Designing for Hackability	301.3	Tapping into Electromagnetic Systems	301.3.1	Christina Kubisch	311.4	Mechatronic Music	341.4.1	Godfried-Willem Raes	351.4.2	Trimpin	371.4.3	The Machine Lab	38Chapter 3	Human-Circuit Interaction in the Gallery	413.1	Interaction Rail	423.1.1	Electrical Box	433.2	Open Interaction	473.2.1	Cathode Ray Tubes	483.3	Deception	503.3.1	Symbiotic SNES	513.3.2	6 * 9 = 42	523.4	Unwelcoming Spaces	533.4.1	No Humans Allowed	543.5	Non-Interactive	553.5.1	Digital Rain	553.5.2	Computer Music	573.6	Conclusion	58Chapter 4	Designing Exploratory Interfaces	604.1	Abstractive Deconstruction	614.1.1	Discovery Synth	624.2	Camouflage and Exposure	654.2.1	Retrono	664.3	Re-Appropriation of Conventions	674.3.1	Rotary SNES	684.3.2	Modular SNES	694.4	Deception	714.4.1	Symbiotic SNES	714.4.2	Chroma-Temporal Surveillance Bot	744.5	Removing Agency	774.5.1	EavesDropper	774.6	Orchestrating Circuitry	794.6.1	The Voltage Slammer	804.6.2	OneToFour	834.7	Conclusion	84Chapter 5	Approaches to Human-Robot Performance	855.1	Non-Interactive	865.1.1	Beatles	875.1.2	Hello Humans	885.1.3	Computer Music	905.2	Mechatronic Instruments Played by Humans	915.2.1	Robots Improvisational Jam	915.3	Mechatronic Instrumentalists Led by Humans	925.3.1	Robot Whispers	925.4	Social	935.4.1	AntiSocial	945.4.2	Hedonism Bot	955.4.3	No Humans Allowed	965.5	Conclusion	97Chapter 6	The Pantheon: A Comprehensive System for Mechatronic Art Creation	986.1	Server	986.2	Sensors	996.3	Digital Conductor	1006.4	OSC	1006.5	Shields	1016.5.1	Brigid	1026.5.2	Homados	1046.5.3	Hermes	1056.5.4	Theia	1066.6	Mechatronic Personalities – A Pantheon Project	1066.7	Conclusion	107Chapter 7	Conclusion	1087.1	Summary	1087.2	Primary Contributions	1097.3	Final Thoughts	109Bibliography	111
List of FiguresFigure 1: Thesis outline.	20Figure 2: Required interaction for Electrical Box.	44Figure 3: Electrical Box spacial layout when installed in the WaveCave gallery.	45Figure 4: Listening station with two EavesDropper EM listening devices.	46Figure 5: Cathode Ray Tubes installation with three Retrono interfaces.	48Figure 6: Example output from Retrono synthesizer.	49Figure 7: Symbiotic SNES control flow.	51Figure 8: No Humans Allowed as installed in the WaveCave gallery at CalArts.	54Figure 9: Digital Rain as presented at the 2015 Digital Arts Expo.	55Figure 10: Computer Music at the 2016 Digital Arts Expo.	57Figure 11: Discovery Synth musical interface.	61Figure 12: Second revision of the Retrono Synthesizers.	66Figure 13: Rotary SNES circuit bent video game console.	68Figure 14: Modular SNES circuit bent video game console.	69Figure 15: Early version of Symbiotic SNES hardware.	73Figure 16: Sample output from Chroma Temporal Surveillance Bot.	74Figure 17: Chroma Temporal Surveillance Bot interface, final design on right.	76Figure 18: EavesDropper magnetic field listening device.	77Figure 19: EavesDropper magnetic flux sonification device with cover removed.	78Figure 20: EavesDropper electrical system diagram.	79Figure 21: The Voltage Slammer (v1) circuit bending probe and sequencer.	80Figure 22: The Voltage Slammer (v2) circuit bending probe and sequencer.	81Figure 23: OneToFour installed in a private residence circa 2016.	83Figure 24: Beatles is composed for MalletOTon (top) and Lydia.	87Figure 25: Computer Music as installed at the 2016 Digital Arts Expo.	90Figure 26: Ivy Liu feeding Hedonism Bot during a performance of Hedonism Bot.	95Figure 27: The Pantheon Server initialization routine.	98Figure 28: Brigid six-channel actuator shield for the Arduino Uno.	102Figure 29: Circuit for a single Brigid, or Homados, actuator channel.	103Figure 30: Homados (v2) sixteen channel actuator shield for the Arduino Mega.	104Figure 31: Hermes four channel stepper motor shield for the Arduino Uno.	105Figure 32: Model-A (left) and Model-B (right) mechatronic personalities.	106
List of Tables`Table 1: The installations presented in this chapter and their approaches to interaction.	42Table 2: Possible interactions with the Retrono interfaces.	50Table 3: Interfaces for challenging human circuit interaction modalities	61Table 4:  Sampling of play modes supported by Symbiotic SNES.	72Table 5: Approaches to mechatronic performance presented in chapter 5.	86Table 6: How changes in on bots state affects the states of the other bots.	96Chapter 1 Introduction      “art becomes interactive when audience participation is an integral part of the artwork. In making interactive art, the artist goes beyond considerations of how the work will look or sound to an observer. The way that it interacts with the audience is also a crucial part of its essence.”       Ernest Edmonds, Professor of Computation and Creative Media at the University of Technology in SydneyIn my daily activities, I am captivated by the authority of the electromagnetic spectrum. I  am fascinated by the diverse technology we have developed to harness, control, and leverage the irresistible power of this spectrum. Our social-personal relationships with electricity are complex, dynamic, and a constant topic of examination in my labors. I love analyzing how we, as humans, have constructed interfaces to interact with electrical systems. Over the past four years during my studies at CalArts I have chosen to express these interests through the design of interfaces that challenge our relationships with electricity, by producing performances that assign unconventional responsibilities to robotic performers, and designing hardware interfaces which invite us to rebuild our expectations for interaction.       In 2017, numerous conventions for human-circuit interaction will benefit from questioning, exploration, and discourse. Many of the ways that we interact with electronic devices are based on old standards of expression which were established in the 20th century, or earlier, and are outdated in today’s technological landscape. A good example of this is the QWERTY keyboard layout. This pattern for assigning functionality to the keys on a keyboard to the letters of the alphabet, and other symbols, originated from the physical limitations of mechanical typewriters. The layout is designed to space the most commonly used keys as far away from each other as physically possible. This is with the intent of slowing down the users typing speed and served to alleviate a tendency of typewriter technology to jam if two keys are pressed in rapid succession. QWERTY, however, remains the default keyboard layout on millions of new keyboards and laptops sold every year. Despite modern keyboards not suffering from the same mechanical limitations as their typewriter counterparts and alternate keyboard layouts such as the Dvorak Simplified Keyboard (DSK) having proved to increase typing speeds, while reducing finger movements and repetitive strain injuries, QWERTY is the only keyboard mapping many of us have ever used.      While the consumer sphere is slow to change, the world of interactive art is agile: constantly redefining the role of the gallery visitor, the artwork, and interaction as a whole. As Professor Edmonds commented in the opening quote, interactive art prioritizes movement and touch over sight and sound: which usually serve as effect to the interactive element. While sight and sound have traditionally been vitally important in galleries over the centuries, interactive art has added touch to the senses used in the gallery. The old motto of “look but don’t touch” has been transformed in many galleries into “look and please touch” and an open accepting audience is more than happy to play test subject to novel, new interactions.[9] Thus, interactive art is the perfect realm in which to explore the possibilities afforded by employing a fresh look at our relationships with electrical systems.      In the 21st century, it is nearly impossible to avoid digital technology during the day-to-day grind and the work discussed in this thesis seeks to re-open the discussion of not only how we fundamentally interact with these electrical systems, but with everyone and everything in the world around us. This corpus challenges human-circuit interaction throughout the disciplines of interface design, interactive installation art, and mechatronic music performance but foremost by creating diverse situations to explore interactive experience.      1.1  Thesis Overview & OutlineFigure 1: Thesis outline.A background chapter which covers artists and movements that have incepted this body of work is presented to provide a framework for remainder of the document to build upon. Next, a variety of installations created by the author, which each champion a unique approach to user interaction in the gallery, are presented in Chapter 3. Chapter 4 introduces eight interfaces which are designed with varying principles to human-circuit interaction and the role of the interface within interactive art.  Chapter 5 outlines seven examples of mechatronic and human-mechatronic performance which each explore the varied roles that humans and robots can play in mechatronic music performances.  Chapter 6 then provides an overview of a modular hardware-software system for building mechatronic instruments, sculptures, and installations which is utilized in a number of the projects discussed in earlier chapters and was developed during the author's studies at CalArts.Chapter 2 BackgroundThe installations, performances, and interfaces exhibited in this thesis are indebted to a multitude of contemporary and past individuals, movements, and ideas. This chapter presents a small selection of the most significant inspirations during the creation of the author’s projects. The sections introduced in this background serve to contextualize the work furnished in the later chapters while also helping the reader acclimate themselves to the author’s frame of mind.1.1 Exposing CircuitryContrary to popular convention, many of the interfaces discussed in this thesis seek to unveil electrical systems both physically and functionally1. The impulse to formulate electrical systems which interact directly with the bodies electrical properties has been acted upon by many designers and artists over the years from the Theremin in 1928, [10], [11] to McPherson’s TouchKeys in 2012, and the technology prevalent in touchscreens today[12]–[14]. The early circuit bending technique of “Laying Hands”[15], where the bender licks his fingers and touches random parts of an exposed powered circuit board to quickly determine active areas of the board, has been a mainstay in the tinkerer’s[3] repertoire for decades. 1.1.1 Circuit Bending & Hardware HackingThe circuit bending and hardware hacking communities served as my introduction to both electronics, and interface design, and have continued to influence the approaches I take when engineering interaction. Circuit bending and hardware hacking are both strange, anti-social, punk, anarchistic pastimes that invite us to subvert the manufacturer's intentions and “Void (Our) Warranty”.[10] Often these hobbies employ a knowledge-on-demand approach to electronics where one learns enough to be safe, have fun, and produce a working end product. The spirit of fun, play, and exploration which hackers and benders identify are coincidently paramount tenets of the artistic process employed in the work submitted in this thesis.[17] [21][15][18]1.1.2 Nicholas CollinsFigure 2: Nicolas Collins’ Original Hacking Manual and Handmade Electronic Music.Nicolas Collins, born 1954 in New York City, is a pioneer in the use of microcomputers in live performance. Collins makes extensive use of hacked and repurposed electronic devices and serves as the father of hardware hacking. Collins received a B.A. and M.A. from Wesleyan University. Collins has participated in over 300 concerts and installations throughout the world as both a solo artist and as a member of various ensembles. In 2006 Nicolas published the book Handmade Electronic Music: The Art of Hardware Hacking which has been instrumental in both my own development as a tech-artist as well as for scores of hackers, artists, and electricians from around the globe. Collins is a renowned curator for performance and installation art holding positions over the years at institutions including the Studio for Electro Instrumental Music (STEIM), School of the Art Institute of Chicago, and, [4]where he currently holds the positions of editor-in-chief, the Leonardo Music Journal.	The 2009 printing of Handmade Electronic Music along with the PDF The Original Hacking Manual were collectively the most influential texts in the development of my interest in creating art with electronics. While circuit bending taught me to become comfortable with exploring electronic circuits while being alright with not fully understanding my actions, the projects in Collins’ texts empowered me to build my own devices from scratch: to invent. The chapters in Handmade Electronic Music  explain how to replicate the project, how it operates, why it functions as it does, and even muses to possible extensions to the underlying concepts. It tells you why everything behaves how it behaves while not dumbing down the tech when it is important. To push the envelope, the book even introduces artists, and their creations, which are relevant to the topics of each section. My experience with these texts was always one of excitement: for the next thing I would learn, about being an artist, and exploring the field. The ideas, projects, and concepts introduced in these texts were simple and that is what makes them so powerful: they showed the power of a little technical knowledge mixed with a lot of creativity.1.1.3 Peter BlasserFigure 3: Peter Blasser tuning his rollable synthesizer before a performance.Peter Blasser graduated from the Oberlin College and Conservatory with a degree in electronic music and Chinese, with minors in computer science and ancient Greek, where he briefly taught electronic music and throat singing. In 2001 Blasser apprenticed with Don Buchla while honing his unique approach to synthesizer design. Blasser is an accomplished performer who has toured with various groups across the USA, usually performing with instruments he built. Blasser is currently CEO of the online company, and website, ciat-lonbarde.net which sells electronic instruments which Peter designs and builds. Blasser enjoys playing mentor and instructor and often holds workshops and lectures about his work with electronic instrument design.      For several years, Blasser developed instruments under the notion of “inner surface” which involves creating instruments that can produce sound on an exposed interior surface. These instruments involve unprotected circuits which performers are able to touch to directly affect the sounds produced. [21] [22] After his work with inner surface, Peter went on to develop “synthesis clothing” and “Paper Circuits” the latter of which he still develops.       Blasser’s paper[5] circuits, point-to-point soldering, and capacitive interfaces are stunningly creative, unique, and functional. Personality dominates his creations as Peter constantly creates new, fun ways to build relationships with the electronic devices we build while subtly questioning the rigid conventions of electrical design. For example, approximately one third of the component values in his schematics are left to the discretion of the builder providing a range of values that could be used instead of a singular value. Blasser does this so each instrument is unique and that the creator of the instrument has a stronger personal bond to the instrument. The closer you look at a Blasser schematic the more you notice Peter’s quirky terminology: including “harry caps” and “X” resistors. His circuits are intentionally unstable and unpredictable while being both reactive and generative. His electronic diagrams are hand-drawn and often use his own symbols in place of industry conventions which he develops according to the electronic effect the component has on the sonic output of the device. This makes it easier for one to transverse the functionality of the circuitry, while imbuing a sense of wonder and exploration when building one of his projects[23]Figure 4: Example "Paper Circuit" by Peter Blasser.      In a world dominated by rigid rules and equations, it is refreshing to embrace Blasser’s unique approach to circuit design which I was exposed to during a CalArts workshop with Peter in 2015. Talking to Blasser about his approach to circuit design while building one of his Old Mr. Grassi synthesizers was instrumental in the development of several of the projects tendered in this document. During that week, Peter instilled in me the importance of building a relationship with electronics. Blasser’s own work does this by both maximizing the amount of personality each of his creations have and ensuring that no two devices are the same. Additionally, the workshop experience helped me figure out ways to apply circuit bending techniques and approaches, which rely on a starting object to modify, to the origination of new interfaces which are not built from the dissection, augmentation, or modification of a preexisting electrical system. Peter’s instruments are intended to be touched and felt relying on our bodies’ electrical properties to function: creating a symbiotic relationship between the instrument and musician.1.1.4 Andrew McPhersonAndrew McPherson is at the forefront of the augmented musical instrument revolution and is an academic powerhouse.[24] Andrew McPherson started his academic career at the Massachusetts Institute of Technology with dual majors in music and electrical engineering where he continued his graduate studies completing a masters degree in engineering. In 2009, Andrew completed his Ph.D. in music composition at the University of Pennsylvania. After his Ph.D. studies, Andrew worked for two years as a postdoctoral researcher at Drexel University in the Music Entertainment Technology laboratory. In 2011, McPherson began work at the Augmented Instruments Laboratory, a research sub-group within the Centre for Digital Music (C4DM) at Queen Mary University of London (QMUL), where he toils with a group of Ph.D. students in developing new instruments, and interfaces, for creative musical expression. McPherson holds the position of Senior Lecturer in Digital Media in the QMUL School of Electronic Engineering and Computer Science. Everything that McPherson has produced in his graduate studies and beyond is worth attention, but there are two specific projects that are of particular importance to the topics discussed in this thesis due to their approach to interaction:  TouchKeys and D-Box. 1.1.4.1 TouchKeysFigure 5: TouchKeys capacitive sensor for augmenting keyboard instruments.The majority of McPhersons work in the field of instrument design is focused around the creation of augmented instruments, in particular the Magnetic Resonator Piano[6], which he defines as “a traditional instrument whose capabilities have been electronically extended through new sensors, new types of sound production or new modes of interaction.” The TouchKeys interface consists of a set of touch sensors that are attached to each of the keys of a full-size keyboard and function to determine where the player’s fingers come into contact with the keys (see figure 5). [25] TouchKeys are able to leverage our bodies’ inherent electrical properties to detect not only the location of our fingers on the keys but additionally the surface area of each finger in contact with the device. While the fidelity of TouchKeys is indisputably impressive, it is how the device leverages the electronics of our biology that enchanted me to begin work on many of the devices and installations introduced in later chapters. TouchKeys’ ability to fit onto any full-size keyboard inspired me to create devices which are able to harvest all of their electrical needs from a host device.1.1.4.2 D-BoxFigure 6: The D-Box circuit bendable musical instrument.The D-Box, created by McPherson in collaboration with Victor Zappi a colleague at the University of British Columbia in Vancouver, is not an augmentation of any preexisting instrument but is instead an entirely new instrument which struggles for comparison. The D-Box was created from the ground up to be circuit bent by its user and function as an electrical sandbox for new music creation. The personal watermelon sized box includes many features to provide an easy, portable, and engaging circuit bending experience. It provides easily-removable panels providing quick access to a breadboard that houses electric components which affect the synthesis engine running on a Beaglebone Black. The fixed sides house Force Sensitive Resistors (FSRs), and a speaker.  By designing for circuit bending and experimentation from the onset D-Box is capable to a much more varied range of sounds and behaviors than any single circuit bent instrument could hope to embody. [26] Aside from its sonic capabilities, what is truly exciting about the D-Box to the author is its expected mode of interaction: hacking.1.2 Interactive Art and Interaction DesignComputers and electronic devices have facilitated the rise of new art forms such as Internet Art, Digital Art, Glitch Art, and Interactive Art and has forever changed the workflow of many conventional artists including painters, photographers, sculptors, architects, and others. [7], [9], [27], [28] This creates a problem for any artist working in the digital realm as Walter Benjamin observes in the seminal essay “The Work of Art in the Age of Mechanical Reproduction”[7]. Benjamin argues that art of the past, such as painting or sculpture, possessed an “aura” that is lacking in mass-produced art. Walter used the camera as an example. He challenged that if any number of prints can easily be reproduced, where lies the art? One approach for addressing this issue has been for artists to focus on the production of art. With interactive installation art the artists are able to ensure that each participant has a unique experience with the installation. The uniqueness and personalized experience becomes the art in installation art; the art does not lie in an artifact, but instead in the experience. While this thesis delivers installations, interfaces, and performances there is only a singular art form that the artist works with: experience.[29]1.2.1 Interaction GoalsMany of the techniques applied to interface design in this corpus follow traditional tenets of interface design which according to Gillian Crampton Smith, the director of the Interaction Design Institute Ivrea, consists of:● Reassuring Feedback – you know you are doing something when it’s being done.● Navigability – your ability to keep track of location in the system and how to get where you are going.● Consistency – a command in one part of the system will have the same effect as in all other parts of the system.These tenets are to facilitate what Smith describes as “Intuitive Interaction” which are exchanges that minimize the conscious thought needed to operate the system.[6] These principles make good sense for devices including computers, automobiles, televisions, and phones as well as some of the installations introduced in later chapters, such as 6 * 9 = 42 and Electrical Box.      This is not always the case, and many of the hardware interfaces formed under the scope of this thesis were created with disparate goals. For these projects, the interfaces are the Art, should not be transparent, and often do not exhibit the traits of intuitive interaction. Devices such as the Symbiotic SNES and the Retrono, for instance, are designed in direct opposition to those priorities in an attempt to either force a reexamination of our expectations for interaction or implicitly draw attention to the interface: instead of simply being concerned with the results of its actions.1.2.2 Designing for HackabilityAmong the approaches used when designing and building the interfaces revealed in later chapters is “Designing for Hackability” as proposed in the 2004 international conferences Designing Interactive Systems (DIS) by Anne Galloway, Jonah Brucker-Cohen, Lalya Gaye, Elizabeth Goodman, and Dan Hill in the paper with the same name. Interfaces that are designed for Hackability are customizable: allowing the user to turn them into the device they want them to be. Hackable interfaces cultivate reciprocity between the designers, users, and the device itself while embracing unanticipated use with both transparency = and robustness in construction.[30] Applying these principles to interface design has been done before and many examples can be found from modular synthesizers to laptops. However, in the current age of hyper-normalization and increased technological literacy, a revitalized consumer desire for individuality and personalization is emerging. Hackability is one approach to fulfilling those desires and a topic of investigation in projects such as the Discovery Synth and Modular SNES. [31]1.3 Tapping into Electromagnetic SystemsHardware hacking and circuit bending are both inherently violent activities that tend to mutilate the original device: altering its capabilities, interactions, and even purpose. While that method is exemplified in several works presented in later chapters, and is a valid approach, not all use those methods. A source of provocation and the catalyst for many projects has been Christina Kubisch’s work as an installation artist. Christiana’s installations empower visitors to listen to electronic circuitry with her custom magnetic flux sonification headphones. The headphones enact their magic from afar without any violence, obtrusiveness, or even physical contact and are a direct departure from the exchanges typical with circuit bent devices. Her interactions are introverted yet exploratory, covert and empowering.1.3.1 Christina KubischFigure 7: Christina Kubisch with one of the listening devices used on her Electrical Walks.Christina Kubisch (b 1948) studied electronic music at the Milan Conservatory of Music. She quickly became unsatisfied with the conventionality of the conservatories offered topics of study [NV8]and she decided to enroll in the Technical University in Milan to take classes in electronics. In her own process of opportunistic design, as described in an interview for cabinet magazine, Christina stumbled upon what has become known as the Electrical Walks:“One day I bought a telephone amplifier, a little cube that you could put next to your telephone so that you could hear it without having the receiver in your hand. The cube was switched on, and when I came into the laboratory, it started to make really strange sounds in my handbag. I took it out and asked my professor what was going on. He explained to me that there were coils in this little cube, and that they picked up some of the machines in the room. It was like a flash in my mind. It was exactly at the time when I wanted to get away from performance and start producing installations.”She goes on to explain how her excitement over the technology commanded her installation configurations.“In my early installations, there were people wandering around with these little cubes in their hands, walking along thick electrical cables that had sounds running through them. I didn’t think about using the sounds of the outside world. I had no idea about electricity in general or that it could make interesting sounds. I just used the system of electromagnetic induction as a way of amplifying musical sounds.”After five years of searching for collaborators, she started working with an Italian headphone manufacturing company and commissioned twenty custom headphones with her electromagnetic snooping technology installed inside of large soviet headphones. She made several installations showcasing the custom headphones but eventually the set deteriorated and the project was put on hold. Almost a decade later, she found a sponsor which helped develop the technology to create an improved system. In 1999, at the Potsdamer Platz2 in Berlin, the new system was used for the first time in the installation Forty Pillars and One Room located in a large parking garage. She wrapped lengths of cables covered in green phosphorescent paint around forty of the free standing pillars in the parking garage creating the trunks of trees as seen from underground. Each of the pillars emitted a peculiar sequence of tones: with all of them sharing the common theme of water. The participants particular sonic experience is dependent on their position within the space and the specific time of day [32]. Forty Pillars and One Room interestingly uses electricity and concrete to create a world of implied nature. Christina created a sonic landscape in direct juxtaposition to the electrical and industrial materials she used for construction.Figure 8: Map from Kubisch's 2009 Elecctrical Walk in Milano.      In 2004, Kubisch officially began exhibiting works which used the EM listening devices in public locations under the umbrella name of Electrical Walks. Christina used the term “electrical walk” to describe the action of exploring a space’s EM properties by means of EM listening: just as one might go on a nature walk and listen for bird calls. For her, the Electrical Walks are not only for other people to enjoy, but are activities she enjoys doing for herself. The Electrical Walks, although closely related to her previous work with the listening devices, feature divergent source material and interactions than seen in her past work. Instead of planting composed electromagnetic signals in wiring that people listen to with her devices, Electrical Walks delegates the creation of sonic content to the environment. When researching a new walk, Kubisch embarks into an (usually) urban center with an EM listening device. She walks around the city and maps the magnetic activity. She uses the master map to create tours showing areas of sonic interest with routes that tour the cities magnetic features. The public receives copies of the routes along with her custom magnetic field listeners and are sent off to explore the environment at their own pace.       Christina Kubisch is of importance to the author's work because of her approach for creating unique experiences for her gallery viewers. This has influenced the interactions and experiences crafted by the work supplied in later chapters. Her carefully distilled and delicate treatment of technology and the electromagnetic spectrum has driven the author [NV9]to design for simplicity and elegance in his own interfaces. Kubisch’s work creates intimate experiences that can be shared by many people at the same time. Technology is at the core of her work and is necessary to tell the narrative and impart the experience she is attempting to enforce. This reliance is not shoved in the participant's face, instead, her installations abstain from telling the interactee about the wonders at hand and simply give them enough information to navigate the worlds she reveals. 1.4 Mechatronic MusicFigure 9: Mechatronics is a blend of many engineering and computer science disciplines.Mechatronics is an interdisciplinary field which blends electrical engineering, computer science, control engineering, telecommunications engineering, systems engineering, and mechanical engineering to create a wide variety of electro-mechanical systems from self-driving cars to robotic butlers. The field of mechatronic music is concerned with the musical implications of mechatronic systems within the context of human-robot musical performance. Many of the installations, and a majority of the performances, introduced in this paper utilize preexisting mechatronic instruments, are concerned with the creation of new mechatronic instruments, and/or involve music composed for mechatronic performers. This section does not provide a comprehensive overview of the history of mechatronics, nor does it mention scores of innovators in the field who have dedicated their lives to the creation of mechatronic entities, instead it aims to introduce the three most important influences on the author's work in the field. In the following sub-sections, Godfried-Willem Raes, Trimpin, and The Machine Lab are introduced in chronological order according to the genesis of their work.1.4.1 Godfried-Willem Raes Figure 10: Godfried-Willem Raes with a portion of the Man and Machine robot orchestra.Godfried-Willem Raes, born 1952 in Ghent, Belgium, is the mastermind behind the Man and Machine orchestra at the Logos Foundation, founded in 1968, where he proceeds over about 150 new music concerts a year.[33], [34]  In 1968/69 Raes co-founded the Logos Ensemble3 while about a year later, in 1970, Raes began performing with the Logos Duo in collaboration with Moniek Darge. In 1973, Raes began acting as programmer for the Philharmonic Society at the Palais des Beaux Arts in Brussels where he held the position until 1988. In 1990, Rae’s commitment to mechatronic instrument creation, and composition, lead to the founding of the Man and Machine Orchestra which currently boasts over forty-five wind, string, percussion, and noise-generation instruments and is one of the oldest robotic orchestras in the world.       Raes’ careful documentation and clean, refined method are an inspiration to how I try to conduct my own research. Raes, his students, and collaborators do a thorough job documenting the process of design and construction of many of the instruments that make up the Man and Machine orchestra. Raes takes meticulous notes on what is accomplished for the given project on each day it is worked on. The foundation freely publishes the information along with pictures of the work in progress on the Logos Foundation’s website. These valuable notes even contain information about what books and websites were used to research various bits of information: such as saxophone fingering diagrams.[NV10] These notes serve not only as an invaluable guide to discerning how the individual instrument was structured, but additionally provides insight into the overarching process that Raes and the Logos Foundation employs when creating new mechatronic instruments and performances.      In 1990, with the construction of Autosax, Raes championed the Logos Foundation into a new era, where the foundation shifted its focus away from of the design and use of analog and electronic hybrid sound generating devices and onto the creation of musical robots. Over years performing with purely electronic synthesizers, Raes became convinced that loudspeaker reproductions of sounds are nothing more than a virtualized reality of acoustic sound. He started building new mechatronic instruments and started writing compositions which take advantage of both the extra-human capabilities of the robotics and the liberties afforded onto human instrumentalists when they are able to interact with their instrument in unconventional manners. [35] This has developed into extensive research into the use of gesture recognition to interface with the robots of the orchestra. [36]–[38] The instruments that constitute the Man and Machine orchestra are beautiful, unique, and inspirational but it is Raes explorations into the roles of humans and robots in shared performance spaces which is of paramount importance to the pieces introduced in this document, specifically in the fifth chapter. 1.4.2 TrimpinFigure 11: Trimpin with Sheng High in 2006.Trimpin, born 1951 in Germany to a father who played wind instruments, is a kinesthetic sculptor, mechatronic inventor, and installation artist based out of Seattle, Washington. Trimpin played wind instruments before developing an allergy to brass after which he began experimenting with modifying electronic devices. In 1980, after studying at the University of Berlin and showcasing installations in Germany, Trimpin moved to America in pursuit of old, used electronic components, which he found difficult to find in Europe. Using repurposed materials, Trimpin currently works creating large-scale sound art in galleries and public spaces throughout the world.      Trimpin often employs the tactic of building multiples of a single object that are parallel yet contrasting. [NV11]This is used to great effect in installations such as Klompen (1990), Conloninpurple (1997), and Sheng High (2006) which is shown with Trimpin in figure 11. Unlike artists such as Zimoun, whose installations employ flocks of identical objects which create emergent complexity due to their numbers and not their differences, Trimpin’s multiples tend to be unique. For instance, in Sheng High each of the mechanisms is tuned to a distinctive note and the composition could not be realized without each and every device. Trimpin approaches his installations both as a visual artist and as a composer, a philosophy implemented in several of the installations introduced in the third chapter.      Just like Godfried-Willem Raes, an idea Trimpin is adamant about is the inherent power of acoustic sound over its loudspeaker counterpoint. Trimpin, along with many of his disciples [39], are adamant that speakers are inadequate at reproducing the experience of the original sound. This sentiment is a tenet in many mechatronic ensembles which tend to only feature mechanically actuated sonic content. Although the work in later chapters often does follow this approach, there are projects, namely Computer Music, which attempt to utilize only the electro-mechanical artifacts of the mechatronic instruments to create the soundscape.      Throughout his impactful career, Trimpin has maintained humble and willing to teach the wonders of mechanical art to anyone with interest. This I learned firsthand over the years at CalArts as Trimpin has served as a deeply valued mentor on several of the projects described in the following chapters. 1.4.3 The Machine LabFigure 12: The Machine Orchestra on stage at the Walt Disney Music Hall.The CalArts Machine Lab is the hub of the Music Technology department as well as the Digital Arts Minor and functions as the technological core of the institute. The Machine Lab is home to the nine mechatronic instruments that make up the Machine Orchestra which consists of a mixed ensemble of human and robotic performers which combines the musical elements of a laptop ensemble with the acoustic affordances of traditional instruments. [40]–[42]      Nine mechatronic musical instruments inhabit the Machine Lab at CalArts. BreakBot is a hanging percussion instrument that features a kick drum, a crash cymbal, and a snare4  [43]. Spread throughout the entire room, hidden in the ceiling grid, are twenty Clappers: each consisting of a single solenoid, with a blue LED inside of a ping-pong ball. MalletOTon is a mechatronic marimba that features 48 rotary solenoid actuated rubber headed mallets striking its keys  [41]. StringThing is made up of three steel strings picked by DC motors with plectrum mechanisms as well as steel post dampener mechanisms activated by solenoids. RattleTron is a percussion instrument that includes an assortment of hand percussion instruments along with three pipes struck with solenoids. MahaDeviBot is an Indian percussion robot that consists of a total of twelve solenoid actuators that strike frame drums, gongs, bells, wood blocks, and finger cymbals. GanaPatiBot is a percussion robot that features five plastic drums of various sizes each with multiple solenoid powered beaters. Lydia is a standup piano with twenty solenoids that strike the strings percussively, sixteen DC motors which ring the strings via custom rubber strikers, and a hacksaw which saws through a large steel bolt at the base of the instrument.  JackBox is both a percussion and string instrument which features twelve guitar and bass strings, three cymbals, eleven German beer glasses, an eight key xylophone, and three plastic drums which are all activated using dozens of solenoids5. Tammy consists of six brass bells struck with steel posts and six custom cut wooden keys directly actuated by solenoid plungers.  [43]      By way of my undergraduate and graduate studies with the Music Technology program at CalArts, the Machine Orchestra served as my introduction into the worlds of mechatronic music performance.  Over the past four years, I have gotten to know the multifarious instruments in the Machine Lab through hours spent repairing, maintaining, upgrading, and composing for them. My experiences caring for these robots shape the adjunctions made when designing my own mechatronic instruments and installations. Before I began building my own mechatronic inventions, the robots of the Machine Orchestra were the only mechatronic instruments I have ever worked with and I will always compare my own creations to those inhabiting the Machine Lab.

Chapter 3 Human-Circuit Interaction in the GalleryIn this chapter, several of the authors installations are described in terms of their approach to human-circuit interplay in the gallery.  The first section, Interaction Rail, presents Electrical Box as an installation which guides participants through a series of sequential exchanges. Next, Open Interaction presents Cathode Ray Tubes as an installation that creates an interaction structure that is simple, open, flexible, and branching. The Deception section bestows two interfaces: Symbiotic SNES, a project that reinterprets familiar games and their interfaces through the manipulation of control messages; and 6 * 9 = 42, a project that implements a program which misuses data to publically label users without their knowledge. Next, No Humans Allowed is tendered as an example of a hostile environment that discourages interaction in the Unwelcoming Spaces section. This chapter concludes with the Non-Interactive section where Computer Music and Digital Rain are featured as two example installations where interactivity is nonexistent.Installation NameInterfaceType of Gallery InteractionApproach to Human-Circuit InteractionElectrical BoxEavesDropperInteraction rail, linearObservational, extension of bodyCathode Ray TubesRetronoOpen, branching, non-linearDirect contactSymbiotic SNESSymbiotic SNESGame, deceptionRe-appropriated6 * 9 = 42Chrome Temporal Surveillance BotOpen, branching, non-linear, deceptionTypical, sinisterNo Humans AllowedNoneUnwelcoming environment, presence discouragedObservational, frictionDigital RainNoneNoneObservationalComputer MusicNoneNoneObservationalTable 1: The installations presented in this chapter and their approaches to interaction. 3.1 Interaction RailThe terminology “Interaction Rail” is used by the author to describe situations where a interactee encounters multiple interactions which must be executed in a specific order without the option for deviation. In video game design a game is considered to be “on-rail” if the manner the player travels is pre-determined on a line, as if literally on rails. This originally was done to allow for the use of high production backgrounds and higher quality pre-rendered graphics. Over time this technical approach to game design has become a stylistic one that still persists today.6 An example of an interaction rail, outside the context of gallery art or video games, is the financial transactions that use a credit card chip-reader. In order to pay for the goods, the customer must complete the interaction rail in order:1. Insert credit card into chip-reader2. Confirm that the amount is ok3. Sign for the purchase4. Remove the credit card from the chip-readerIf the customer skips one of these steps, or attempts to perform any step out of order, the purchase is rendered void.       Unsurprisingly, with installations that use these configurations, it can be difficult to ensure the attendee follows the rail. Thus, installations that exhibit this structure are burdened with guiding the visitors along the rail, usually while affording minimal confusion and discomfort onto the interactee. This can be easier to accomplish by closely guiding the participator with written, or implicit symbolic, guidance. The installation introduced in this section, Electrical Box, instead attempts to guide subjects without the use of explicate written or symbolic directions. The installation sheds its responsibilities of explaining itself to the visitor to allow it to impart a spirit of discovery and exploration to its attendees. 3.1.1 Electrical BoxFigure: Electrical Box as seen in the WaveCave gallery from September 9th through September 19th, 2016.Electrical Box offers a silent room ordained with over one-thousand feet of instrument cables hanging from the ceiling’s rigging grid of the WaveCave gallery at CalArts. Small, Light Emitting Diodes (LEDs) flicker at the ends of the cables suspended around the room. Several pairs of headphones hang in the far corners of the gallery. After walking to one of the corners of the gallery and equipping themselves with a pair of headphones and an accompanying small metal tin, participants can hear a faint static.  As they explore the room, radio broadcasts can be heard emanating from the cables. The tins, or EavesDroppers, empower visitors to listen into the radio stations hidden within the separate lengths of cable hanging in the chamber. The devices empower its users with the ability to sonically explore the electromagnetic energy permeating the space; energy which was inaudible when first entering the gallery.3.1.1.1 Approach to InteractionFigure 2: Required interaction for Electrical Box.Electrical Box guides visitors through a singular interaction rail (as seen in figure 12) by utilizing minimal direction to the visitor. In an attempt to avoid granting explicate written or symbolic instructions for how to interact with the installation, subtler methods were used to encourage viewers to stay on rail. This included minimal signage, the strategic placement of open space, lighting, and strategic interface design.      The signage for Electrical Box functions as clues for visitors to uncover steps in the interaction rail. A simple sign outside of the gallery only discloses the name of the installation and that the installation is “electro-magnetic” and “interactive”. The information disclosed on the sign is essential for helping visitors decouple the spaces expectations. Electro-magnetic informs visitors to the underling physics behind the installation while hopefully promoting an aura of danger and scientific adventure. The word “interactive” on the sign informs the visitor of the participatory nature of the installation; helping to ease them into a mindset of participation (assisting in steps II, III and IV). Figure 3: Electrical Box spacial layout when installed in the WaveCave gallery.      Although the installation utilizes over 1000’ feet of cable, 35% of the gallery is designated as free space which is void of cables, EavesDroppers, or any other clutter. The free space takes two forms: the walkways, or boarders, and the listening posts. The outside rows and columns of the grid, the frame, is left void of cables with the exceptions of the corners which house the EavesDroppers (see figure 13). The frame encourages viewers to enter into the space, approach the headphones, and to explore the room and functions as a walkway around the installation (assisting with steps I, II and V). This helps guide viewers though the interaction rail while softening the transition into the gallery by allowing intermediate commitment to the space.  In addition to the frame, EB harbors nine listening ports which each allow gallery viewers to stand, un-harassed by hanging cables, amidst the heart of the installation (assisting with step V). These alcoves made it easier to listen to a variety of signals simply by spinning in a circle, furthermore, the listening posts gave people a place to go once they discovered the EavesDroppers.Figure 4: Listening station with two EavesDropper EM listening devices.3.1.1.2 Lighting"A painter should begin every canvas with a wash of black, because all things in nature are dark except where exposed by the light."  -- Leonardo da Vinci“I will love the light for it shows me the way, yet I will endure the darkness for it shows me the stars.” -- Og MandinoThe approach to lighting in EB is as Mandino and da Vinci foreshadows, is a tool used sparingly to show folks the way. EB has three sources of light that participants are exposed to inside the installation space: the cable LEDs, the door light, and the flood-lights. This section discusses how each of these luminance sources were leveraged to guide the viewer to the interaction rail.      At the terminus of each of the cables are white LEDs which echo the audio signal being transmitted through the cables. These LEDs are the primary visual draw to most visitors due to their flickering and relative brightness in the dim room. As indicated in figure 12, seven LEDs are concentrated in the rear of the installation. The remaining nine LED’s are distributed through the rest of the space, leaving a single row buffer between the formation in the rear and the foreground. The rear formation creates a visual focal point which encourages folks not only to enter into the space but to additionally explore it (assisting with steps I and II).       When the doors to the WaveCave are opened, the gallery is flooded with outside luminescence while the large, heavy glass doors take upwards of eight seconds to close. As folks enter the gallery, the slow closing of the doors, and their descent into relative darkness, eases the transition into the installation by dampening the shock of the eyes adjusting and by simply giving the visitor time to adjust to the new environment before locking them inside.       The final source of light for EB are dim spot lights which are directed to the headphones and EavesDroppers which are resting on glass shelves the corners of the room. The spot lights are not bright enough to drastically change the overall ambience of the space, but do provide enough illumination to focus attention on the headphones (assisting with steps II and III).3.2 Open InteractionThe Open Interaction approach to interaction design provides multiple ways users can affect the installation while refraining from establishing a hierarchy of value over the varied interaction options. Open Interaction installation’s interactions are non-linearly structured where all possibilities are available at all times. This approach seeks to create a rewarding experience for both participants that are willing to spend the time to fully explore the capabilities of the space, as well as wallflowers which are uncomfortable touching things in front of strangers. This section introduces Cathode Ray Tubes as an installation which follows an Open Interaction design approach and which is conceived to create a hyper-reactive environment which facilitates a multitude of possible engagements.3.2.1 Cathode Ray Tubes Figure 5: Cathode Ray Tubes installation with three Retrono interfaces.Cathode Ray Tubes creates a feedback loop out of four cathode ray tube (CRT) televisions (TVs) and four modern knock-offs of the Nintendo Entertainment System (NES) video game consoles which have been slightly modified creating Retrono’s. The Retrono interfaces are sensitive to changes in the electromagnetic field surrounding them resulting to a vulnerability to the presence of human bodies. The Retronos, with no game cartridge inserted, produce the varied and evolving visuals seen in figure 15. The CRT TVs, which each Retrono is placed in front of, creates a strong electro-magnetic field which acts as an input stimulus to keep the Retronos in a state of flux. Changes in the visual output of the TVs result in corresponding changes in the EM field surrounding the Retrono units affecting its audio and visual outputs. This feedback loop between the Retrono and its TV creates an electrical system with numerous interactions while refraining from showing favor over one interaction over another. The goal of the technology is to create a reactive system which passively encourages folks to participate in whatever manner they are comfortable with.      Cathode Ray Tubes was initially exhibited in the WaveCave gallery at CalArts in Valencia, California from April 5th, 2016 through April 11th, 2016. Subsequently, the installation has been shown at the 2016 Digital Arts Expo and was installed in the Kadenze Inc. corporate headquarters in Valencia, California from May 2016 through June 2017.3.2.1.1 Interaction DesignFigure 6: Example output from Retrono synthesizer.The video and audio synthesized by the Retronos devices are affected by gallery goers in many distinct ways (see table 2). The experience of interaction is envisioned to be one of discovery with no rules or systems which force or limit any form of interaction. The desired interaction is both none and all of the options proposed in table 2. What is important is that the viewer discovers their own unique relationship with the space and is able to forge their own backstory and explanation of the space not that they do any specific thing. InteractionCommitmentEffect SeverityExample ResultNoneNoneBaselineOutput slowly oscillates as the feedback loop is the only source of inputStand within 3’ of unitMildMildThe unit will visually react to your presenceWave hand over RetronoMediumMediumThe unit will immediately visually and sonically react to your presence immediatelyTouch TVFullMediumThe static charge on the TV will discharge, providing a spike to the system before temporarily reducing the effects of the feedback loopTouch a RetronoFullMedium-MajorThe unit will immediately visually and sonically react to your presence. You will have more control over the effectTouch multiple Retronos at onceTotalMajor-ExtremeBoth units will immediately visually and sonically react to your presenceMove Retrono interfaceTotalMajorChanges the sensitivity of the feedback loopUse foreign objectFullMild-ExtremeDepends on the construction of the objectTable 2: Possible interactions with the Retrono interfaces.3.3 DeceptionUsually when creating interactive installation art, one of the fundamental tenets is to facilitate scenarios that are reactive to the interactee’s actions. If a guest pulls a lever, pushes a button or somehow interacts with the installation, it is traditionally desirable the visitor understands how their actions affect the installation or why they have no effect. in the book Windows and Mirrors, Bolter and Gromala referred to this quality in interaction design as “transparency”. [8] While deceptive art usually takes the form of optical illusions or visual trickery[44], the two installations demonstrated in this section deceive their participants with divergent tactics while striving for opacity. Symbiotic SNES supplies a familiar interface that behaves in unexpected ways while 6 * 9 = 42 presents a seemingly innocent visual sandbox while obscuring its true motives from the implicated party.3.3.1 Symbiotic SNESFigure 7: Symbiotic SNES control flow.Symbiotic SNES (SSNES) is an interactive installation where two visitors at a time are able to play the video game Super Mario World on a Super Nintendo Entertainment System (SNES) in a completely new way. Two unmodified SNES controllers which are plugged into the SSNES device which is in turn plugged into the SNES console (see figure 16). When participants start to play the familiar video game the subversive nature of the SSNES hardware reveals itself. The SSNES device controller messages from the players and performs a bitwise AND operation on the controller data before sending the resulting controller message to the console. The result is a truly co-operative gaming experience as both of the players are required to act in tandem to control Mario, the in game character, on his adventures. Mario is unable to move around the digital world unless the two players coordinate their button presses as the device only allows button presses occurring on both controllers to be passed to the console7. This is in contrast to the typical multiplayer gaming experience where you either take turns playing the same character or everyone controls their own separate avatar.       This installation could have easily been realized on any 16-bit era, or earlier, console and could have featured any game made for the chosen console, however, the SNES console and Super Mario World game have a broad nostalgic appeal. The SNES’s cultural familiarity and popularity was unmatched by the Sega Genesis, Neo Geo or TurboGrafx-16. But besides being the most popular video game console of the 16-bit era, the SNES has one of the most iconic controllers of all time which is still easy to understand for those who have never used one before. [45][46] Super Mario World is a natural choice for the game, released in 1990 and selling over 20 million copies worldwide, Super Mario World was a pack-in launch title for the SNES. The was created with a superstar team, being directed by Takashi Tezuka and produced by Shigeru Miyamoto, and with over 20 million copies sold. Millions of gamers are familiar with the simple controls for Super Mario World and (think they) know how the controller will behave when they play the game.       Choosing the most popular game of the most popular video game system maximizes the percent of interactees who might have had previous experience playing that game. This is important as the heart of the SSNES experience is rooted in the deception that the device exhibits. But if one has never seen a SNES before, and does not know how it usually behaves, there no longer is the opportunity for deception. While the game might still be fun to play, and its approach to co-operative gaming novel the initial experience will not be as impactful. 3.3.2 6 * 9 = 42According to the book series The Hitchhikers Guide to the Galaxy, written by Douglas Adams, 42 is “the answer to the ultimate question of life, the universe, and everything” as calculated, over 7.5 million years, by the mammoth supercomputer Deep Thought. When faced with the answer to the ultimate question, the beings whom constructed Deep Thought realized they did not know what the ultimate question actually is. Thus, the beings built a second ever more powerful, planet-sized supercomputer to calculate the question. After millions of years, the program came to a conclusion and it was revealed that without any doubt, the ultimate question is: “What do you get when you multiply six by nine?”. The aliens were baffled.[47]       6 * 9 = 42 seeks to bring attention to the deceptive nature of data while providing critique on our reliance, and trust, of data and the menace of omnipresent surveillance. The installation presents an iMac computer, with no keyboard or mouse, along with what looks like an unpainted guitar pedal with a button and a single knob. As the viewer approaches, they can see a temporally distorted video feed of their actions over the last few seconds. By pressing the button, or by turning the knob, they can modify the underlying slit-scan algorithm8 which displays its output on the iMac’s screen.[49] After the user is satisfied with their experience playing with the system, they leave and go on with their day. Unbeknownst to them, the underlying algorithm, the Chroma Temporal Surveillance Bot (CTSB), has a sinister agenda. Ten percent of the button presses cause the program to perform a “political profiling” of its user. The program saves the currently displayed frame; separates the red, green, and blue color information for each pixel; and averages the color content of each pixel over the entire image to determine if there is more Red or Blue relative to the other colors. Based on the results of this chroma analysis the program designates a political orientation to the interactee and then proceeds to tweet the image along with a proclamation of the users suspected political orientation. None of this activity is explicitly told to the user who only experiences a temporarily dropped framerate. In fact, the user has to use a computer, or internet connected smart device, to visit the CTSB twitter page to get any idea of the programs secret agenda.3.4 Unwelcoming SpacesNo Humans Allowed’s (NHA) mechatronic personalities do everything in their power to encourage visitors to leave by creating an uncomfortable, unnervingly hostile environment. NHA exhibits a circuit-centric interaction architecture where its personalities react with aggression, or silence, to the presence of a human; rendering the installation most active when no-one is present to observe the system. 3.4.1 No Humans AllowedFigure 8: No Humans Allowed as installed in the WaveCave gallery at CalArts.NHA creates a community of mechatronic personalities which reside in the gated WaveCave community. The personalities are xenophobic: reacting to outsiders via paralysis or violence. When the presence of a human is detected, the community’s productivity breaks down as the individuals are no longer able to function harmoniously. The result is a hostile space where outsiders are unable to enter without being attacked or shunned by a robotic society. Each of the three mechatronic sound sculptures, or mechatronic personalities, are constructed from extruded aluminum, acrylic, ultrasonic rangefinders, solenoids, and LEDs. The ultrasonic rangefinders allow each personality to independently detect the presence of physical presences in the gallery which affect their behavior. When no outside presence is detected, all members of the community are alive, active, and productive while the presence of a human, or other, disrupts the community. If the outsider ventures too close to any personality, the personality will either become paralyzed by hate and fear, and turn off, or attempt to “violently” deter the intruder with loud, abrupt, a-rhythmic noises. Either way, the personality is so preoccupied by the presence of the other it no longer actively contributes to the community as a whole, disrupting the harmony of society. By endowing these situations, No Humans Allowed hopes to shine light on the danger of xenophobic other thinking that is becoming increasingly common in our zeitgeist. With the rise of mechatronics, robotics, machine learning, and artificial intelligence (AI) questions of AI morality are no longer topics for future generations. Do we want our robotic children to exhibit violent, isolationist, bigoted tendencies or do we want them to be accepting, loving and caring to all other forms of live and intelligence?3.5 Non-InteractiveAlthough this thesis is primarily concerned with interaction between humans and electronics it does not advocate for interaction as the end to a means and this section exhibits two mechatronic sound art installations which exhibit no interactive content. Digital Rain is a dynamic installation which sonifies weather conditions from around the world, while Computer Music is a static installation where an ensemble of mechatronic instruments perform a through-composed, eight-hour long composition inspired by phase interference patterns. Both of these two installations benefit from providing no human-circuit interaction to their visitors due to divergent motives. 3.5.1 Digital RainFigure 9: Digital Rain as presented at the 2015 Digital Arts Expo.Digital Rain is a data driven art installation which explores the crossroads of algorithmic and generative music, emergence patterns, data sonification, and technology driven systems of expression. 192 electromagnetic relay switches, broken out into twenty-four units of eight, are arranged in a grid and mounted on the gallery wall. The relays are orchestrated by six Arduino Megas which are networked together and controlled by a hidden host computer. Weather conditions from a randomly selected meteorological station is collected by a Python script which then announces the location of the station along with the weather conditions via a text-to-speech algorithm projecting out of a speaker sitting in front of the installation. Meta forecastst conditions, specifically “sunny”, “rainy”, or “cloudy”, select the composition algorithm while parameters for the selected composition are a factor of the wind speed, humidity, temperature and barometric pressure. Digital Rain utilizes the mechanical ticking of the relays as the sonic source material for the installation. The relays, because of their precision and speed, are able to actuate fast enough to produce sustained pitch. This, in addition to their aptitude for arrhythmic snaps, allows for a wide variety of soundscapes which are surprisingly representative of the atmospheric conditions they strive to emulate. When the generative composition comes to a close, the system resets and a new station is polled.3.5.1.1 Approach to Non-InteractivityDigital Rain attempted to directly sonify weather conditions through the use of electromagnetic relay switches. The playback speed of the sonification was mapped to the temperature of the current station: with a slower playback when the weather is cooler. The humidity dictated the density of notes, with a higher humidity resulting in less time between actuations. The installation cycles through stations at a steady pace, only lingering on a single station for more than a minute if networking errors occur. 	Digital Rain could have been realized as an interactive installation. Visitors could have been given agency over what weather station was being represented or could have selected the different parameters which effect sonification. This would have changed the dynamic of the installation and would have violated its conceptual goals. Digital Rain attempts to reflect the varied, grand scale of the earths atmospheric patterns. It is attempting to impart on its viewer not only the specifics of the weather at one or two of the stations, but farther how varied the weather is across the globe at any one moment.  If guests are able to select individual weather stations, for instance, they are more likely to view the system as an educational tool than a work of art. If guests are able to affect the playback parameters of the sonification algorithm, the accuracy of the sonification suffers and it no longer sounds like the events it is attempting to emulate. Digital Rain, is an installation that, for conceptual reasons, does not benefit from human-circuit interactivity.3.5.2 Computer MusicFigure 10: Computer Music at the 2016 Digital Arts Expo.Computer Music, unlike Digital Rain, is an installation unaffected by outside persuasion. The mechatronic ensemble of floppy disk drives (FDD), hard disk drives (HDD), stepper motors, and Compact Disk Read Only Memory (CD-ROM) drives are controlled by four Arduino microcontrollers. A Python9 script listens to MIDI10 traveling through an internal virtual bus. For Computer Music, the composition is written in Ableton Live11 but the configuration allows any program or programming language capable of outputting MIDI messages to control the mechatronic ensemble. The FDDs and CDROMs are pitched and are amplified using single-coil guitar pickups positioned on the stepper motors of each device. The pickups each were attached a standard unbalanced ¼” instrument cables. The twelve pickups are amplified and mixed using a Mackie Onyx 16-channel mixer and the output was amplified using studio monitors. The HDD spindles are continuously spinning throughout the composition creating a source of white noise to intersperse with the pitched FDDs and CD-ROMs. The stepper motors each raise and lower the covers to the HDDs, revealing the spinning disk while filtering the noise. 3.5.2.1 Approach to Non-InteractionWithout an interactive element, or any indeterminacy due to external factors, non-interactive installations affords their creators precise control over their outcome: a necessity for Computer Music’s sonic content. Computer Music takes a deterministic approach to sonic art akin to how a typical single-channel video art work is presented. The video content is static and is screened, projected, or shown as a single series of images; if someone watches the film from beginning to end, they will witness the entire film and can no longer experience new content.[50] In the same manner, the composition Computer Music is static and the mechatronic interpretation of the piece remains consistent from one performance to another; if someone stays in the gallery for eight-hours, they will hear the entire piece. The Computer Music ensemble performs a composition written specifically to take advantage of their natural talent for keeping track of complex polyrhythms and precise timing variations. Each of the twelve pitch producing instruments play the same motif, but with each instrument pausing for a slightly different duration before repeating the theme. These variations are minuscule, fractions of a millisecond, but throughout the eight-hour rendition the CD-ROMs and FDDs fall out of sync before gradually realigning at the performance finale. The composition leaves no room for interpretation by the mechatronic performer and must be played exactly as written or the effect is ruined12. If any interactive element is injected into the system, it will interfere with the precision of the musical execution and will prove detrimental to the overall experience.3.6 ConclusionThis chapter presented five contrasting approaches to interactivity, with example installations, for gallery installation art. Electrical Box, in the Interaction Rails section, created a complex set of interactions which must be executed sequentially. Open Interaction showed Cathode Ray Tubes as an installation consisting of a highly reactive system open to interaction in a variety of ways: all with equal validity. The Deception section talked about installations that attempted to deceive users by either re-appropriating familiar interfaces with the example of Symbiotic SNES, or by disguising their true intentions, as with 6 * 9 = 42. Unwelcoming Spaces looked at No Humans Allowed as an installation which uses interactive elements to create an aware space which is hostile to gallery viewers. With Computer Music and Digital Rain, the section Non-Interactive compared deterministic and dynamic approaches to creating mechatronic installations.  Collectively, these installations and their corresponding philosophies to interaction are the authors attempt to question how we interact with electronic devices, specifically in the art world, and explore possible interaction frameworks for creating new forms of art.Chapter 4 Designing Exploratory Interfaces This chapter reveals detail about interfaces created for the installations presented in chapter 3, while additionally introducing new interfaces which explore human-circuit interaction (see table 3). The first contribution, the Discovery Synth, facilitates interaction by removing physical abstractions that separate humanity from circuitry. The second section introduces the Retrono which repackages preexisting electrical systems in a way that exposes them to direct human contact while transforming their function. The next section compares and contrasts two approaches to circuit bending retro video game consoles with the Rotary SNES and Modular SNES. The Symbiotic SNES and the Chroma Temporal Surveillance Bot are presented in the following section as examples of deceptive interfaces that either obscure their true intentions or sabotage their users actions. The EavesDropper is disclosed in the sixth section as an example which does not provide any control options to its user while the final section introduces The Voltage Slammer and OneToFour as two distinctive interfaces which act as puppeteer over multiple host devices. Project NameType of ProjectForm of InteractionDesign PrioritiesDiscovery SynthAudio/visual synthesizerButtons, pots, slidersRemoval of mechanical abstractionsVoltage SlammerSequencer for circuit bent devices, circuit bending toolRotary encoders, buttons, distance sensorsOrchestrating multiple circuit-bent systems from one deviceRotary SNESCircuit bent video game consoleRotary switchesTransparencyModular SNESCircuit bent video game consolePots, patchbayFlexibility, modularity, complexitySynergetic SNESControl message interceptor, and injector, for SNESNoneDeceptionRetronoAudio/visual synthesizerPresence, physical contactReduction, minimalismEavesDropperMagnetic flux sonifierNoneTransparencyTable 3: Interfaces for challenging human circuit interaction modalities4.1 Abstractive DeconstructionFigure 11: Discovery Synth musical interface.This section introduces the Discovery Synth (DS) as an example of a musical interface which applies techniques of deconstructivism and abstraction to its design. The interface seeks to eliminate any unnecessary mechanical abstractions that separate our bodies from the electronics; the interface’s buttons and potentiometers integrate the human body as the mechanical portion of the device.       The DS was created as a reaction to that observation that electricity, in its raw form, is of little use to our society. Lightning arching in rainclouds, or striking the ground, does little to ease the struggle of human existence just as the static electricity that builds on your body as you shuffle along a shag carpet is rarely anything but an annoyance. However, electricity can work miracles when harnessed using the correct tools. The power of electricity, in modern society, comes from the design and implementation of electronic components which are able to focus the physics of electro-magnetic energy to accomplish specific tasks. As a result, we usually interact with electricity via a physical abstraction or a tool which then electronically modifies the underlying circuitry. For instance, when you press the popcorn button on a microwave, the button physically separates your finger from the electronics that operate the microwave. The button, when pressed, connects two points in the circuitry which were unconnected before. This connection causes electrons to flow which alerts the microwaves logic to the certitude that the popcorn button was pressed. The DS project seeks to remove physical constructs, as in the popcorn button, which separate our bodies from the electricity which control the electronic device we are using.4.1.1 Discovery SynthThe Discovery Synth is a Raspberry Pi powered interface which is used in both installation and experimental music performance. The DS Raspberry Pi cape was invented for the CalArts AV Ensemble in collaboration with Clay Chaplin and uses Pure Data[51] both for the audio/video synthesis engine and to read values from the buttons, pots, and sliders. Each of the ensemble members built their own version of the DS and students were free to choose whatever specific components, enclosures, and configurations they preferred for their instrument as long as the final instrument contained at least sixteen voltage dividers and eight buttons. The authors iteration features eight custom buttons along with sixteen voltage dividers: eight of which are standard mechanical potentiometers while the remaining eight are custom. The instrument is crafted from reclaimed materials: the buttons and pots were housed in an old lamp casing, the main body was crafted out of wood found on the side of the road, and the tuning pegs were salvaged from an old guitar. 	The Raspberry Pi 2 features twenty-six General Purpose In/Out (GPIO) pins which can be used as either inputs or outputs at a logic level of 3.3V.[52] While the GPIO pins are adequate for many circuits, they are limited both by their strictly digital operation and minimal current sourcing capabilities. The Discovery Synth Cape13 gives the Raspberry Pi input capabilities which reflect an Arduino or equivalent microcontroller: bestowing the ability to read analog values from sensors in addition to expanding the available number of usable inputs. This is done with two MCP3008 8-channel, 10-bit, A/D converters which are used to read the voltage dividers. Circuitry for twelve buttons, two LEDs, and a LCD monitor is provided by the cape in addition to the A/D converters. 4.1.1.1 ButtonsThe DS’s buttons have no physical mechanism separating the action of pressing from the flow of electrical current. Every part of the design is functional and vitally important for the device to work properly. The process started conceptually by distilling how Normally Open (NO) electro-mechanical push buttons function; they internally contain two conductive paths which are electronically separated when no external force is applied to the mechanism. When the button is activated, the two parts of the circuit are joined through mechanical means to allow current flow from one side to the other.        While the DS’s buttons follow the NO model, providing no electrical connection in the resting state but allowing current to flow through the buttons when the button is activated. As the DS refrains from using any unneeded abstractions for the buttons, the buttons consist simply of two conductive bolts, spaced a few millimeters apart, bolted into the top of the interface. One of the bolts is connected to the 3.3v power rail while the is monitored by a GPIO pin on the Raspberry Pi. By pressing on the bolts with a finger, the interactee creates an electrical connection through their skin between the two bolts. 4.1.1.2 SlidersThe DS’s sliders are atypical in their design when compared to the eight potentiometer-style voltage dividers conjointly found on the interface. The goal when designing the slider-style voltage dividers was to remove the physical abstraction that rests between the human and the circuitry and to create a more direct interaction: just like with the buttons discussed in the previous section. Figure 23: How a potentiometer, or slider[NV12], functions.	A slider, or potentiometer, is mechanical component that functions electronically as a variable resistor. Although the exact manner in which sliders create a controllable variable resistance varies, it usually consists of a strip of resistive material, such as carbon or plastic, is touching a conductive wiper which is moved using mechanical force to adjust its point of contact with the strip. The three leads of the slider correspond with the two sides of the resistive strip and the conductive wiper.  A common use for slider, and how the DS is using its sliders, is to connect the component to a circuit so it functions as a voltage divider. By connecting the outside two leads of the potentiometer to the circuits power and ground and the center wiper lead to an input pin of an analog input the component is able to adjust the voltage seen at the A/D input node. 	The DS slider design functions identically to a conventional potentiometer; it has a strip of resistive wire (Kanthal) that comes into contact with conductive copper tape at different locations producing a variable voltage at the wiper node. What makes the DS sliders novel is not how they behave electronically, but is instead how they are constructed. Instead of separating our body from the electrons flowing through the circuitry, the DS sliders remove the physical mechanisms, along with any extraneous and unnecessarily casing, which keep the wiper attached to the resistive strip,      Each of the eight wires are strung across two bridges so each wire rests about a half an inch above a strip of copper tape. One end of the Kanthal wire is attached to system ground while the other end is connected to the power rail on the Raspberry Pi. The copper tape is hooked up to one of the inputs on one of the two MCP3008 A/D converter. The MCP3008 8-channel 10-bit A/D converters are able to be powered off the Raspberry Pi’s power rail and is controlled over SPI serial.[53] When the Kanthal wire is pressed against the copper tape a voltage divider is created.       A pecurality of the slider design becomes apparent when they are not being pressed. The Kanthal wire moves back to its resting position breaking the circuit and causing the interface to read a 0 for that channel.  In this way, the DS sliders do not hold their last value as a typical slider does. In a way, the DS sliders function as normally open potentiometers: meaning they will only return a value when physical force is being applied to them. This quirk ended up being desirable under some circumstances: working well for controlling expressive effects, filters, or sample playback parameters. At other times, this behavior became problematic. In compositions with parameters that demanded the ability to hold and maintain an intermittent value, the parameters had to be mapped to the standard potentiometers. To offset this limitation, the interface is often presented with several copper pipe segments. The pipes can be used to maintain an electronic connection between the copper tape and Kanthal wire allowing the performer to hold intermittent values on the sliders; freeing up fingers for other tasks.4.2 Camouflage and ExposureThis section looks at the Retrono interface, used in the Cathode Ray Tubes installation, as a case study in repurposing preexisting electronic systems while exposing their circuitry to direct human contact as a means of control. The Retrono interface is an appropriated video game console which is repackaged to facilitate a completely new and unconventional interaction schema between the device and interactee. The interface exposes, highlights, and reveals the internal circuitry of the device ironically disguising it from recognition and liberating it from the uses of its past life.4.2.1 RetronoFigure 12: Second revision of the Retrono Synthesizers.The Retrono interface is not a blue-sky project built from the ground up from a concept. Instead, creating a Retrono is an act of removal and replacement as oppose to construction. The interface is essentially a Retron retro video game console, a product of the Hyperkin corporation. The Retron console is a hardware emulator for the famed Nintendo Entertainment System, or the NES, and is capable of playing NES game cartridges and using NES controllers. To turn the Retron into a Retrono takes three steps:1. The controller ports, reset button, and power button are removed from the Retron2.  The red power LED is replaced with a white LED.3. The original plastic case is removed while the hardware is rehoused in a laser-cut clear acrylic boxThe boxes have four holes: one for the power, two for the video and audio outputs, and one large rectangular opening directly above where the unit’s main circuitry is housed for interfacing with the circuit board. The rectangular opening intentionally exposes the Retrono’s circuitry to outside interference. The case does not allow a game cartridge to be inserted into the console and once a Retron is converted into a Retrono it is unable to play NES games. The lack of a game does not deter the console from attempting to make sense of the electrical charges on the pins of the cartridge port as it would with an actual NES. The console attempts to decode the floating electrical charges at each of its input pins as video and audio data. The once video game console is transformed into an 8-bit audio-visual synthesizer whose output is can be manipulated by the electrical properties of its user’s body.	Retronos are most effective when CRT TV’s are used to display their output. The strong electromagnetic field emanating from the tubes turbocharges the reactivity of the Retrono creating a feedback loop between the TV and Retrono. As they are not functional in a conventional sense there is no right, or wrong, way to interact with a Retrono. They are created out of the desire for a hyper-reactive system that people can play with and explore without the burden of any expectations or instructions.4.3 Re-Appropriation of ConventionsThe two interfaces introduced in this section, the Rotary SNES and the Modular SNES, originated from the desire to develop techniques for circuit bending retro video game consoles. The Rotary SNES uses familiar interface components, two knob, to allow users to select from over a hundred contrasting combinations of circuit bends. Its more complicated counterpart, the Modular SNES, mimics a patchbay to allow for millions of configurations. This section explains the process of creating these two interfaces, describes their capabilities, and compares their relative success.4.3.1 Rotary SNESFigure 13: Rotary SNES circuit bent video game console.The Rotary SNES is a circuit bent Super Nintendo Entertainment System that has twenty-two video bends applied to the image processors on the console and is the precursor to the Modular SNES introduced in the next sub-section. The bends were found by opening up the consoles case and probing vias on the motherboard near the unit’s graphics processing ICs. The vias are bridged to the system’s ground, through a low value resistor, while the unit is running to see if any interesting glitches occur. The glitches vary from changing the color blend, mismatching tile data, inserting random noise, and even removing textures. The Rotary SNES can play any standard SNES game and allows its users to switch between bend variants using two 12-pole rotary switches (see figure 23). The common terminal for each switch is connected to system ground. One of the twelve positions is left unconnected, allowing for the user to choose “no bend” for that switch, while the other eleven positions are each attached to a different bends that were found in the console using the method described above.4.3.2 Modular SNESFigure 14: Modular SNES circuit bent video game console.The Modular SNES is a modified Super Nintendo Entertainment System that has been hacked and circuit bent using an Arduino Nano microcontroller.  While the Rotary SNES’s switches make it easier to modify the curated bends, the Modular SNESs patchbay inspired interface addresses a need for a version of the device that is more flexible, modular, and robust. The activity of circuit bending is steeped in exploration and discovery and the Modular SNES chose a patchbay interface to allow for flexibility while still benefitting from the advantages afforded by working within an established convention with the advantages of preexisting expectations for interaction. The Modular SNESs patchbay interface is controlled using patch cords to connect discrete sections of the SNES console to itself or the onboard Arduino Nano (see figure 24).       In contrast to the Rotary SNES, where all of the bends were discovered by testing the potential node to the system ground, the Modular SNES’s potential bends were discovered by probing the console with an Arduino Nano microcontroller. The Arduino Nano’s PWM pins were used to pulse, at varying speeds, potential locations on the SNES mainboard. If a particular node was found to produce interesting results when assaulted with the Arduino it was connected to a 1/8th jack which is attached to the SNES case (see figure 24). As the internal logic levels of the SNES operates at 5V and the system is organized with at least 500mA of current overhead, the console can internally power an Arduino Nano microcontroller: which the Modular SNES does. The Arduinos PWM output pins are connected to 1/8th jacks allowing the microcontroller to insert messages into the SNES bends. Additionally, analog input pins from the Arduino are ported out to 1/8th inch jacks allowing for the Arduino’s output patterns to be effected by any signal plugged in. The operations of the Arduino can furthermore be controlled using four potentiometers positioned on the top of the SNES case.	The Modular SNES, in addition to all the visual manipulation that the Rotary SNES is capable of, affords vast options for bending the host console. The patchbay interface allows for every possible bend to be connected to any other bend, or Arduino port, vastly increasing on the number of possibilities offered by the Rotary SNES. Additionally, the Modular SNES provides an output from the audio card, allowing for the visuals to be effected by a games music and sound effects. Furthermore, an connection which is attached to the controllers is provided allowing for in-game manipulation of the sprites under some circumstances. All of the input and output jacks are of standard 1/8th inch variety allowing the device to be interfaced with external hardware, including other Modular SNESs, as long as the interfaced system has an operating voltage of 5V. 4.3.2.1 Compared to Rotary SNESBoth the Modular SNES and Rotary SNES have been shown at various Makers Faires, Expos, Festivals, and installations often together with the Symbiotic SNES at the SNES Trinity. The Modular SNES is technically a much more capable devices that, with the right user, can create much more dynamic, exciting bends than its counterpart. With the ability to be programmed and with access to the systems audio and controller information the Modular SNES is simply a more powerful machine. However, the Modular SNES is prone to “crashing” and under some circumstances the system will reboot or refuse to respond to input. While these events are uncommon after learning what the most common triggers are, these crashes proved crippling during public events where the Modular SNES units were often exchanged for Rotary SNESs. The complexity of the Modular SNES works to its disadvantage. The Rotary SNES ended up being intimidating to many guests: its dozens of input and output jacks along wit the operational cabling ended up distracting from the Art, which is the circuit bent video game guests are able to play.      Together, these two projects showed me the values of transparency, simplicity, and minimalism when designing interfaces for public installations where the topic is not the interface itself. The Rotary SNES was far from perfect but succeeded in its transparency. It refrained from obstructing the circuit bent games, which are the topic of the installation, while still allowing for control over the system. 4.4 DeceptionThis section offers the Symbiotic SNES (SSNES) as well as the Chroma-Temporal Surveillance Bot (CTSB) as examples of interfaces that are schematized to deceive their users.  First, the SSNES is introduced along with its method of exhibiting familiar interfaces that behave in unexpected ways, breaking your expectations. Next, the 6 * 9 = 42 installation’s interface and software system, the CTSB, is submited as a more sinister example of a deceptive interface. 4.4.1 Symbiotic SNESThe SSNES is a small Arduino powered “black-box” which intercepts controller messages from standard SNES controllers and alters the data before sending it to an unaware SNES console. Besides the verity that the SSNES physically exists, there is no indication to either the SNES or the Player that an agent is acting on the data that the SNES is acting upon. The controllers do not look any different than a standard regular controller; as they are unmodified, regular controllers. The console receives, and acts upon, the messages just as it would without the SSNES inserted into the signal chain. The SSNES acts a saboteur or psi-operative, coloring the data into misinformation as it attempts to create new experiences from familiar technology. The SSNES operative can’t be reasoned with once installed and affords no agency to the participant over its behavior. What the system does to the controller date before sending it off to the SNES console depends on the operating mode chosen for that particular installation(see table 4). NameOperationResultUltimate Co-OpBitwise ANDOnly buttons pressed by both players are passed to the consoleOpposing ForcesBitwise XOROnly buttons pressed by one player will get passed to the console (multiplayer mode)Alternating-PressesButton PressesPlayers alternate total control over the character after a predetermined number of button pressesAlternating-TimeTurn LengthsPlayers alternate total control over the character over a set period of timeTwo FaceController SplitPlayers alternate control over different parts of the controllerTable 4:  Sampling of play modes supported by Symbiotic SNES.      There have been over a dozen single player and multiplayer modes programmed for the SSNES. What makes the single player modes differ from the multiplayer modes is not the number of people that play the game but instead is the type of game the mode supports. Both the single player and multiplayer modes require two players to operate. The single player modes will support SNES games where one player is controlling a character on screen at a time,14 while the multiplayer modes will support SNES games where two players are able to control a in-game character at the same time15. The single player modes each divulge  a way two participants can play a single player game together. For example, the “Agree” mode only sends messages (button presses) to the SNES if both of the input controllers are pressing the same button at the same time forcing the two players to press the same buttons as the same time on their controllers if they want to get anything done in the game world. This is contrary to the multiplayer experience offered when these games were originally released and is even different from any experience in modern games because the two players are not controlling two independent characters but instead have to work in tandem to control a singular character.  Each of the modes create a completely new and unique way to experience content that was created decades ago. The SSNES system allows us to play nostalgic classics for the first time with our friends and loved ones in a truly co-operative way. 4.4.1.1 Technical DetailsFigure 15: Early version of Symbiotic SNES hardware.Two SNES knock off controllers have their plugs cut off and wires stripped. The SNES controller uses five wires to communicate with the SNES console. The SNES powers the circuitry on the controller with the first two wires which are 5V and GND. The other three pins are for communication: clock, latch, and data. Thanks to the “SNES” Arduino library16 it is simple to read in incoming controller data. Once the Arduino knows which buttons are being pressed on the two input controllers it performs its logic before flipping digital pins that are connected to pads with wires soldered into them whose other ends are soldered to each of the button pads of a SNES controller. When the sensing side of the button pad reads 5v it sends an ‘ON’ messages to the SNES, instead of the controller receiving this voltage via the bridging of the two sides of the button, the Arduino mimics this be sending its own voltage to the pad.       As oppose to my other work with SNES consoles, this project is completely portable. The Symbiotic SNES system will work on any production SNES ever made and is not tied to any hardware modifications to the console itself. As the SNES’s internal voltage level is most always 5v, the console lends itself nicely to interfacing with Arduino microcontrollers, in this project the Arduino is directly powered through its output connections to the SNES console.        The SNES controller’s buttons are purely binary, meaning they are either on or off with no alternative: this lends itself nicely to bitwise logic operations. In fact, that is how all of the first mods started out.  If the controller inputs from the two controllers have a bitwise AND performed on them the resulting interaction will be that no messages get sent through unless both controllers are pressing the same button at the same time: which is the “Agree” mode. Likewise, if a XOR is performed on the incoming controller data only buttons that are pressed on a single controller are sent through, but if both controller press the button they cancel each other out and no message is sent to the host.      The second category of modes are the multiplayer modes which were designed to be used when playing a multiplayer competitive game. [NV13]4.4.2 Chroma-Temporal Surveillance Bot The Chroma-Temporal Surveillance Bot (CTSB) consists of a simple hardware interface along with a few hundred lines of Processing code. The interface is minimal and is made up of a single push button and a twelve-position rotary switch. The two components are housed in a small metal box which is typically used for guitar-effect-pedal construction. The enclosure is connected via USB to a host computer which runs the Processing program.Figure 16: Sample output from Chroma Temporal Surveillance Bot.	Upon initialization the CTSB creates three contrasting greyscale image masks: one for each of the primary colors. As the program runs, it stores the 256 most recent images captured from the host computers webcam and stores them in a FIFO17 buffer. With each new video frame the program calculates the color of each pixel one at a time. For each pixel that is being calculated the program references the value stored in each of the three master image mask’s corresponding pixel. The resulting RGB value is then used to look up a corresponding image stored in the FIFO buffer. This process is repeated for the green and blue values of the pixel before the entire being applied to all of the pixels to be displayed on screen for that frame.      Each of the hardware interfaces rotary switch’s twelve positions correspond to a distinctive combination of algorithms used to create the master masks used for the slit-scan processing18. When the switch is turned the program will recreate the three master masks and the video output will take on different aesthetic qualities. When the pushbutton is pressed the program reconstructs the masks using the rule set dictated by the rotary switch. The result is a variation of the aesthetics dictated by the switch.       While the resulting video produced by the CTSB is entertaining, beautiful, and somewhat magical it comes at a cost to the user. The hidden purpose of the CTSB is not to create beautifully psychedelic videos, but instead is to gather data about the political affiliation of the gallery visitors. Ten percent of the time, chosen randomly, the pushbutton is pressed the CTSB executes its surveillance routine. The program analyzes the color content of the frame it is about to display on screen. It adds up all of the red and blue values for all of the pixels and determines if the image overall contains more red or blue. According to the results of this “chroma analysis”, the CTSB determines the interactee is either Republican (if there is more red) or Democrat (if there is more blue). Although the system for determining a users political affiliation is obviously naive and erroneous, the CTSB proclaims the results of its findings along with its evidence (the image) on Twitter in the form of a tweet proclaiming allegiance to the affiliated political party.4.4.2.1 Interaction DesignFigure 17: Chroma Temporal Surveillance Bot interface, final design on right.The CTSB has gone through two major hardware revisions. The first version of the interface comprised of six N.O. push-buttons on the top of a BB aluminum project enclosure box. Inside of the enclosure, an Arduino Nano recognizes button presses and reports the events to a Processing sketch running on a host computer. The Processing program handles communication with the hardware, reading images from the computers webcam, computing the slit-scan processing, and displaying the video output. Each of the buttons on the controller gave the user an axis of control over the slit-scan processing. This included: changing the buffer length, reconstructing a mask, cycling through the mask categories, toggling between Red, Green, and Blue channel separation, inverting the color processing, tweeting a photo, and cycling through different frame rates. This multitude of control resulted in millions of different program states that could be achieved. After some testing, it became apparent that something simpler which facilitated a curated set of states was required. 	The second, and final, version of the interface contained a single button that redraws the slit-scan masks used to calculate the displayed image and a twelve-position continuous rotary switch which allowed the user to choose between the specific program states. The simplified design allows gallery viewers to consistently experience the program in a curated, yet dynamic, state. This eliminates confusion about each individual button’s effect on the displayed image, while still inviting exploration and allowing for a multitude of possibilities. As the interface needs to attract participants to collect data, it is important that the device appears friendly, innocent, and easy to use. The hardware interface is straightforward, familiar, and easy to understand to hide the software’s more sinister purpose. 4.5 Removing AgencyThis section introduces the EavesDropper interface, used in the installation Electrical Box, as a device that attempts to minimalize its user’s agency over its functionality by removing access to its operational parameters. The rationale behind this design determination, how the interface technically functions, and the psychological implications to its interactions are discussed.   One of the goals for the EavesDropper to impart on its user the sensation of gaining a superhuman ability while avoiding giving the user the impression that they are in control of the device, or even fully understand it. Figure 18: EavesDropper magnetic field listening device.4.5.1 EavesDropperThe Eavesdropper is exhibited to its users as a black box19 which obscures  its internal workings and logic from the outside. The device furnishes no instructions, explanations, or ever options for control to its users. The absence of any user control removes the need for a calibration process and operational learning curves while avoiding usage possible mishaps from device miscalibration. The experience and interaction that is meant to be imparted onto users is not calibrating the device, but holding the device up to EM fields. Ideally, the EavesDropper functions as an extension of the body; a task easier to achieve with a simple, intuitive interface. Scott Summers, a.k.a. Cyclops of X-Men fame, and his destructive vision is an apt analogy. Cyclops’ destructive energy-ray vision is always on as long as his eyes are open: always blazing away at 100% power. He has no option for calibrating the destructive power of his vision and relies on his ruby quartz glasses to keep the destructive might at bay. While I do not users to feel burdened by the EavesDroppers, I do want them to feel removed from controlling the devices. I wanted peoples sense of magnetic eavesdropping to be something that they either have, in fully power, or do not have.4.5.1.1 Technical DescriptionFigure 19: EavesDropper magnetic flux sonification device with cover removed.The EavesDropper devices leverage the properties of EM inductance to sense changes in the magnetic field that the device emits. Changes in this EM field, resulting from external sources, creates a voltage difference in the device which causing a small current to flow. This signal is amplified before being sent to a pair of headphones where it is transduced into acoustic energy as sound. Figure 20: EavesDropper electrical system diagram.      Each EavesDropper system consists of a small metal tin, which houses a battery and all of the electronics, as well as a pair of Telex headphones. The tins house a single-coil guitar pickup, a stereo amplifier, a ¼” headphone jack, and a lithium ion battery. The amplifiers are small 1.85cm x 2.11cm breakout boards that house PAM8403 ICs which provide enough amplification, at 3-watts to boost the output of the pickups to an audible level. The PAM8403’s features a filter-less architecture allowing it to drive the headphones directly eliminating the need for additional components and prolonging the devices battery life. The amplifiers are efficient Class-D amplifiers which operate off of a supply voltage between 2.5 and 5.5 volts allowing them to be powered directly from a lithium-ion battery and consume less power than a comparable Class AB or Class A amplifier. [54]4.6 Orchestrating CircuitryThis section introduces two interfaces which each control multiple electronic devices: The Voltage Slammer and OneToFour. OneToFour allows for a single pair of SNES controllers to control four SNES consoles concurrently while The Voltage Slammer is an experimental circuit bending probe and sequencer which is both used to circuit bend electronic devices, such as toys and radios, as well as control those devices in a manner analogous to musical sequencers. Both of these interfaces allow a single user to control multiple external electronic devices, that would otherwise require several people to operate, though a singular interface.4.6.1 The Voltage SlammerFigure 21: The Voltage Slammer (v1) circuit bending probe and sequencer.The Voltage Slammer interface is conceived to provide centralized control over a variety of circuit bent battery powered toys. The interface has gone through two major hardware revisions: the first interface was made of wood, included less channels of control and did not include as much visual feedback as the second revision.  Its first eight output channels produce Pulse Wave Modulation: a type of digital signal that allows the user to adjust the duty cycle which modifies the average voltage over the line. Each of these channels have a corresponding potentiometer and switch. The potentiometer is used to modulate the pulse width of the outgoing signal, affectively producing more current and higher voltage to the client device. The switch cuts off the current flow to the client device entirely. Small LEDs are positioned above the switches which light up along with the output signal. These outputs are additionally affected by a master delay pot stationed in the upper left hand corner of the interface. The master delay will rapidly trigger the outputs, this is effective for simulating switch or toggle conditions in bent circuits and is necessary for getting many instruments to reach incantation. The next five outputs are kindred to the first eight but have no feedback LEDs, no on/off switches and are arranged on the interface in a separate group. They are used to control motors in bent devices, or any other bend in which a constant current is desired and the output should not be effected by the master delay pot. In the rear of the Voltage Slammer, all thirteen outputs are accessible via RCA connectors20. The ring of the RCA cables is connected to the systems common ground which is shared by the Voltage Slammer and all connected devices. The pin carries the signal which originates from the devices Arduino. One additional RCA connection in which both the ring and pin are connected to ground, to allow for easier probing and bending. Lastly, the Voltage Slammer has an ultrasonic rangefinder which allows the interface to be aware of the presence of gallery viewers in the case of installation.Figure 22: The Voltage Slammer (v2) circuit bending probe and sequencer.      The second revision of the controller boasts sixteen rotary encoders, instead of the thirteen potentiometers found on the first version, which each feature built-in push-buttons and RGB LEDs. The encoders provide a much more natural experience to interactees during installation configurations. The system resets the encoder states in-between each visitor ensuring each interactee is yielded the same options. Because the encoder shafts support continuous motion, users are not stuck having to reset the controls back to a starting state themselves, instead, the color LEDs turn green indicating that the values have been reset. As the user turns an encoder it will change from green to yellow and eventually red as its value increases. The pushbutton on the encoder allows its user to reset its state: turning the LED green and resetting the value.       The SPST21 toggle switches were replaced with metal pushbuttons with LED rings. The LED rings eliminated the need for adding additional discrete LEDs to the interface and reduced the number of components needed. An additional upgrade form the first version is that the controller can be powered by rechargeable batteries instead of the typical USB, which the interface still supports. As the device is usually controlling battery powered electronics, the entire system can be easily mobilized for performance, or installation, in locations without access to a power grid.       The Voltage Slammer is not only a mechanism for controlling circuit bent electronics but is additionally a platform for assisting in the activity of circuit bending battery powered devices. The Voltage Slammer is part of an ongoing exploration in controlling circuit bent toys and instruments with Arduino powered interfaces.  It allows for simultaneous control over up to sixteen circuit bent devices.  The interface has a RGB-pushbutton-rotary encoder for each of its sixteen output channels as well as eight push-buttons with RGB LED rings. Lastly, to increase options for interactivity, the device included four ultrasonic rangefinders: one facing upwards, one facing forward, and one on each side.       The front and sides of the interface have built in ultrasonic rangefinders granting the interface a rough sense of spacial awareness. This proves especially beneficial when the interface is used in an installation setting. When the installation is idol, it will remain off for just under a minute before pulsing all its channels, calling out for interactees. It continues to repeat this cycle until someone approaches. Thanks to its ultrasonic rangefinder the Voltage Slammer was aware of the presence of humans. When no-one was near the device the device entered into a resting state. It stopped sending continuous signals to its circuit bent minions and was mostly silent, allowing the toys to complete the cycles they might have been currently engaged in. The Voltage Slammer will then proceed to randomly pulse one of the devices every two minutes. This is an act to silicate attention from anyone in the gallery. Once the presence of a body is detected by the voltage slammer the device will enter into its active state; again sending messages out to its toys.	The result of the Voltage Slammer’s interaction with its circuit bent toys was in a state of constant flux: it was hard to predict what the actual results might be from one sitting to another. The system behaves differently if there are five devices connected, or ten devices, as each new device that is added changes the electronic properties of the system. 4.6.2 OneToFourFigure 23: OneToFour installed in a private residence circa 2016.OneToFour is a modified, extended version of the SSNES interface discussed in section 4.5.2. which allows a single SNES controller to send its controller messages to up to four SNES consoles simultaneously. Just like the SSNES interface OneToFour has two female jacks which accept any SNES compatible controller. As oppose to the SSNES interface which has an output for each of the input controllers, OneToFour has a total of eight output ports. The Arduino Mega, which acts as the brain of OneToFour, is housed in a small clear plastic box, so that its feedback LED’s, one for each button, can be viewed if desired. The devices distribution of the control messages to the four individual attached consoles is done through common electrical connections. This ensures that the messages reach their destined consoles simultaneously. This devices affords experimentation with divergence between the consoles due to discrepancies in their internal clocks, their hardware capabilities, and other factors. 4.7 ConclusionThis chapter presented experimental interfaces under the context of six approaches to addressing human-circuit interaction. How users interact with the interfaces was discussed for each approach. Collectively, the design approaches introduced in this chapter serve as explorations into our relationship with electrical systems. They strive to invite us to minimalize our distance from the electrical systems we prevalently use and to rethink our relationships, interactions, and co-existence with electrical systems.Chapter 5 Approaches to Human-Robot PerformanceThis chapter introduces performances that exercise diversified techniques for affecting stage dynamics and compositional responsibility during human-mechatronic performance. The first section, Non-Interactive Performances, covers compositions that do not require human performers and exhibit no elements of interactivity. Mechatronic Instruments Played by Humans, in contrast discusses a performance where the mechatronics instruments are always being directly controlled by human performers in real time. The third section, Humans Leading Robots in Musical Performance, presents a composition where the mechatronic performers are led by the actions of humans but are able to exhibit limited agency over the specifics of their actions. The final section, Social Performance, looks at social interaction with three pieces that challenge mechatronic personalities in outlandish social situations. Each of the performances introduced in this chapter seek to explore, in contrastive ways, the roles mechatronic entities can play in sonic performance art in 2017 and beyond.PerformanceNameHuman Performer’s RoleMechatronic Performer’s RoleAudience Role Robot WhispersOrchestrate robots through voices and a MIDI controllerAccompany human performersNoneBeatlesNoneProvide all contentNoneRobot Improvisational JamPlay both traditional and mechatronic instruments directlyTo be played by human performersNoneHedonism BotRitualistically interact with mechatronic entityRespond to human interaction, bring composition to conclusionNoneHello HumansNoneProvide all contentNoneComputer MusicNoneProvide all contentNoneAntiSocialNoneSocial interactionSocial interactionNo Humans AllowedNoneSocial interactionSocial interaction	Table 5: Approaches to mechatronic performance presented in chapter 5.5.1 Non-InteractiveThis section introduces three compositions which feature mechatronic instruments performing through-compositions without real-time guidance from humans. These compositions follow the “press play and sit down” presentation style popularized by the electro-acoustic, computer, and electronic music genera’ in the mid 20th century.[55] These compositions do not utilize human performers and no interaction occurs between the human composer and the mechatronic performers. Furthermore, there is no communication, or interaction, between the individual mechatronic instruments during the performance itself. Non-interactive mechatronic musical ensembles can be compared to the Nickelodeon, Orchestrion, or Player Piano all of which are mechanically programmed to perform the same handful of songs, in the same manner, on demand. Akin to the stage presence exhibited by these mechanical marvels, when mechatronic ensembles play without the presence of a puppeteer, or accompanying human performers, a distinct concert environment emerges separate from that found when listening to a metropolitan philharmonic orchestra. Often times the composer is not on stage during the performance and/or does not introduce the work, decentralizing audience attention. With less visual stimulation, again drawing parallels to many electro-acoustic music performances, the music, and technology, take center stage. Each of the works in this section abstain from interaction either because conceptually they have to, or because non-interactivity affords exploration into compositional avenues which would otherwise be hidden by gesture. 5.1.1 BeatlesFigure 24: Beatles is composed for MalletOTon (top) and Lydia.Beatles is an eight-minute etude written for the Machine Orchestra bots MalletOTon and Lydia (see figure 35) and is performed, in a concert setting, with no human presence. Beatles is coded in the ChucK programming language and was first performed in 2014, for the Composing for Robots final concert, in the Machine Lab at CalArts. Without introduction, the piece quietly begins with many low velocity messages being sent to Lydia’s solenoid beaters at quick random intervals. Each individual actuation is barely noticeable and only produces minute mechanical flutters, failing to approach the minimal force required to strike the piano strings with the solenoid plungers. The triggering rate, and overall velocity, of these message slowly increase over a period of a minute. After this gradual build, the messages begin to slow down and fade out as MalletOTon, positioned on the opposite side of the performance space, begins to exhibit the same behavior. Over the next minute MalletOTon goes through the same cycle Lydia just experienced. The two instruments trade off several times, progressively getting louder and faster with each transition. As the actuations approach the point of striking the strings, or keys, the composition enters into the next section.       Both Lydia and MalletOTon become active together and both begin receiving trigger messages from the server. Together the two instruments receive the messages at an increased rate and, at random intervals, one of the instruments will receive a message for the same solenoid in rapid succession causing the actuator to strike the instrument; resulting in a tone. For several moments the performance maintains this condition until, gradually, the messages slow. Over two minutes the messages slow to a stop and the composition is finished. 	The composition relies heavily on random number generators, indeterminacy, and the narrow velocity range when an actuator produces electro-mechanical noise, but does not strike its sound making mechanism. As result, every performance of Beatles is unique and each time the composition is actualized the realization will vary. Due to the unique orchestration and conceptual reliance on random number generations Beatles is unable to be performed by human instrumentalists and exists strictly in the realm of mechatronic computer music.5.1.2 Hello Humans      Hello Humans is a four-minute-long mechatronic music composition written for all of the robots of the CalArts Machine Orchestra. The piece is written in Ableton Live and was performed in a concert setting in the fall of 2016 in the Machine Lab at CalArts with no human presence on stage. The composition is through-composed with three distinct sections and will result in the same note messages and performance with each realization. Hello Humans begins with the chime of a bell on MahaDeviBot. As the reverberations of the bell fades into the room, BreakBot’s snare brush slowly starts to rub on the drum head. Slowly, bells, chimes, and cymbals quietly begin to accompany the brush along with the twenty Clappers: which are arranged throughout the ceilings rigging grid. For the remainder of the intro, the rest of the bots are introduced through short small motifs that are shared and exchange between them. As the introduction transitions into the middle section, the tempo increases from 63 Beats-Per-Minute (BPM) to 126BPM over approximately forty seconds. The middle portion of the song is marked by heightened activity between all of the bots along with tempo modulation; the tempo drops back down to 63BPM and then up to 198BPM during this time. The middle section attempts to conform to consonance and is arguably the most pleasant portion of the performance as a small handful of hummable motifs are passed between the instruments. The introduction of a solenoid repeatedly slamming a woodblock transitions the composition into the outro which begins with more repetitive, fast solenoids slamming noise making devices and woodblocks. At first they start off quiet, barely striking their sound producing mechanisms, but gradually they become louder and dominate the soundscape. The tempo once again begins to slowing increase as the other instruments in the ensemble begin to emulate the behavior of the wood block solenoids. The room becomes increasingly intense as the tempo revvs up and all the bots join in, creating an almost unbearable cacophony. The tempo tops out at 300BPM when each of the bots suddenly cease their performance. A final chime from the same bell that started the composition brings everything to a close.      Hello Humans relies on careful attention to the spacialization of the bots to create both a visually and sonically engaging concert experience. [NV14]When the Machine Lab is used as a concert venue for the Machine Orchestra, it is not configured as a typical concert hall with a large stage for the performers on one side of the building, with the audience facing the stage on the other side of the building. Instead the stage configurations for the Machine Lab are decentralized: half of the mechatronic instruments are permanently hung from the rooms ceiling grid, suspended 7-8 feet in the air, while the other half are resting on the floor dispersed throughout the room. Chairs are placed along the walls while large rugs are placed on the floor to provide locations for people to sit, although standing and moving around the space is highly encouraged. One of the tactics employed for Hello Humans to dramatize the spacial aspects of the venue is careful selection of which bot plays when. For instance, for the first two minutes of the composition the Clappers are used strictly for their visual qualities and as a spacialization tool. The Clappers are triggered at very low velocity levels, sub 8 on the MIDI scale, ensuring that their onboard LED flickers but the bot makes no sound. By activating the Clappers in groups it was possible to visually focus audience member’s attention to where the bots were mounted. This effect was used in Hello Humans both to create visual movement to accompany the music and to introduce specific bots at key moments of the composition. Another tactic employed to heighten the specialization effect was by sharing melodic and rhythmic motifs between the different bots. This gave audience members something to latch onto and follow around the room. They could hear one simple melody, for instance, originate in Lydia, move over ten feet to the left to JackBox whom plays it several times before passing it to the other side of the room where MahaDeviBot and BreakBot discard the melody but playback the rhythmic content.       The compositional goal of Hello Humans’ is to create an arrangement which plays to the strengths of the Machine Lab as a performance venue as well as the extra-human capabilities of the mechatronic performers housed with. Hello Humans relies heavily on constant, and precise, rhythmic and tempo modulation where precise execution is paramount. Hello Humans is near impossible for human performers to realize due to complexities in its rhythmic structure, tempo, and orchestration. 5.1.3 Computer Music Figure 25: Computer Music as installed at the 2016 Digital Arts Expo.Computer Music is a mechatronic ensemble of floppy disk drives, CD-ROM drives, stepper motors, and hard disk drives as well as an eight hour long musical performance written for the ensemble which is shown as a non-interactive installation (see figure 36). When the Computer Music installation was shown at the 2016 Digital Arts Expo it was active between 12:00PM and 8:00PM performing a single eight-hour composition. The ensemble is orchestrated through Ableton Live and is amplified through studio monitors using guitar pickups and a powered mixer. [TODO – need paragraph about what the composition was like][TODO – why was is chosen as the composition?][TODO – How non-interaction is essential for its success]      Computer Music could only have been performed with mechatronic instruments due to both the length of the piece and the subtle complexity of the rhythmic phasing that the composition is structured around. The intent is not for gallery goers to stay for the entire composition or that they necessarily fully understand the scope of the performance. 5.2 Mechatronic Instruments Played by HumansThis section presents the Robots Improvisation Jam as an example of a human-mechatronic performance where humans improvise using mechatronic, acoustic, and digital instruments. The mechatronic instruments are controlled with varying granularity at the note, score, and clip levels using a multitude of programming languages and physical interfaces. In these performances, the mechatronics are always being directly controlled by human performers and do not exhibit independence over their actions at any point. These situations can be compared to a typical rock show where each human performer plays an instrument, such as guitar or bass, and that instrument is unable to play without its human counterpart. During these performances, the humans are always in control and the mechatronics function as a guitar or bass: simply an instrument to be played by the human musician.5.2.1 Robots Improvisational JamThe Robots Improvisational Jam is a ten-minute, live, human-mechatronic, group improvisational musical performance featuring eight student musicians improvising over a loose compositional form using a variety of mechatronic instruments, digital synthesis engines, audio feedback, and traditional string instruments. The Robots Improvisational Jam was the headline act for the 2015 composing for robots final showcase concert. During the performance mechatronic instruments in the Machine Lab were controlled by the performers using grid controllers, laptops, microphones, and a variety of software systems including ChucK, Ableton Live, Reaktor, and Python.       The instrumentalization for the Robots Improvisational Jam was varied. Juan Puablo Yepez exhibited note level control over MalletOTon over the majority of the performance using an PUSH grid-controller. The author manipulated feedback on his laptop by xxxxx. Xxx played that one bowed guitar thing. Dexter played an electric guitar. Eric Heep and xxxx did xxxxx.[NV15]	The Robots Improvisational Jam, contrary to what the name suggests, is a composition that foremost is about human musicians improvising using, mostly, instruments that are unique and new. Throughout the performance, the rhythmic, harmonic, and melodic content was dictated by the actions of the human performers while the robotics did not exhibit agency over their actions. With so many performers and no score or conductor, the piece required each participant to exercise considerable restraint, leaving silence for the other member to fill gaps. Relying heavily on the ear, the student performers each needed to exhibit total control over the sounds they were producing throughout the course of the ten-minute improvisation.5.3 Mechatronic Instrumentalists Led by HumansThis section discusses a human-mechatronic musical performance which incorporates reactive mechatronic systems that listen for input from human performers to determine its respective course of action. Robot Whispers, the case study for this section, is realized by an ensemble of seven mechatronic instrumentalists who react to the whisperings of two human performers according to the thresholds set by a third performer. In these class of performance, the mechatronic instruments are able to exhibit limited agency over what notes they play and when they play them but their overall behavior is dictated by humans in real-time.5.3.1 Robot WhispersRobot Whispers was performed in the CalArts Machine Lab in the fall of 2015 over the course of approximately ten minutes. Composed in collaboration with Eric Heep22 and Danny Clarke23, Robot Whispers features three human performers who influence the behavior of over a half-dozen of the Machine Lab’s mechatronic instruments with the frequency content of their voices while reading poetry: which is algorithmically generated in real-time as the written score. We wanted to create a system which allows us to collaborate with the mechatronic instruments, adapt to on-the-fly changes during the performance, and utilize unconventional means of interaction. We were intrigued by the compositional affordances of textual language and the difference between listening to music and the spoken word and instead of directly dictating the notes that each of the robots play during the performance we decided to create a system for the robots to listen, and react, to the frequency content of our voices.       Throughout the performance a text score is algorithmically generated by a computer program in real time and is printed to a terminal window. The score contains information about the words that should be spoken, the tone in which they should be uttered, and the desired speaking speed. Eric and Danny followed the text score by quietly speaking the words into microphones. The audio from the microphones are processed with reverb, delay and other effects before being amplified and sent through quad sound into the performance space. Only the wet signal is amplified and after the extensive processing the original audio content is unintelligible.       Audio from the microphones is used to control the mechatronic instruments in the Machine Lab though a ChucK program which analyzes the frequency content of the microphones, in real-time, and splits up the energy content into several MEL bands each representing a range of frequencies.[56] The actuators for the robots in the Machine Lab are divided into three groups according to the relative pitch of each actuator. The high, medium, and low actuator groups are mapped to groups MEL bands according to relative pitch. Throughout the performance one of the human performers uses a MIDI controller to adjust the threshold for each of three groupings of MEL bins. At any given time, if the overall amplitude of the bands contained is higher than the threshold set by the MIDI controller, the robots will activate and begin to emulate the sounds uttered into the microphones: attempting to echo our language. 5.4 SocialIn contract to the work presented in the other sections, which primarily seeks to create music that is interesting to listen to, the pieces introduced in this section are more concerned with the performance itself. They explore creating social situations that are not concerned with sonic results but instead are crafted for their performative and social dynamics. This section investigates extra-musical opportunities for mechatronic performance by using the mechatronic personalities which will be further described in section 6.6. In the following sub-sections, the performance installations No Humans Allowed, AntiSocial, and HedonismBot are each examined in accordance to their approaches to audience interaction, musical content, and social dynamics.5.4.1 AntiSocialAntiSocial is an extra-musical social performance which involves the mechatronic personality Craig intermingling with any number of audience members in an informal social gathering such as a reception or party. AntiSocial can take place over any period of time but when it was showcased in the fall 2016 MTIID Masters Show the performance lasted for two hours. Although AntiSocial is extra musical in nature, Craig is only able to express himself using solenoids and LED strips resulting in his interactions exhibiting rhythmic and (at times) tonal qualities.      In AntiSocial, a Model-A personality is given the behavior patterns of Craig and is forced to interact with gallery viewers for several hours. Craig suffers from severe social anxiety and is poor at communicating and socializing with both robots and humans. When no-one is directly interacting with Craig he gives himself prep-talks in an attempt to boost confidence for the inevitable social encounter. As Craig sees someone approaching him, all his confidence fades and he is unable to speak, retreating into himself as he is gripped by social paralysis; Craig no longer activates any of his lights or solenoids, falling silent. If someone gets close enough that Craig is unable to ignore them he does his best to interact. Unfortunately, things go from bad to worse for Craig as he fumbles for the correct words, loudness, and pose to express his thoughts. 	These social situations are sonically realized in the following ways. When Craig is unable to detect someone within eight feet of his position, he will rhythmically trigger his solenoids in sequence at a slow, to moderate, speeds with low velocities. To represent him building confidence the longer no-one is detected the time between strikes will slowly decrease as the strike velocities increase. When Craig detects someone is approaching him, he shuts down and goes silent: only rarely activating one of his solenoids or LED’s. Lastly, if Craig detects someone within two feet of his position he attempts to converse as best he can. As he is inept at articulating his feelings and thoughts, the result is an arrhythmic splattering of loud, abrupt, and inappropriate solenoid strikes accompanied by excessively bright strobing light. 	This piece is not a musical performance, nor is it purely an interactive art installation, instead it is a performance of social interaction. AntiSocial is the authors first exploration into imbuing human personality traits, in this case shyness and social anxiety, onto a mechatronic entity and is the beginning of the work concerned with mechatronic personalities. 5.4.2 Hedonism Bot Figure 26: Ivy Liu feeding Hedonism Bot during a performance of Hedonism Bot.Hedonism Bot, composed by Kyle McCarthy, Jake Turpin, Ivy Liu and the author, is a highly musical social ritual that was performed in a concert setting with both mechatronic and human talent for the 2016 Composing for Robots final concert at CalArts. Over eight-minutes, the human performers created sounds, using iPads and hemispherical speaker arrays, while the mechatronic personality fed of the sounds, one at a time, eventually entering into a state of hyperactivity to lead the performance to its conclusion.        A Model-A mechatronic personality is given the characteristics of “Hedonism Bot”. Hedonism Bot, throughout the course of the seven-minute structured improvisation, is ‘fed’ the sounds of human performers whom bow to the robot one at a time while presenting sonic offerings. Each time Hedonism Bot feeds on the offerings it attempts to fully initialize its system; it activates its solenoids attempting to jam with the human performers. However, for the first few feedings Hedonism Bot is unable to maintain enough energy to keep playing for longer than a few seconds. As the performance progresses Hedonism Bot gets stronger and is able to play louder and longer with each meal. Eventually, Hedonism Bot has been fed enough to come to life and the social dynamics of the performance shift. Instead of the human performers leading the pace and narrative of the ritual by creating sounds which are then fed into the robot, Hedonism bot takes the musical lead. The robot cycles through its actuators and creates a consistent rhythm while the human performers fade their instruments out. During the last minute of the performance, Hedonism bot guides the audience through an outro without the accompaniment of any other performers.[NV16] Xxx[NV17].5.4.3 No Humans Allowed[NV18]No Humans Allowed (NHA) is an interactive mechatronic sonic installation where human participants are repelled by xenophobic mechatronic entities. NHA is extra-musical in nature but its three robots create a soundscape, by way of their solenoids, that could easily be analyzed for its musical content. NHA was installed in the WaveCave gallery in the Spring of 2017 for five days of intermittent performance.Bot becomes AggressiveBot becomes SurveillanceBot becomes ProductiveOther bot is AggressiveNo effectNo effectNo effectOther Bot is SurveillanceNo effectNo effectNo effectOther Bot is ProductiveForces into state of SurveillanceDecreases productivityIncreases productivity levelTable 6: How changes in on bots state affects the states of the other bots.      Parallel to the interactions seen in AntiSocial, each of the personalities in NHA have a total of three states: or moods. When no outsiders are detected in the gallery, the personalities are in their productive, happy state. They rhythmically activate their solenoids simulating a fully functioning productive state of mind. If a personality detects an outside presence in the gallery, such as a gallery viewer, their productivity steeply declines as the personality is preoccupied with the outsider and unable to accomplish their daily ‘work’. This mode is the surveillance state or cautious mood. If one of the personalities notices an outsider it alerts the other bots in the community which likewise enter into a state of surveillance; but with a higher productivity rating24 than the bot who sounded the alarm. The third state, or mood, is activated when an outsider ventures too close to the robot. The personality turns hostile as it flashes its lights, which are primarily dormant in the other states, and slams its solenoids in a disturbingly loud, fast, and arrhythmic way. The hostile personality alerts the other personalities in the gallery to the threat causing them to enter into a state of surveillance with a low productivity rating. 	Just like AntiSocial, NHA is not a musical performance nor is it an installation. Instead, it is a performance of social interaction, fear, and isolationism which invites us to question not only human-robot social interaction but conjointly human-human interaction on both personal and societal levels.5.5 ConclusionIn this chapter, four approaches to human-mechatronic performance were discussed through the lenses of mechatronic agency, reactiveness, and human-robot interaction. Each of these compositions were actualized as either installations, performances, or rituals and were introduced in each of the sections. While the styles, approaches, hardware, and software employed for each of these works were varied, they were all conceived, written, and actualized as explorations in the possibilities afforded by mechatronic presence in the social performance space. With mechanical and digital entities becoming increasingly common on the concert stage and in other performance venues, this body of work hopes to inspire performers to explore new possibilities for human-circuit interaction within the entertainment arena.Chapter 6 The Pantheon: A Comprehensive System for Mechatronic Art CreationThe Pantheon is a mechatronic art system which evolved out of an adaptation of the servers and hardware used by the music technology department at CalArts to control the mechatronic instruments residing in the Machine Lab. The Pantheon is structured to be modular, flexible, and easy to learn. This chapter provides an overview of the software and hardware that make up the Pantheon mechatronic system and constitute the technological core of many of the mechatronic installations, and inventions, presented in chapters 3 and 4.6.1 ServerFigure 27: The Pantheon Server initialization routine.The Pantheon server is written in the ChucK programming language[57]–[60] and plays host to mechatronic instruments and sensor banks in several the installations presented in earlier chapters. To ensure that the server is able to keep track of any number of microcontroller clients, a handshake routine is run whenever the server is initialized to sort out the Pantheon microcontrollers from unrelated USB devices which might be plugged into the host computer (see figure 34). The routine requests an identification number (ID) from each USB device connected to the host computer. Connected Pantheon boards respond with their unique ID allowing the server to disseminate information about the microcontroller and assign a corresponding OSC address to the Arduino. Unrelated USB devices receiving the message meanwhile will simply ignore it and continue to function as expected.       After the handshake is complete, the server begins to listen on the network for any OSC messages which correspond to the Arduinos who’ve completed the handshake. When the server recognizes a valid OSC address, which includes valid arguments, it proceeds to forward the message to the appropriate microcontroller using a custom serial communication protocol. In addition to the OSC listener, a supplementary ChucK program can optionally be executed to convert MIDI messages, from an internal IAC bus, into OSC messages that the server understands. This simple, yet flexible, system allows for the easy addition of any number of clients, can be controlled using any programming language able to output MIDI or OSC, provides a standardization for interfacing with the instruments, and gives the system administrator a built-in diagnostic to test if each of the devices are properly communicating with the server. 6.2 SensorsWhile the microcontrollers used in the Pantheon system usually only receive messages from the server, Arduinos with onboard sensors report their reading to the server. During the handshake routine if any of the microcontrollers are discovered to be using sensors the server will spork a shred25 which infinitely polls the shield for readings. The Arduino firmware is kept as simple as possible and does not perform any unnecessary calculations such as smoothing or filtering of its raw sensor values; the signal conditioning is instead delegated to the host computer. This allows for quicker calibration of the signal conditioning, provides a much more powerful machine to perform calculations, and reduces the number of times the microcontrollers need to be flashed. The Pantheon polls the Arduinos telling each unit when to check the values of their sensors and report the result. This is done instead of the Arduinos continuously reporting their value to ensure the user maintains control over any crosstalk between the sensors. This is especially important with ultrasonic rangefinders which have to be triggered one at a time and with an interval of inactivity between triggering to avoid false positives and inaccurate readings. 6.3 Digital ConductorWhen the server is orchestrating many Arduinos that make up larger, more complex structures, such as with the mechatronic personalities in No Humans Allowed which each use five Arduinos, the server initializes a “digital conductor” software process which organizes the multiple devices into larger constructs (personalities) while providing a comparatively intuitive interface for the artist to work with. The digital conductor orchestrates the overall activity of each of the personalities while acting as conduit for communication between the numerous Arduinos used in the ensemble. Just as an orchestral conductor does not play a violin or piano during a concert, the digital conductor does not exhibit direct control over what the personalities are doing. It instead acts as the glue that binds their communication and interaction to the world.6.4 OSCThe Pantheon uses the Open SoundControl (OSC) protocol to orchestrate communication between clients and servers.[61] OSC has many advantages over comparative protocols, such as MIDI, which are often used for controlling musical instruments or installations. For one, OSC is built around the UDP26 internet protocol allowing it to work seamlessly over the network. This makes it possible for Pantheon installations and performances to decentralize via wireless communication. MIDI limits the values for notes and velocities to the range of 0 to 127 while OSC, on the other hand, is able to send full 32-bit integers (ranging from -2,147,483,648 to 2,147,483,637), floating point numbers, strings, and even audio data, or video frames, disguised as what the protocol refers to as “blobs”. One advantage of OSC over MIDI is its freedom to define custom communication schemas. While the OSC schema that The Pantheon uses for any particular project depends on the demands of the project, installations that utilize the mechatronic personality architecture follow a pattern of  “/xyz/n/v” where:• x is the personality number• y is the board type (1: Brigid, 2: Homados, 3: Hermes, 4: Theia)• z is the board number of its type within its parent personality• n is the note number (0-63)• v is the velocity (0-1023)6.5 ShieldsArduino shields are modular circuit boards that piggyback onto a specific Arduino model instilling the microcontroller with added functionality. Many shields were created for the Pantheon system to handle a variety of commonalities when creating mechatronic installations and performances. From driving stepper motors, actuating solenoids and reading ultrasonic rangefinders, the functionality of each board is specialized and its construction varied. All of the Pantheon shields do, however, share a grouping of common traits:• All connectors used are Molex Mini-Fit Jr.o These robust connectors are able to withstand current of up to 9.0A, feature fully isolated terminals with locking housings, require low engagement forces, and use polarized housings.• All boards are conceived as shields for use with either an Arduino Uno or Arduino Mega microcontroller (not both).• For all boards the connectors are consistently wired with the tops of the housings always corresponding with a connection to ground.• All boards have a RGB LED which is programmed to behave consistently between shields. The LED is red while booting after which it turns yellow until it responds to the servers handshake routine. After completing the handshake the LED turn off, but can optionally flash blue each time a message is received from the server.6.5.1 BrigidFigure 28: Brigid six-channel actuator shield for the Arduino Uno.Brigid is the smallest of the two general purpose actuator shields and is designed for use with the Arduino Uno microcontroller.[62] Brigid has a RGB status LED, a I2C port[63], six channels of control for solenoids, DC motors, LED strips or other two-lead DC actuators, and an input jack for interfacing with an external power source. Each of the actuator channels utilize a Pulse Width Modification (PWM) pin on the Arduino, instead of a simple digital pin, for added flexibility and control.[64] The Brigid, along with its big brother Homados, includes JST jacks, along with pull-up resistors, for interfacing with the SDA and SCL pins on the Arduino; allowing for the easy attachment of I2C sensors.Figure 29: Circuit for a single Brigid, or Homados, actuator channel.      The Brigid shield, as well as the larger Homados solenoid driver, employ the same circuit for each of the individual channels (see figure 36). The circuit is engineered for activating solenoids but can be used for other components namely DC motors, LED strips, and relay switches. The reliability of both the Homados and Brigid in installations and performances is largely due to the AOT460 N-Channel Enhancement Mode Field Effect Transistors used for each of their control channels. The AOT460’s are able to safely handle loads of up to 60V at 85A giving them enough headroom to handle most DC solenoids, relays, motors, and lights.[65] The gate of the transistor is connected to one of the Arduino Uno’s PWM pins through a 1kΩ resistor in series; limiting the current draw for each pin putting less strain on the Arduino while ensuring the transistors are not driven too hard. The transistor drain is connected to the positive end of the output jack where a 1N4004 clamp diode, with a path to PWR, protects the transistor from any possible inductive fly-back current caused by solenoids.[66] 6.5.2 HomadosFigure 30: Homados (v2) sixteen channel actuator shield for the Arduino Mega.Homados is the larger of the two actuator shields in the Pantheon system and is fashioned for use with the Arduino Mega microcontroller. The board supports sixteen channels of actuator control, three I2C jacks, and a RGB status LED. The first fifteen channels of the Homados driver utilizes PWM while the sixteenth channel uses a standard digital pin. The Homados is intended to function as a larger version of the Brigid shield and is to be used when six channels of control are inadequate. The Homados shield implements the circuit described in section 6.5.2 and is functionally comparable to the Brigid in all ways.6.5.3 HermesFigure 31: Hermes four channel stepper motor shield for the Arduino Uno.Hermes is a Arduino Uno shield designed to control stepper motors. The Hermes shield provides the Arduino with an interface to two Toshiba ULN2803APG high-voltage, high-current darlington drivers[67] which are used to control up to four stepper motors. The ULN2803APG is a flexible chip which contains eight NPN darlington pairs with internal clamp diodes to protect against switching inductive loads. Each channel can operate at up to 50V at 125mA with a 5V, 0.5mA signal at the input. The ULN2803APG’s afford control over up to four permanent-magnet, or hybrid, unipolar stepper motors which are wired using either the 2-phase or 4-phase unipolar wiring convention. The darling pairs on the Hermes have quick turn-on and turn-off delays, at 0.1 and 0.2 microseconds respectively, allowing the attached stepper motors to be controlled at audio rate to produce sustained tones. In addition to the darlington arrays and output jacks Hermes additionally includes a single I2C channel, a RGB status LED, and two power jacks: one for the motors, and the other for the Arduino. 6.5.4 TheiaTheia is designed specifically for interfacing SR-04 ultrasonic rangefinders which are common sensor used in the work introduced in earlier chapters due to its cost efficiency and abundant availability. The shield features eight channels of control for the rangefinders as well as a RGB status LED. Although Theia was specifically structured for use with SR-04 rangefinders, the shield can alternatively be used for other sensors and actuators. Each of the eight 4-position Mini-Fit Jr. jacks provide power, ground, and two digital pins. The digital pins can be configured in the firmware to operate as either inputs or outputs allowing the shield to control 5V LEDs, motors, actuators, or sensors.6.6 Mechatronic Personalities – A Pantheon ProjectFigure 32: Model-A (left) and Model-B (right) mechatronic personalities.The author has created three mechatronic personalities for the purpose of exploring human-mechatronic interaction. Two models of personalities have been created: Model-A and Model-B. Both are approximately five feet tall, are constructed primarily from extruded aluminum, are powered by the Pantheon mechatronic art system, have ultrasonic rangefinders poised at all four their sides, and feature dozens of solenoids and LED strips which can be controlled by the server. Model-A (figure 36, left) has six rotary solenoids, six large push-pull solenoids, and six smaller push-pull solenoids. None of the solenoids serve any explicate musical or mechanic purpose and are used for expression. The rotary solenoids are hanging in air while the small and large push-pull solenoids simply bang against the aluminum skeleton. Model-B (figure 36, right) does not have rotary solenoids but instead features sixteen additional push-pull solenoids. Only a single Model-A personality was constructed while two Model-B personalities were built. The Model-B personalities differ from each other minimally in their assembly and construction but are functionally exactly the same.	Apart from their minor differences, the personalities have many things in common. To streamline the amount to cables going to each robot, each of the personalities has its own seven-channel powered USB hub and power strip. The USB hubs allows the five Arduinos required to control all of the sensors, solenoids, and LED’s to be condensed down to be interfaced using a single USB cable. To accommodate the LED strips along with all the varieties of solenoids, each of the bots contains a 15amp, 24V and a 30amp, 12V switching power supply. The USB hub, and two power supplies, are plugged into a power strip allowing each bot to be powered with a single extension cable. To help with mobility, the personalities each have casters allowing them to be easily pushed around. 6.7 ConclusionThis chapter introduced the hardware and software systems behind The Pantheon mechatronic system for art creation.  Although still in its infancy, the current capabilities of the server and several of the Arduino shields was demonstrated through the examples of the Model-A and Model-B mechatronic personalities. The goal of this system is to ease in the creation of new mechatronic musical instruments and mechatronic driven installation art by providing a set of diverse modules along with easy to  use, standardized software to control them. The hope is that my implementing The Pantheon the majority of the engineering and software design that goes into the creation of mechatronic art can be alleviated.Chapter 7 Conclusion7.1 SummaryThis document examined a portion of the work fathered by Nathan Villicaña-Shaw during his studies as a MFA student at CalArts. The projects presented were ways the author has approached questioning, exploring, and examining human-circuit interaction within the context of performance and installation art. A background of relevant artists, movements, and ideas in the background chapter was followed by chapter 3 which presented a multitude of installations that created varied interaction scenarios for visitors to navigate. Chapter 4 went into detail about the design philosophies behind the interfaces used in the installations presented in previous chapter while additionally introducing brand new interfaces which challenge our relationship with electronic devices. Chapter 5 detailed four approaches, with eight performance examples, for managing human and mechatronic agency during performance art within both concert and installation environments.       Through the completion of these projects, the author has refined his approach to interaction design not by means of iteration on a singular idea, or approach, but instead by employing new techniques with every project. The multiple lenses used to view the topic of human-circuit interaction has afforded a clarity in values, approach, and aesthetics to the authors artistic practice. This thesis is not a comprehensive study of interaction design, nor does it intend to present its discoveries with any authority. Instead, it seeks to document years spent exploring, pondering, and musing on how our interactions with technology affect the human condition.7.2 Primary ContributionsHistorically, the majority on research in interaction design is conducted by industrial designers, product designers, web engineers, and computer scientists attempting to create easy to use, flexible ways to interact with complex hardware and/or software systems.[6] This corpus attempted to break away from the goals of conventional interaction design, which is concerned with interface transparency and idiosyncrasy, to explore interaction design through the disciplines of experimental music performance and mechatronic installation art. Throughout these works, one approach to interaction is not valued over another while all served to gather perspective on the field.7.3  Final ThoughtsThese projects were inspired by the author’s fascination with electricity, magnetism, and how the human race has harnessed electro-magnetism to run the world around us. In the 21st century, it is nearly impossible to avoid digital technology in the day-to-day grind and the work discussed in this thesis seeks to re-open the discussion on how we fundamentally interact with electrical systems. I invite readers to examine how their bodies electrical properties coexist and affect the electromagnetic devices that are vital in modern society. The goal of the art tendered in this thesis is to invite us to question how we interact not only with electrical systems but with everyone, and everything, in the world around us. 	The end of this document does not mark the end of this work or the authors fascinations with the topics contained herein. The author will continue to develop work that explores our interactions with technology, will continue to extend the capabilities of The Pantheon mechatronic system, and will begin building his own ensemble of mechatronic instruments.Bibliography[1]	“The War of the Currents: AC vs. DC Power,” Energy.gov. [Online]. Available: http://www.energy.gov/articles/war-currents-ac-vs-dc-power. [Accessed: 14-Nov-2016].[2]	C. A. Mack, “Fifty Years of Moore’s Law,” IEEE Trans. Semicond. Manuf., vol. 24, no. 2, pp. 202–207, May 2011.[3]	N. Wiener, The Human Use of Human Beings: Cybernetics and Society. New York, N.Y: Da Capo Press, 1988.[4]	K. Kwastek, Aesthetics of Interaction in Digital Art. Cambridge, Massachusetts: The MIT Press, 2013.[5]	W. R. ASHBY, INTRODUCTION TO CYBERNETICS. Place of publication not identified: MARTINO FINE Books, 2015.[6]	B. Moggridge, Designing interactions. Cambridge, Mass: MIT Press, 2007.[7]	C. Paul, Digital art, Third edition. London: Thames & Hudson, 2015.[8]	Jay David Bolter and Diane Gromala, Windows and Mirrors: Interaction Design, Digital Art, and the Myth of Transparency. 2003.[9]	B. Wands, Ed., Art of the Digital Age, 1. paperback ed. London: Thames & Hudson, 2006.[10]	L. S. Theremin and O. Petrishev, “The Design of a Musical Instrument Based on Cathode Relays,” Leonardo Music J., vol. 6, p. 49, 1996.[11]	S. T. Leo, “Method of and Apparatus for the Generation of Sounds,” US1661058 A, 28-Feb-1928.[12]	S. Hotelling, “Multi-functional hand-held device,” US20060197753 A1, 07-Sep-2006.[13]	S. Hotelling, J. A. Strickon, and B. Q. Huppi, “Multipoint touchscreen,” US7663607 B2, 16-Feb-2010.[14]	C. Honigman, J. Hochenbaum, and A. Kapur, “Techniques in Swept Frequency Capacitive Sensing: An Open Source Approach.,” in NIME, 2014, pp. 74–77.[15]	R. Ghazala, Circuit-bending: build your own alien instruments. Indianapolis, IN: Wiley Publishing, 2005.[16]	A. M. Fernandez and F. Iazzetta, “Circuit-Bending and the DIY Culture,” Escole Communivações E Artes Universidade São Paulo, 2011.[17]	J. A. Paradiso, J. Heidemann, and T. G. Zimmerman, “Hacking Is Pervasive,” IEEE Pervasive Comput., vol. 7, no. 3, pp. 13–15, Jul. 2008.[18]	Motherboard, Reed Ghazala, the Father of Circuit Bending: Sound Builders. .[19]	“Ghazala.” .[20]	“Ghazala.” [Online]. Available: http://www.anti-theory.com/bio/. [Accessed: 15-Feb-2017].[21]	P. Blasser, “Pretty Paper Rolls: Experiments in Woven Circuits,” Leonardo Music J., vol. 17, pp. 25–27, Dec. 2007.[22]	“Peter Blasser (biography).” [Online]. Available: http://www.fondation-langlois.org/html/e/page.php?NumPage=372. [Accessed: 28-Apr-2017].[23]	Peterb:justb, “Peter B: Just B: Peter Blasser Biography,” Peter B, 11-Mar-2012. .[24]	A. McPherson and Y. Kim, “Augmenting the Acoustic Piano with Electromagnetic String Actuation and Continuous Key Position Sensing.,” in NIME, 2010, pp. 217–222.[25]	A. McPherson, “TouchKeys: Capacitive Multi-Touch Sensing on a Physical Keyboard.,” in NIME, 2012.[26]	A. P. McPherson, A. Chamberlain, A. Hazzard, S. McGrath, and S. Benford, “Designing for Exploratory Play with a Hackable Digital Musical Instrument,” 2016, pp. 1233–1245.[27]	M. Rush and M. Rush, New Media in Art, 2nd ed. London: Thames & Hudson, 2005.[28]	R. Greene, Internet Art. New York, N.Y: Thames & Hudson, 2004.[29]	W. Benjamin, “The Work of Art in the Age of Mechanical Reproduction,” Film Theory Crit., vol. 4, pp. 665–82, 2006.[30]	A. Galloway, J. Brucker-Cohen, L. Gaye, E. Goodman, and D. Hill, “Design for Hackability,” 2004, p. 363.[31]	A. McPherson and V. Zappi, “Exposing the Scaffolding of Digital Instruments with Hardware-Software Feedback Loops,” in Proceedings of the international conference on New Interfaces for Musical Expression, 2015, pp. 162–167.[32]	M. A. Net, “Media Art Net | Kubisch, Christina: Sound Flow Light Source – Forty Pillars and One Room,” 05-Oct-2016. [Online]. Available: http://www.medienkunstnetz.de/works/klang-fluss-licht/. [Accessed: 05-Oct-2016].[33]	L. Maes, G.-W. Raes, and T. Rogers, “The Man and Machine Robot Orchestra at Logos,” Comput. Music J., vol. 35, no. 4, pp. 28–48, 2011.[34]	“Biography Page Godfried-Willem Raes Composer and Music Maker.” [Online]. Available: http://www.logosfoundation.org/cv-god.html. [Accessed: 25-May-2017].[35]	TEDx Talks, A robot Orchestra Under Gesture Control: Godfried-Willem Raes at TEDxGhent. .[36]	G.-W. Raes, Gesture controlled virtual musical instruments. Ghent, 1999.[37]	G.-W. Raes, “NaMuDa: Gesture Recognition for Musical Practice,” Available -Line Www Logosfoundation OrgiiNamuda, vol. 123, 2010.[38]	G.-W. Raes, “Expression Control in Automated Musical Instruments,” in a paper presented at the, 2015.[39]	Jim Murphy, Ajay Kapur, and Dale Carnegie, “Musical Robotics in a Loudspeaker World: Developments in Alternative Approaches to Localization and Spatialization,” Leonardo Music J., vol. 22, pp. 41–48, 2012.[40]	A. Kapur and M. Darling, “A Pedagogical Paradigm for Musical Robotics.,” in NIME, 2010, pp. 162–165.[41]	A. Kapur, J. Murphy, M. Darling, E. Heep, B. Lott, and N. Morris, “MalletOTon and the Modulets: Modular and Extensible Musical Robots,” New Interfaces Music. Expr., pp. 69–72, 2016.[42]	A. Kapur et al., “The Machine Orchestra,” in ICMC, 2010.[43]	A. Kapur et al., “The Machine Orchestra: An Ensemble of Human Laptop Performers and Robotic Musical Instruments,” Comput. Music J., vol. 35, no. 4, pp. 49–63, Dec. 2011.[44]	“Deceptive Art Installation by Jeroen Bisscheroux.” [Online]. Available: http://www.huhmagazine.co.uk/6616/deceptive-art-installation-by-jeroen-bisscheroux. [Accessed: 23-May-2017].[45]	“Super Nintendo Entertainment System,” Wikipedia. 12-Apr-2017.[46]	J. Ryan, Super Mario: how Nintendo conquered America. New York: Portfolio Penguin, 2011.[47]	D. Adams, The Ultimate Hitchhiker’s Guide: five complete novels and one story, Complete & unabridged. New York: Gramercy Books, 2005.[48]	“FORM+CODE In Design, Art, and Architecture by Casey Reas, Chandler McWilliams, and LUST.” [Online]. Available: http://formandcode.com/code-examples/transform-slit-scan. [Accessed: 23-May-2017].[49]	Andrew Davidhazy, “Slit-Scan Photography.” Rochester Institute of Technology, 17-Apr-2006.[50]	“Video Art: Characteristics, Origins, History.” [Online]. Available: http://www.visual-arts-cork.com/video-art.htm. [Accessed: 23-May-2017].[51]	M. Puckette and others, “Pure Data: Another Integrated Computer Music Environment,” Proc. Second Intercollege Comput. Music Concerts, pp. 37–41, 1996.[52]	“Raspberry Pi GPIO Pin Information.” [Online]. Available: http://www.thebox.myzen.co.uk/Raspberry/Understanding_Outputs.html. [Accessed: 16-Nov-2016].[53]	Microchip, “MCP3008 Datasheet” Microchip, 02-Jan-2008.[54]	“PAM8403 Datasheet” .[55]	B. Schrader, Introduction to Electro-Acoustic music. Englewood Cliffs, N.J: Prentice Hall, 1982.[56]	A. Lerch, Audio Content Analysis: an Introduction. Hoboken, N.J: Wiley, 2012.[57]	G. Wang, P. R. Cook, and S. Salazar, “Chuck: A Strongly Timed Computer Music Language,” Comput. Music J., 2016.[58]	G. Wang, A. Misra, A. Kapur, and P. R. Cook, “Yeah, ChucK it! ⇒ dynamic, controllable interface mapping,” in Proceedings of the 2005 conference on New interfaces for musical expression, 2005, pp. 196–199.[59]	G. Wang, R. Fiebrink, and P. R. Cook, “Combining Analysis and Synthesis in the ChucK Programming Language.,” presented at the International Computer Music Conference, 2007.[60]	P. R. Cook, S. Salazar, A. Kapur, G. Wang, and C. Reas, Eds., Programming for Musicians and Digital Artists: Creating Music with ChucK. Shelter Island: Manning, 2015.[61]	“Open SoundControl: A New Protocol for Communicating with Sound Synthesizers.” [Online]. Available: http://cnmat.org/ICMC97/papers-html/OpenSoundControl.html. [Accessed: 04-Mar-2017].[62]	Y. A. Badamasi, “The Working Principle of an Arduino,” 2014, pp. 1–4.[63]	F. Leens, “An Introduction to I2C and SPI Protocols,” IEEE Instrum. Meas. Mag., vol. 12, no. 1, pp. 8–13, Feb. 2009.[64]	M. Margolis, Arduino Cookbook. Sebastopol, Calif.: O’Reilly, 2012.[65]	Alpha & Omega Semiconductor Inc., “AOT460 Datasheet.” .[66]	P. Scherz and S. Monk, Practical Electronics for Inventors, Third edition. New York: McGraw-Hill, 2013.[67]	Toshiba, “ULN2803A Datasheet” Toshiba, 03-Dec-2010.1 The Retrono, Discovery Synth, Voltage Slammer, and Modular SNES interfaces presented in Chapter 4 are examples.2 The Potsdamer Platz is an important public square, and traffic intersection, in the center of Berlin, Germany, lying about 1 km south of the Brandenburg Gate and the German parliament building.3 The Logos Ensembles was founded in 1968/1969 and has included dozens of members over the decades. The ensemble’s spring, 2017 members are Godfreid-Williem Raes, Moniek Darge, Karin De Fielyt, Marc Maes, Stefaan Smagghe, Kris De Baerdemacker, and Kristof Lauwers. 4 All are actuated with solenoid beaters. The crash symbol has two dampening mechanisms. The snare has a brush, which can be rubbed on the membrane, as well as a beater.5 The glasses, xylophone, cymbals and drums are directly struck by tubular push-pull solenoids. The guitar and bass strings each have their own picking mechanism, a string dampener, and five possible fret positions.6 Examples of games that belong to the rail shooter genera include: The House of the Dead 1, 2, 3, and 4; Star Fox 64; Virtua Cop 1, 2, and 3; Time Crisis 1, 2, 3, and 4; just to name a few. 7 More information about the SSNES play modes can be found in section 4.4.1.8 Digital slit scan processing is a video process for transforming the frames of a video into a single image. [48] More information about the authors implementation can be found in sections 4.5.3 and 4.5.4.9 https://www.python.org/10 MIDI or Musical Instrument Digital Interface is a communication protocol commonly used for communication between hardware and software systems during music production.11 Ableton Live is a software music sequencer and digital audio workstation used for recording, arranging, composing, mixing, DJing, and mastering.12 See section 5.3.3 for more information about the composition.13 A Cape for a Raspberry Pi is analogous to Shield’s for the Arduino platform. It Is a small printed circuit board that is designed to be attached to the GPIO headers of the Raspberry Pi and provides some sort of additional functionality usually though the use of IC’s and/or discrete electrical components.14 Such as Super Mario World (1990), The Legend of Zelda: A Link to the Past (1992), or Donkey Kong Country (1994).15 Such as Mario Cart (1992), Teenage Mutant Ninja Turtles: Turtles in Time (1992), Super Double Dragon (1992), and Killer Instinct (1994).16 https://github.com/turicas/SNES17 A “First In First Out” buffer is a type of circular buffer that continually rewrites over the oldest values with the newest values.18 Examples include color-separated Perlin noise masks, vertical gradient masks, horizontal gradient masks, image masks, and video feedback maaks.19 A black box is a device or system that is viewed in terms of its transfer characteristics (inputs and outputs) without any knowledge of its internal workings.20 An RCA connector is a type of electrical connector commonly used to carry audio and video signals. The connectors are sometimes casually referred to as A/V jacks. The name "RCA" derives from the Radio Corporation of America, which introduced the design by the early 1940s for internal connection of the pickup to the chassis in home radio-phonograph consoles. 21 SPST: Single Pole Single Throw is the name for a type of switch which has two different states over a single channel.22 CalArts 2016 – MFA MTIID Alum23 CalArts 2016 – MFA Composition Alum24 A higher productivity rating will result in more actuator activations than a lower rating.25 Sporking a shred, in ChucK, creates a non-blocking, concurrent sub-process which runs on the same virtual machine as the host program.26 UDP or User Datagram Protocol is one of the core members of the internet protocol suite which allows computer applications to send messages over the internet to other hosts.[NV1]TODO – talk about how every project strove to adove different values[NV2]TODO – need to update with current state of things – expand a little about the motivations around presenting the chapters as they were presentedfind another word, coolerWhat is dat?Instrument, instrument, instrument, also creates, creates, createsAdd citation here...Cite that shit[NV8]TODO – something for scholastic sounding[NV9]Perspective? First person?[NV10]Sounds dirty…[NV11]TODO – needs sentence that talks about what a multitude is?[NV12]Out of sync[NV13]TODO – this needs to be flushed out still[NV14]TODO – add diagram of where each of the ML bots live[NV15]TODO – this section needs to be filled in…        [NV16]This is the performance where we feed the bot. Talk about the dangers of the performance space and how it forced us to “wizard of Oz” the live performance. The following citation covers the Wizard of Oz effect.[6, pp. 43–44][NV17]TODO – perhaps add more about why and who cares?[NV18]No Humans Allowed (NHA) is the final performance discussed in this chapter which utilizes the authors mechatronic personalities. While AntiSocial and Hedonism Bot both only used a single Model-A personality, NHA uses one Model-A personality in addition to two Model-B personalities to create a community of xenophobic robots.--------------------------------------------------------------------------------------------------------------xiv